{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Machine Learning Engineering \u00b6 Oh man... really? Err... no momento, n\u00e3o estou mais atualizando esse material j\u00e1 que passei a estudar (e manter) um material sobre engenharia de dados (que ainda se encontra offline, rs.) Ent\u00e3o, novos conte\u00fados n\u00e3o ser\u00e3o adicionados aqui por um tempo (pelo menos n\u00e3o em 2022) Salve, pessoa lendo isso! Lidar com modelos de machine learning no mundo real envolve muito mais do que .fit() e .predict() . Coloc\u00e1-los em produ\u00e7\u00e3o, garantir consist\u00eancia e qualidade das predi\u00e7\u00f5es, resili\u00eancia e efici\u00eancia quando submetido a grandes volumes de dados, versionamento e reprotudibilidade... Para cuidarmos certinho dos nossos modelos de ML (em escala), precisamos de uma s\u00e9rie de pr\u00e1ticas, estrat\u00e9gias e tecnologias. Por conta disso, decidi registrar o meu aprendizado sobre Machine Learning Engineering e MLOps nessa p\u00e1gina. Caso queira dar uma olhadinha, sinta-se a vontade! Note que o trabalho ainda est\u00e1 em progresso. Portanto, provavelmente voc\u00ea vai acabar encontrando alguns erros tanto conceituais quanto de escrita. Por\u00e9m, problemas ser\u00e3o corrigidos e melhorias ser\u00e3o adicionadas \u00e0 medida que o trabalho avan\u00e7ar Caso queira contribuir com sugest\u00f5es, sinta-se \u00e0 vontade para abrir Issues & PRs aqui no reposit\u00f3rio ahayasic/machine-learning-systems-design !","title":"In\u00edcio"},{"location":"#machine-learning-engineering","text":"Oh man... really? Err... no momento, n\u00e3o estou mais atualizando esse material j\u00e1 que passei a estudar (e manter) um material sobre engenharia de dados (que ainda se encontra offline, rs.) Ent\u00e3o, novos conte\u00fados n\u00e3o ser\u00e3o adicionados aqui por um tempo (pelo menos n\u00e3o em 2022) Salve, pessoa lendo isso! Lidar com modelos de machine learning no mundo real envolve muito mais do que .fit() e .predict() . Coloc\u00e1-los em produ\u00e7\u00e3o, garantir consist\u00eancia e qualidade das predi\u00e7\u00f5es, resili\u00eancia e efici\u00eancia quando submetido a grandes volumes de dados, versionamento e reprotudibilidade... Para cuidarmos certinho dos nossos modelos de ML (em escala), precisamos de uma s\u00e9rie de pr\u00e1ticas, estrat\u00e9gias e tecnologias. Por conta disso, decidi registrar o meu aprendizado sobre Machine Learning Engineering e MLOps nessa p\u00e1gina. Caso queira dar uma olhadinha, sinta-se a vontade! Note que o trabalho ainda est\u00e1 em progresso. Portanto, provavelmente voc\u00ea vai acabar encontrando alguns erros tanto conceituais quanto de escrita. Por\u00e9m, problemas ser\u00e3o corrigidos e melhorias ser\u00e3o adicionadas \u00e0 medida que o trabalho avan\u00e7ar Caso queira contribuir com sugest\u00f5es, sinta-se \u00e0 vontade para abrir Issues & PRs aqui no reposit\u00f3rio ahayasic/machine-learning-systems-design !","title":"Machine Learning Engineering"},{"location":"about/","text":"Sobre o Autor \u00b6 Saaalve! Meu nome \u00e9 Alisson, sou formado em Ci\u00eancia da Computa\u00e7\u00e3o pela Universidade Federal S\u00e3o Carlos e atualmente trabalho como Engenheiro de Dados no iFood . Como voc\u00ea j\u00e1 deve saber, ensinar \u00e9 a melhor forma de aprender e este projeto tem exatamente essa inten\u00e7\u00e3o! Todo o conte\u00fado presente aqui tem como objetivo ser um caderno de notas e resumos \\(-\\) totalmente de guia pessoal \\(-\\) sobre os principais t\u00f3picos relacionados ao projeto de Sistemas de Machine Learning. Logo, dado o car\u00e1ter pessoal, pe\u00e7o que n\u00e3o se estresse caso a did\u00e1tica seja ruim e o conte\u00fado esteja mal organizado ou faltante, afinal este material n\u00e3o visa servir como refer\u00eancia ou material de ensino (pelo menos n\u00e3o no momento... talvez no futuro?). No m\u00e1ximo, algo pra compartilhar conhecimento de modo informal Por\u00e9m, ao mesmo tempo, caso encontre quaisquer erros, por favor entre em contato comigo e irei corrigi-los o mais r\u00e1pido poss\u00edvel (e voc\u00ea tamb\u00e9m estar\u00e1 me ajudando a aprender mais!). Enfim, divirta-se!","title":"Sobre o Autor"},{"location":"about/#sobre-o-autor","text":"Saaalve! Meu nome \u00e9 Alisson, sou formado em Ci\u00eancia da Computa\u00e7\u00e3o pela Universidade Federal S\u00e3o Carlos e atualmente trabalho como Engenheiro de Dados no iFood . Como voc\u00ea j\u00e1 deve saber, ensinar \u00e9 a melhor forma de aprender e este projeto tem exatamente essa inten\u00e7\u00e3o! Todo o conte\u00fado presente aqui tem como objetivo ser um caderno de notas e resumos \\(-\\) totalmente de guia pessoal \\(-\\) sobre os principais t\u00f3picos relacionados ao projeto de Sistemas de Machine Learning. Logo, dado o car\u00e1ter pessoal, pe\u00e7o que n\u00e3o se estresse caso a did\u00e1tica seja ruim e o conte\u00fado esteja mal organizado ou faltante, afinal este material n\u00e3o visa servir como refer\u00eancia ou material de ensino (pelo menos n\u00e3o no momento... talvez no futuro?). No m\u00e1ximo, algo pra compartilhar conhecimento de modo informal Por\u00e9m, ao mesmo tempo, caso encontre quaisquer erros, por favor entre em contato comigo e irei corrigi-los o mais r\u00e1pido poss\u00edvel (e voc\u00ea tamb\u00e9m estar\u00e1 me ajudando a aprender mais!). Enfim, divirta-se!","title":"Sobre o Autor"},{"location":"references/","text":"Work in progress","title":"References"},{"location":"concepts/machine_learning_engineering/","text":"Sobre Machine Learning Engineering \u00b6 Introdu\u00e7\u00e3o \u00b6 Projetar, construir e manter solu\u00e7\u00f5es de machine learning n\u00e3o s\u00e3o tarefas f\u00e1ceis. Muito pelo contr\u00e1rio! S\u00e3o complexas e exigem melhorias cont\u00ednuas. De acordo com o relat\u00f3rio \"2020 State of Enterprise Machine Learning\" da Algorithmia. A maior parte das empresas ainda n\u00e3o descobriram como atingir seus objetivos de ML/IA pois a lacuna entre a constru\u00e7\u00e3o do modelo de ML e o deploy \u00e9 desafiadora. Apenas 22% das companhias que usam aprendizado de m\u00e1quina implantaram com sucesso um modelo de ML em produ\u00e7\u00e3o. E isso ocorre pois apenas uma pequena fra\u00e7\u00e3o dos sistemas de ML do mundo real s\u00e3o compostos por c\u00f3digo de ML . Um sistema em produ\u00e7\u00e3o \u00e9 composto de diversos componentes , como, por exemplo: interfaces para que usu\u00e1rios e desenvolvedores interajam com o sistema, infraestrutura para executar a aplica\u00e7\u00e3o, engenharia e governan\u00e7a de dados para o gerenciamento e confiabilidade dos dados, entre outros. Fonte: Sculley, David, et al. \"Hidden technical debt in machine learning systems.\" Advances in neural information processing systems 28 (2015): 2503-2511. Al\u00e9m disso, considerando a escala de muitos sistemas de ML que \\(-\\) consumem grandes quantidades de dados, exigem um grande recurso computacional e afeta milhares de vidas \\(-\\) a simples necessidade de coloc\u00e1-lo em produ\u00e7\u00e3o j\u00e1 \u00e9 um grande desafio de engenharia e social. Como diz nossa querida Chip Huyen: Cita\u00e7\u00e3o \"Quando este desafio n\u00e3o \u00e9 bem compreendido, o sistema de ML pode causar grandes preju\u00edzos tanto \u00e0 companhia quanto a vida das pessoas.\" \\(-\\) Chip Huyen Portanto, precisamos de um conjunto de pr\u00e1ticas e processos eficazes para projetar, construir, implantar e manter modelos de ML em produ\u00e7\u00e3o de forma escal\u00e1vel e confi\u00e1vel . Andriy Burkov define machine learning engineering como a \u00e1rea respons\u00e1vel pela produtiza\u00e7\u00e3o, operacionaliza\u00e7\u00e3o e manuten\u00e7\u00e3o de sistemas de ML, sendo a defini\u00e7\u00e3o: Defini\u00e7\u00e3o de Machine Learning Engineering \"Machine learning engineering \u00e9 o uso de princ\u00edpios cient\u00edficos, ferramentas e t\u00e9cnicas de aprendizado de m\u00e1quina e engenharia de software tradicional para projetar e construir sistemas de computa\u00e7\u00e3o complexos. O MLE abrange todas as etapas, desde a coleta de dados, at\u00e9 a constru\u00e7\u00e3o do modelo, a fim de disponibilizar o modelo para uso pelo produto ou consumidores.\" \\(\u2014\\) Andriy Burkov Por\u00e9m, h\u00e1 pessoas que dizem que MLOps \u00e9 a \u00e1rea respons\u00e1vel por lidar com modelos em produ\u00e7\u00e3o, sendo MLOps definido pela MLOps SIG como: Defini\u00e7\u00e3o de MLOps \"A extens\u00e3o da metodologia DevOps para incluir ativos de aprendizado de m\u00e1quina e ci\u00eancia de dados como cidad\u00e3os de primeira classe dentro da ecologia DevOps.\" Contudo, independente do termo utilizado (MLOps ou MLE) , o que importa \u00e9 o objetivo da \u00e1rea de fornecer um processo para o projeto e desenvolvimento de sistemas baseados em machine learning que sejam reprodut\u00edveis, escal\u00e1veis e robustos. Aqui , MLOps estar\u00e1 restrito a tarefas relacionadas a operacionaliza\u00e7\u00e3o dos modelos de ML. Demais tarefas correspondentes a outras etapas de um projeto de ML ter\u00e3o pr\u00e1ticas classificadas como pertencentes a \u00e1rea machine learning engineering . Sistema x Aplica\u00e7\u00e3o Embora eu j\u00e1 tenha escrito \"sistema\", \"sistema\" e \"sistema\", n\u00e3o deixei claro sobre o que eu estou falando. O que \u00e9 um sistema de ML? \u00c9 a aplica\u00e7\u00e3o? Ou a solu\u00e7\u00e3o de ML que a aplica\u00e7\u00e3o usa? E essa solu\u00e7\u00e3o de ML... Usa alguma plataforma de ML para auxiliar na produ\u00e7\u00e3o de modelos? Se sim, a plataforma \u00e9 o sistema de ML? No caso, h\u00e1 pessoas que consideram aplica\u00e7\u00f5es baseadas em ML (i.e. que usam recursos de ML em algum momento, como uma aplica\u00e7\u00e3o que usa algoritmos de recomenda\u00e7\u00e3o) e sistemas de ML como a mesma coisa. Por\u00e9m, \"sistemas de ML\" n\u00e3o me parece transmitir bem essa ideia. Ent\u00e3o, vamos considerar aqui que um sistema de ML \u00e9 qualquer aplica\u00e7\u00e3o ou solu\u00e7\u00e3o que possui alguma depend\u00eancia com algoritmos de ML e, portanto, necessitam de pr\u00e1ticas espec\u00edficas para ML. Ainda, tamb\u00e9m vamos dizer que uma plataforma de ML \u00e9 uma aplica\u00e7\u00e3o que fornece um conjunto de recursos a execu\u00e7\u00e3o de pr\u00e1ticas MLOps. Machine Learning na Ind\u00fastria \u00b6 Muitas pessoas possuem o senso comum de que: O desenvolvimento de algoritmos e sistemas de ML \u00e9 o mesmo tanto na ind\u00fastria quanto na academia Desenvolver aplica\u00e7\u00f5es baseadas em ML \u00e9 o mesmo que desenvolver softwares tradicionais. Essa perspectiva n\u00e3o apenas est\u00e1 errada, como tamb\u00e9m \u00e9 perigosa. Sistemas de ML possuem diversos desafios pr\u00f3prios e, como j\u00e1 dito anteriormente, n\u00e3o compreender tais desafios pode levar a consequ\u00eancias ruins . ML na Pesquisa x ML na Ind\u00fastria (Mercado) \u00b6 O desenvolvimento de modelos de ML na academia possui um prop\u00f3sito diferente quando comparado com a ind\u00fastria. Na academia, (geralmente) estamos preocupados em alcan\u00e7ar o estado-da-arte (SOTA, do ingl\u00eas state-of-the-art) em um determinado problema. Por conta disso, \u00e9 muito comum que os modelos resultantes sejam custosos demais para serem utilizados na ind\u00fastria. Modelos com bilh\u00f5es de par\u00e2metros, por exemplo, s\u00e3o extremamente custosos para treinar e operacionalizar. Dependendo de onde ser\u00e1 feita a sua implanta\u00e7\u00e3o (e.g. dispositivo m\u00f3vel), o uso de algo t\u00e3o complexo \u00e9 invi\u00e1vel. Nota Eventualmente os \"big models\" v\u00e3o se tornar menores e mais r\u00e1pidos. Por\u00e9m, a diferen\u00e7a de prioridades entre a academia e ind\u00fastria raramente ir\u00e1 permitir que os m\u00e9todos SOTA sejam utilizados em produ\u00e7\u00e3o. Ainda, em projetos de pesquisa \u00e9 muito comum que os dados sejam algum \"benchmarking\". Logo, s\u00e3o dados geralmente limpos e que permitem o foco total no desenvolvimento de modelos de aprendizado. Por outro lado, sistemas em produ\u00e7\u00e3o precisam lidar com falta de dados, dados desorganizados, ru\u00eddosos e que mudam constantemente. De fato, tanto os objetivos quanto os desafios s\u00e3o consideralvemente diferentes em cada contexto. Contudo, ainda assim \u00e9 muito comum os profissionais de dados focarem unicamente no desenvolvimento do modelo e encarar com menor import\u00e2ncia as demais tarefas. Esta atitude \u00e9 um exemplo de quando o desafio de colocar sistemas de ML em produ\u00e7\u00e3o n\u00e3o \u00e9 bem compreendido. Softwares Tradicionais x Sistemas de ML \u00b6 Diferente de softwares tradicionais, sistemas de ML n\u00e3o compreendem apenas c\u00f3digo, mas tamb\u00e9m dados e modelos. A adi\u00e7\u00e3o de mais dois artefatos torna o desenvolvimento de aplica\u00e7\u00f5es baseadas em ML significativamente mais complexo, pois al\u00e9m de testar e versionar c\u00f3digos, temos que testar e versionar dados e modelos. Consequentemente, desafios \u00fanicos ao projeto de sistemas de ML surgem, desde etapas como desenvolvimento, at\u00e9 o teste, integra\u00e7\u00e3o, compila\u00e7\u00e3o e monitoramento do sistema. Etapas de um Projeto de ML \u00b6 O projeto de um sistema de ML \u00e9 processo formado por v\u00e1rias etapas que partem desde a concep\u00e7\u00e3o at\u00e9 a manuten\u00e7\u00e3o da solu\u00e7\u00e3o encontrada. Este processo \\(-\\) tamb\u00e9m chamado de ciclo de vida \\(-\\) \u00e9 composto por quatro etapas principais (que por sua vez, podem ser divididas em mais etapas). S\u00e3o elas: Escopo Prepara\u00e7\u00e3o dos Dados Modelagem Implanta\u00e7\u00e3o (do ingl\u00eas, deployment). Not so shallow... Al\u00e9m de descritas abaixo, cada uma dessas etapas cont\u00e9m se\u00e7\u00f5es particulares onde s\u00e3o abordadas com mais detalhes, incluindo estrat\u00e9gias sobre o que fazer em cada momento da etapa e como fazer. A gra\u00e7a do mundo est\u00e1 na diversidade O ciclo de vida apresentado aqui \u00e9 o considerado por Andrew Ng. No entanto, h\u00e1 diversas figuras importantes na \u00e1rea de ML com perspectivas diferentes sobre o ciclo de vida e suas etapas. Por exemplo, este ciclo de vida pode transmitir uma no\u00e7\u00e3o de ser algo direto e n\u00e3o repetitivo. Por\u00e9m, muito pelo contr\u00e1rio, na pr\u00e1tica o processo de cria\u00e7\u00e3o de um modelo de ML \u00e9 extremamente iterativo, ciclo e dificilmente termina. Afinal, uma vez que o modelo est\u00e1 em produ\u00e7\u00e3o, precisamos mant\u00ea-lo! Consequentemente, temos que desenvolver toda uma estrutura para que isso seja feito da forma mais din\u00e2mica poss\u00edvel. Nesse sentido, prepara\u00e7\u00e3o de dados \u00e9 a etapa onde toda a arquitetura de dados para o projeto \u00e9 definida, por exemplo. Escopo \u00b6 O escopo \u00e9 a etapa onde o projeto \u00e9 definido. Logo: Qual problema ser\u00e1 atacado Como o problema ser\u00e1 atacado Qual o crit\u00e9rio de sucesso Os principais objetivos desta etapa s\u00e3o identificar o que deve ser feito e o qu\u00e3o vi\u00e1vel \u00e9 o que deve ser. Assim, \u00e9 muito importante que o objetivo do projeto seja claro e bem definido. Perguntas que podem nos ajudar a definir o objetivo do projeto s\u00e3o: Qual \u00e9 o problema que queremos resolver usando ML? Por que queremos aplicar ML? Quais s\u00e3o as entradas que ser\u00e3o consumidas pelo modelo? Quais as sa\u00eddas que devem ser geradas pelo modelo? Quais m\u00e9tricas e crit\u00e9rios definem o sucesso do modelo? Quais m\u00e9tricas e crit\u00e9rios definem o sucesso do projeto? Nota O objetivo do modelo n\u00e3o necessariamente precisa ser o mesmo objetivo do ponto de vista de neg\u00f3cios (ou seja, o que o cliente busca alcan\u00e7ar). Por exemplo, uma empresa de e-commerce pode ter como objetivo maximizar os lucros com base no pre\u00e7o dos produtos. J\u00e1 o modelo pode ter como objetivo encontrar o pre\u00e7o de um conjunto de produtos que maximize a probabilidade de compra conjunta destes produtos. Outra pr\u00e1tica comum que pode nos ajudar a definir o escopo do projeto com mais rigor (tal como sua execu\u00e7\u00e3o) \u00e9 o uso de Canvas, como o ML Canvas . Risco e Impacto do Projeto \u00b6 Uma vez definido o que deve ser feito, \u00e9 comum avaliarmos a viabilidade do projeto atrav\u00e9s de estimativas de riscos e impacto. At\u00e9 o momento n\u00e3o existem m\u00e9todos de estima\u00e7\u00e3o de complexidade de um projeto de ML que s\u00e3o amplamente utilizados pela ind\u00fastria. Ainda, projetos de ML s\u00e3o incertos por natureza uma vez que nem sempre os recursos necess\u00e1rios para a solu\u00e7\u00e3o do problema existem ou s\u00e3o vi\u00e1veis. Por exemplo, \u00e9 dif\u00edcil definir com precis\u00e3o quais ser\u00e3o os dados necess\u00e1rios, a quantidade de dados necess\u00e1rios, se os modelos existentes na literatura resolvem o problema em quest\u00e3o, etc. Portanto, o uso de modelos de risco-impacto \u00e9 uma abordagem segura e efetiva. Um exemplo de modelo de risco-impacto para projetos de ML \u00e9 o apresentado na figura abaixo. Fonte: Business Objectives \u2013 ML Life Cycle by ProductizeML Custos do Projeto \u00b6 O custo de desenvolvimento e opera\u00e7\u00e3o de um projeto de ML \u00e9 um fator decisivo na balan\u00e7a de risco e impacto. De acordo com Andriy Burkov, h\u00e1 tr\u00eas fatores principais que influenciam consideravelmente o custo de um projeto de ML. Dificuldade do problema. Quanto maior a dificuldade do problema, maior o custo de execu\u00e7\u00e3o e engenharia. Perguntas que nos ajudam a identificar a dificuldade do problema s\u00e3o: H\u00e1 empresas que j\u00e1 resolveram o mesmo problema ou semelhante? H\u00e1 solu\u00e7\u00f5es para problemas parecidos na academia? H\u00e1 implementa\u00e7\u00f5es dispon\u00edveis de algoritmos capazes de resolver o problema em quest\u00e3o? O quanto de poder computacional \u00e9 necess\u00e1rio para construir e executar o modelo em produ\u00e7\u00e3o? Custo de aquisi\u00e7\u00e3o dos dados. Coletar a quantidade necess\u00e1ria dos dados corretos tende a ser custoso, principalmente se h\u00e1 necessidade de categoriza\u00e7\u00e3o manual dos dados. Perguntas que nos ajudam a identificar o custo de aquisi\u00e7\u00e3o dos dados s\u00e3o: Quais os dados necess\u00e1rios? Qual a quantidade de dados neces\u00e1rios? Os dados podem ser gerados automaticamente? \u00c9 necess\u00e1rio categorizar amostras? Se sim, quantas? Qual o custo? Necessidade de assertividade. Quanto maior a necessidade de assertividade do modelo, maior o custo associado (que crescer\u00e1 exponencialmente). Afinal, a assertividade de um modelo n\u00e3o depende apenas do modelo em si, mas tamb\u00e9m dos dados dispon\u00edveis (geralmente, quanto mais dados, melhor) e dificuldade do problema. Nota Novamente, aqui o uso de Canvas para ML tamb\u00e9m \u00e9 \u00fatil tanto para fazermos as perguntas certas quanto encontrarmos as respostas corretas e assim estimarmos custos com maior precis\u00e3o. Definindo Baselines \u00b6 Do ponto de vista de um projeto de ML, uma baseline \u00e9 o desempenho base a partir do qual queremos melhorar. Portanto, antes de come\u00e7armos a implementarmos nossos pr\u00f3prios modelos, \u00e9 importante pesquisarmos solu\u00e7\u00f5es j\u00e1 existentes para o problema que queremos atacar (ou ent\u00e3o, semelhantes ao problema que queremos atacar). O Model Zoo , por exemplo, \u00e9 uma plataforma onde diversos modelos pr\u00e9-treinados (de deep learning) s\u00e3o disponibilizados, de forma que o desenvolver tenha apenas que \"plug\u00e1-lo\" no sistema ou processo de desenvolvimento. Prepara\u00e7\u00e3o dos Dados \u00b6 Esta \u00e9 a etapa onde os dados necess\u00e1rios para a execu\u00e7\u00e3o do projeto e constru\u00e7\u00e3o do modelo s\u00e3o coletados e processados. Note que a prepara\u00e7\u00e3o de dados \u00e9 absolutamente importante, visto que erros nos dados s\u00e3o propagados ao longo de todo o projeto, o que pode resultar em problemas cr\u00edticos. Al\u00e9m disso, a etapa de prepara\u00e7\u00e3o de dados \u00e9 (geralmente) composta pelas seguintes tarefas: Ingest\u00e3o de Dados. Coleta e armazenamento de dados oriundos de diversas fontes em diversos mecanismos de armazenamento, tais como Data Lakes e Data Warehouses. Essa etapa tamb\u00e9m pode incluir o enriquecimento de dados e/ou gera\u00e7\u00e3o de dados sint\u00e9ticos. Explora\u00e7\u00e3o e Valida\u00e7\u00e3o. Perfilamento de dados a fim de obter informa\u00e7\u00f5es sobre sua estrutura que, por sua vez, s\u00e3o utilizadas para definir poss\u00edveis esquemas de dados, assim como rotinas de teste e valida\u00e7\u00e3o. Data Cleaning. Processo de formata\u00e7\u00e3o dos dados e corre\u00e7\u00e3o de erros (e.g. valores faltantes ou inconsistentes) de forma que se enquadrem nos esquemas definidos. Data Splitting. Divis\u00e3o do dados em conjuntos dedicados ao treinamento, valida\u00e7\u00e3o e teste dos modelos produzidos. Entramos em mais detalhes sobre a prepara\u00e7\u00e3o de dados na se\u00e7\u00e3o Prepara\u00e7\u00e3o de Dados . Modelagem \u00b6 Esta \u00e9 a etapa onde os modelos cogitados para atacar o problema definido no escopo s\u00e3o treinados, testados, selecionados e reavaliados. As subetapas principais da etapa de modelagem s\u00e3o: Treinamento & Sele\u00e7\u00e3o de Modelos. Processo onde modelos s\u00e3o treinados e o melhor \\(-\\) com base em m\u00e9tricas de desempenho para a tarefa em quest\u00e3o (e.g. acur\u00e1cia, erro quadr\u00e1tico m\u00e9dio, etc) \\(-\\) \u00e9 selecionado como candidato \u00e0 produ\u00e7\u00e3o. Avalia\u00e7\u00e3o. Processo onde s\u00e3o executadas an\u00e1lises de erro a fim de verificar se o modelo \\(-\\) al\u00e9m de possuir boas m\u00e9tricas de desempenho (do ponto de vista de treinamento) \\(-\\) resolve o problema definido. Nesta etapa tamb\u00e9m \u00e9 comum avaliar um poss\u00edvel enviesamento do modelo, assim como requisitos n\u00e3o funcionais (e.g. tempo de infer\u00eancia, custo computacional, etc.) Al\u00e9m disso, \u00e9 neste momento que comparamos o modelo constru\u00eddo com poss\u00edveis baselines e analisamos quais pontos podem ser melhorados. Entramos em mais detalhes sobre o treinamento e avalia\u00e7\u00e3o de modelos nas se\u00e7\u00f5es Constru\u00e7\u00e3o de Modelos e Avalia\u00e7\u00e3o , respectivamente. Implanta\u00e7\u00e3o \u00b6 Etapa onde o modelo constru\u00eddo \u00e9 colocado em produ\u00e7\u00e3o. Logo, al\u00e9m das pr\u00e1ticas convencionais aplicadas no desenvolvimento de modelos de ML, durante o deployment (implanta\u00e7\u00e3o) pr\u00e1ticas de engenharia de software s\u00e3o aplicadas com mais intensidade, incluindo testes unit\u00e1rios e de integra\u00e7\u00e3o, integra\u00e7\u00e3o do modelo com o restante do sistema, defini\u00e7\u00e3o de pol\u00edticas de monitoramento, etc. A etapa de implanta\u00e7\u00e3o \u00e9 geralmente composta pelos seguintes processos: Model Serving. Processo de disponibiliza\u00e7\u00e3o do modelo em um ambiente de produ\u00e7\u00e3o para acesso pelos usu\u00e1rios. Monitoramento de Performance. Processo de monitoramento da performance do modelo em dados n\u00e3o vistos anteriormente a fim de identificar poss\u00edveis falhas no seu desenvolvimento e queda de desempenho ao longo do tempo. Nota Mesmo ap\u00f3s o deployment inicial, a manuten\u00e7\u00e3o de tanto o sistema quanto o modelo \u00e9 necess\u00e1ria. Portanto, \u00e9 comum reexecutarmos etapas anteriores frequentemente. Entramos em mais detalhes sobre implanta\u00e7\u00e3o, serving e monitoramento nas se\u00e7\u00f5es Implanta\u00e7\u00e3o , Model Serving e Monitoramento , respectivamente. Refer\u00eancias \u00b6 Designing Machine Learning Systems by Chip Huyen Machine Learning Engineering by Andriy Burkov Introduction to Machine Learning in Production by Coursera An Overview of the End-to-End Machine Learning Workflow by MLOps ML Life Cycle by ProductizeML","title":"Sobre Machine Learning Engineering"},{"location":"concepts/machine_learning_engineering/#sobre-machine-learning-engineering","text":"","title":"Sobre Machine Learning Engineering"},{"location":"concepts/machine_learning_engineering/#introducao","text":"Projetar, construir e manter solu\u00e7\u00f5es de machine learning n\u00e3o s\u00e3o tarefas f\u00e1ceis. Muito pelo contr\u00e1rio! S\u00e3o complexas e exigem melhorias cont\u00ednuas. De acordo com o relat\u00f3rio \"2020 State of Enterprise Machine Learning\" da Algorithmia. A maior parte das empresas ainda n\u00e3o descobriram como atingir seus objetivos de ML/IA pois a lacuna entre a constru\u00e7\u00e3o do modelo de ML e o deploy \u00e9 desafiadora. Apenas 22% das companhias que usam aprendizado de m\u00e1quina implantaram com sucesso um modelo de ML em produ\u00e7\u00e3o. E isso ocorre pois apenas uma pequena fra\u00e7\u00e3o dos sistemas de ML do mundo real s\u00e3o compostos por c\u00f3digo de ML . Um sistema em produ\u00e7\u00e3o \u00e9 composto de diversos componentes , como, por exemplo: interfaces para que usu\u00e1rios e desenvolvedores interajam com o sistema, infraestrutura para executar a aplica\u00e7\u00e3o, engenharia e governan\u00e7a de dados para o gerenciamento e confiabilidade dos dados, entre outros. Fonte: Sculley, David, et al. \"Hidden technical debt in machine learning systems.\" Advances in neural information processing systems 28 (2015): 2503-2511. Al\u00e9m disso, considerando a escala de muitos sistemas de ML que \\(-\\) consumem grandes quantidades de dados, exigem um grande recurso computacional e afeta milhares de vidas \\(-\\) a simples necessidade de coloc\u00e1-lo em produ\u00e7\u00e3o j\u00e1 \u00e9 um grande desafio de engenharia e social. Como diz nossa querida Chip Huyen: Cita\u00e7\u00e3o \"Quando este desafio n\u00e3o \u00e9 bem compreendido, o sistema de ML pode causar grandes preju\u00edzos tanto \u00e0 companhia quanto a vida das pessoas.\" \\(-\\) Chip Huyen Portanto, precisamos de um conjunto de pr\u00e1ticas e processos eficazes para projetar, construir, implantar e manter modelos de ML em produ\u00e7\u00e3o de forma escal\u00e1vel e confi\u00e1vel . Andriy Burkov define machine learning engineering como a \u00e1rea respons\u00e1vel pela produtiza\u00e7\u00e3o, operacionaliza\u00e7\u00e3o e manuten\u00e7\u00e3o de sistemas de ML, sendo a defini\u00e7\u00e3o: Defini\u00e7\u00e3o de Machine Learning Engineering \"Machine learning engineering \u00e9 o uso de princ\u00edpios cient\u00edficos, ferramentas e t\u00e9cnicas de aprendizado de m\u00e1quina e engenharia de software tradicional para projetar e construir sistemas de computa\u00e7\u00e3o complexos. O MLE abrange todas as etapas, desde a coleta de dados, at\u00e9 a constru\u00e7\u00e3o do modelo, a fim de disponibilizar o modelo para uso pelo produto ou consumidores.\" \\(\u2014\\) Andriy Burkov Por\u00e9m, h\u00e1 pessoas que dizem que MLOps \u00e9 a \u00e1rea respons\u00e1vel por lidar com modelos em produ\u00e7\u00e3o, sendo MLOps definido pela MLOps SIG como: Defini\u00e7\u00e3o de MLOps \"A extens\u00e3o da metodologia DevOps para incluir ativos de aprendizado de m\u00e1quina e ci\u00eancia de dados como cidad\u00e3os de primeira classe dentro da ecologia DevOps.\" Contudo, independente do termo utilizado (MLOps ou MLE) , o que importa \u00e9 o objetivo da \u00e1rea de fornecer um processo para o projeto e desenvolvimento de sistemas baseados em machine learning que sejam reprodut\u00edveis, escal\u00e1veis e robustos. Aqui , MLOps estar\u00e1 restrito a tarefas relacionadas a operacionaliza\u00e7\u00e3o dos modelos de ML. Demais tarefas correspondentes a outras etapas de um projeto de ML ter\u00e3o pr\u00e1ticas classificadas como pertencentes a \u00e1rea machine learning engineering . Sistema x Aplica\u00e7\u00e3o Embora eu j\u00e1 tenha escrito \"sistema\", \"sistema\" e \"sistema\", n\u00e3o deixei claro sobre o que eu estou falando. O que \u00e9 um sistema de ML? \u00c9 a aplica\u00e7\u00e3o? Ou a solu\u00e7\u00e3o de ML que a aplica\u00e7\u00e3o usa? E essa solu\u00e7\u00e3o de ML... Usa alguma plataforma de ML para auxiliar na produ\u00e7\u00e3o de modelos? Se sim, a plataforma \u00e9 o sistema de ML? No caso, h\u00e1 pessoas que consideram aplica\u00e7\u00f5es baseadas em ML (i.e. que usam recursos de ML em algum momento, como uma aplica\u00e7\u00e3o que usa algoritmos de recomenda\u00e7\u00e3o) e sistemas de ML como a mesma coisa. Por\u00e9m, \"sistemas de ML\" n\u00e3o me parece transmitir bem essa ideia. Ent\u00e3o, vamos considerar aqui que um sistema de ML \u00e9 qualquer aplica\u00e7\u00e3o ou solu\u00e7\u00e3o que possui alguma depend\u00eancia com algoritmos de ML e, portanto, necessitam de pr\u00e1ticas espec\u00edficas para ML. Ainda, tamb\u00e9m vamos dizer que uma plataforma de ML \u00e9 uma aplica\u00e7\u00e3o que fornece um conjunto de recursos a execu\u00e7\u00e3o de pr\u00e1ticas MLOps.","title":"Introdu\u00e7\u00e3o"},{"location":"concepts/machine_learning_engineering/#machine-learning-na-industria","text":"Muitas pessoas possuem o senso comum de que: O desenvolvimento de algoritmos e sistemas de ML \u00e9 o mesmo tanto na ind\u00fastria quanto na academia Desenvolver aplica\u00e7\u00f5es baseadas em ML \u00e9 o mesmo que desenvolver softwares tradicionais. Essa perspectiva n\u00e3o apenas est\u00e1 errada, como tamb\u00e9m \u00e9 perigosa. Sistemas de ML possuem diversos desafios pr\u00f3prios e, como j\u00e1 dito anteriormente, n\u00e3o compreender tais desafios pode levar a consequ\u00eancias ruins .","title":"Machine Learning na Ind\u00fastria"},{"location":"concepts/machine_learning_engineering/#ml-na-pesquisa-x-ml-na-industria-mercado","text":"O desenvolvimento de modelos de ML na academia possui um prop\u00f3sito diferente quando comparado com a ind\u00fastria. Na academia, (geralmente) estamos preocupados em alcan\u00e7ar o estado-da-arte (SOTA, do ingl\u00eas state-of-the-art) em um determinado problema. Por conta disso, \u00e9 muito comum que os modelos resultantes sejam custosos demais para serem utilizados na ind\u00fastria. Modelos com bilh\u00f5es de par\u00e2metros, por exemplo, s\u00e3o extremamente custosos para treinar e operacionalizar. Dependendo de onde ser\u00e1 feita a sua implanta\u00e7\u00e3o (e.g. dispositivo m\u00f3vel), o uso de algo t\u00e3o complexo \u00e9 invi\u00e1vel. Nota Eventualmente os \"big models\" v\u00e3o se tornar menores e mais r\u00e1pidos. Por\u00e9m, a diferen\u00e7a de prioridades entre a academia e ind\u00fastria raramente ir\u00e1 permitir que os m\u00e9todos SOTA sejam utilizados em produ\u00e7\u00e3o. Ainda, em projetos de pesquisa \u00e9 muito comum que os dados sejam algum \"benchmarking\". Logo, s\u00e3o dados geralmente limpos e que permitem o foco total no desenvolvimento de modelos de aprendizado. Por outro lado, sistemas em produ\u00e7\u00e3o precisam lidar com falta de dados, dados desorganizados, ru\u00eddosos e que mudam constantemente. De fato, tanto os objetivos quanto os desafios s\u00e3o consideralvemente diferentes em cada contexto. Contudo, ainda assim \u00e9 muito comum os profissionais de dados focarem unicamente no desenvolvimento do modelo e encarar com menor import\u00e2ncia as demais tarefas. Esta atitude \u00e9 um exemplo de quando o desafio de colocar sistemas de ML em produ\u00e7\u00e3o n\u00e3o \u00e9 bem compreendido.","title":"ML na Pesquisa x ML na Ind\u00fastria (Mercado)"},{"location":"concepts/machine_learning_engineering/#softwares-tradicionais-x-sistemas-de-ml","text":"Diferente de softwares tradicionais, sistemas de ML n\u00e3o compreendem apenas c\u00f3digo, mas tamb\u00e9m dados e modelos. A adi\u00e7\u00e3o de mais dois artefatos torna o desenvolvimento de aplica\u00e7\u00f5es baseadas em ML significativamente mais complexo, pois al\u00e9m de testar e versionar c\u00f3digos, temos que testar e versionar dados e modelos. Consequentemente, desafios \u00fanicos ao projeto de sistemas de ML surgem, desde etapas como desenvolvimento, at\u00e9 o teste, integra\u00e7\u00e3o, compila\u00e7\u00e3o e monitoramento do sistema.","title":"Softwares Tradicionais x Sistemas de ML"},{"location":"concepts/machine_learning_engineering/#etapas-de-um-projeto-de-ml","text":"O projeto de um sistema de ML \u00e9 processo formado por v\u00e1rias etapas que partem desde a concep\u00e7\u00e3o at\u00e9 a manuten\u00e7\u00e3o da solu\u00e7\u00e3o encontrada. Este processo \\(-\\) tamb\u00e9m chamado de ciclo de vida \\(-\\) \u00e9 composto por quatro etapas principais (que por sua vez, podem ser divididas em mais etapas). S\u00e3o elas: Escopo Prepara\u00e7\u00e3o dos Dados Modelagem Implanta\u00e7\u00e3o (do ingl\u00eas, deployment). Not so shallow... Al\u00e9m de descritas abaixo, cada uma dessas etapas cont\u00e9m se\u00e7\u00f5es particulares onde s\u00e3o abordadas com mais detalhes, incluindo estrat\u00e9gias sobre o que fazer em cada momento da etapa e como fazer. A gra\u00e7a do mundo est\u00e1 na diversidade O ciclo de vida apresentado aqui \u00e9 o considerado por Andrew Ng. No entanto, h\u00e1 diversas figuras importantes na \u00e1rea de ML com perspectivas diferentes sobre o ciclo de vida e suas etapas. Por exemplo, este ciclo de vida pode transmitir uma no\u00e7\u00e3o de ser algo direto e n\u00e3o repetitivo. Por\u00e9m, muito pelo contr\u00e1rio, na pr\u00e1tica o processo de cria\u00e7\u00e3o de um modelo de ML \u00e9 extremamente iterativo, ciclo e dificilmente termina. Afinal, uma vez que o modelo est\u00e1 em produ\u00e7\u00e3o, precisamos mant\u00ea-lo! Consequentemente, temos que desenvolver toda uma estrutura para que isso seja feito da forma mais din\u00e2mica poss\u00edvel. Nesse sentido, prepara\u00e7\u00e3o de dados \u00e9 a etapa onde toda a arquitetura de dados para o projeto \u00e9 definida, por exemplo.","title":"Etapas de um Projeto de ML"},{"location":"concepts/machine_learning_engineering/#escopo","text":"O escopo \u00e9 a etapa onde o projeto \u00e9 definido. Logo: Qual problema ser\u00e1 atacado Como o problema ser\u00e1 atacado Qual o crit\u00e9rio de sucesso Os principais objetivos desta etapa s\u00e3o identificar o que deve ser feito e o qu\u00e3o vi\u00e1vel \u00e9 o que deve ser. Assim, \u00e9 muito importante que o objetivo do projeto seja claro e bem definido. Perguntas que podem nos ajudar a definir o objetivo do projeto s\u00e3o: Qual \u00e9 o problema que queremos resolver usando ML? Por que queremos aplicar ML? Quais s\u00e3o as entradas que ser\u00e3o consumidas pelo modelo? Quais as sa\u00eddas que devem ser geradas pelo modelo? Quais m\u00e9tricas e crit\u00e9rios definem o sucesso do modelo? Quais m\u00e9tricas e crit\u00e9rios definem o sucesso do projeto? Nota O objetivo do modelo n\u00e3o necessariamente precisa ser o mesmo objetivo do ponto de vista de neg\u00f3cios (ou seja, o que o cliente busca alcan\u00e7ar). Por exemplo, uma empresa de e-commerce pode ter como objetivo maximizar os lucros com base no pre\u00e7o dos produtos. J\u00e1 o modelo pode ter como objetivo encontrar o pre\u00e7o de um conjunto de produtos que maximize a probabilidade de compra conjunta destes produtos. Outra pr\u00e1tica comum que pode nos ajudar a definir o escopo do projeto com mais rigor (tal como sua execu\u00e7\u00e3o) \u00e9 o uso de Canvas, como o ML Canvas .","title":"Escopo"},{"location":"concepts/machine_learning_engineering/#risco-e-impacto-do-projeto","text":"Uma vez definido o que deve ser feito, \u00e9 comum avaliarmos a viabilidade do projeto atrav\u00e9s de estimativas de riscos e impacto. At\u00e9 o momento n\u00e3o existem m\u00e9todos de estima\u00e7\u00e3o de complexidade de um projeto de ML que s\u00e3o amplamente utilizados pela ind\u00fastria. Ainda, projetos de ML s\u00e3o incertos por natureza uma vez que nem sempre os recursos necess\u00e1rios para a solu\u00e7\u00e3o do problema existem ou s\u00e3o vi\u00e1veis. Por exemplo, \u00e9 dif\u00edcil definir com precis\u00e3o quais ser\u00e3o os dados necess\u00e1rios, a quantidade de dados necess\u00e1rios, se os modelos existentes na literatura resolvem o problema em quest\u00e3o, etc. Portanto, o uso de modelos de risco-impacto \u00e9 uma abordagem segura e efetiva. Um exemplo de modelo de risco-impacto para projetos de ML \u00e9 o apresentado na figura abaixo. Fonte: Business Objectives \u2013 ML Life Cycle by ProductizeML","title":"Risco e Impacto do Projeto"},{"location":"concepts/machine_learning_engineering/#custos-do-projeto","text":"O custo de desenvolvimento e opera\u00e7\u00e3o de um projeto de ML \u00e9 um fator decisivo na balan\u00e7a de risco e impacto. De acordo com Andriy Burkov, h\u00e1 tr\u00eas fatores principais que influenciam consideravelmente o custo de um projeto de ML. Dificuldade do problema. Quanto maior a dificuldade do problema, maior o custo de execu\u00e7\u00e3o e engenharia. Perguntas que nos ajudam a identificar a dificuldade do problema s\u00e3o: H\u00e1 empresas que j\u00e1 resolveram o mesmo problema ou semelhante? H\u00e1 solu\u00e7\u00f5es para problemas parecidos na academia? H\u00e1 implementa\u00e7\u00f5es dispon\u00edveis de algoritmos capazes de resolver o problema em quest\u00e3o? O quanto de poder computacional \u00e9 necess\u00e1rio para construir e executar o modelo em produ\u00e7\u00e3o? Custo de aquisi\u00e7\u00e3o dos dados. Coletar a quantidade necess\u00e1ria dos dados corretos tende a ser custoso, principalmente se h\u00e1 necessidade de categoriza\u00e7\u00e3o manual dos dados. Perguntas que nos ajudam a identificar o custo de aquisi\u00e7\u00e3o dos dados s\u00e3o: Quais os dados necess\u00e1rios? Qual a quantidade de dados neces\u00e1rios? Os dados podem ser gerados automaticamente? \u00c9 necess\u00e1rio categorizar amostras? Se sim, quantas? Qual o custo? Necessidade de assertividade. Quanto maior a necessidade de assertividade do modelo, maior o custo associado (que crescer\u00e1 exponencialmente). Afinal, a assertividade de um modelo n\u00e3o depende apenas do modelo em si, mas tamb\u00e9m dos dados dispon\u00edveis (geralmente, quanto mais dados, melhor) e dificuldade do problema. Nota Novamente, aqui o uso de Canvas para ML tamb\u00e9m \u00e9 \u00fatil tanto para fazermos as perguntas certas quanto encontrarmos as respostas corretas e assim estimarmos custos com maior precis\u00e3o.","title":"Custos do Projeto"},{"location":"concepts/machine_learning_engineering/#definindo-baselines","text":"Do ponto de vista de um projeto de ML, uma baseline \u00e9 o desempenho base a partir do qual queremos melhorar. Portanto, antes de come\u00e7armos a implementarmos nossos pr\u00f3prios modelos, \u00e9 importante pesquisarmos solu\u00e7\u00f5es j\u00e1 existentes para o problema que queremos atacar (ou ent\u00e3o, semelhantes ao problema que queremos atacar). O Model Zoo , por exemplo, \u00e9 uma plataforma onde diversos modelos pr\u00e9-treinados (de deep learning) s\u00e3o disponibilizados, de forma que o desenvolver tenha apenas que \"plug\u00e1-lo\" no sistema ou processo de desenvolvimento.","title":"Definindo Baselines"},{"location":"concepts/machine_learning_engineering/#preparacao-dos-dados","text":"Esta \u00e9 a etapa onde os dados necess\u00e1rios para a execu\u00e7\u00e3o do projeto e constru\u00e7\u00e3o do modelo s\u00e3o coletados e processados. Note que a prepara\u00e7\u00e3o de dados \u00e9 absolutamente importante, visto que erros nos dados s\u00e3o propagados ao longo de todo o projeto, o que pode resultar em problemas cr\u00edticos. Al\u00e9m disso, a etapa de prepara\u00e7\u00e3o de dados \u00e9 (geralmente) composta pelas seguintes tarefas: Ingest\u00e3o de Dados. Coleta e armazenamento de dados oriundos de diversas fontes em diversos mecanismos de armazenamento, tais como Data Lakes e Data Warehouses. Essa etapa tamb\u00e9m pode incluir o enriquecimento de dados e/ou gera\u00e7\u00e3o de dados sint\u00e9ticos. Explora\u00e7\u00e3o e Valida\u00e7\u00e3o. Perfilamento de dados a fim de obter informa\u00e7\u00f5es sobre sua estrutura que, por sua vez, s\u00e3o utilizadas para definir poss\u00edveis esquemas de dados, assim como rotinas de teste e valida\u00e7\u00e3o. Data Cleaning. Processo de formata\u00e7\u00e3o dos dados e corre\u00e7\u00e3o de erros (e.g. valores faltantes ou inconsistentes) de forma que se enquadrem nos esquemas definidos. Data Splitting. Divis\u00e3o do dados em conjuntos dedicados ao treinamento, valida\u00e7\u00e3o e teste dos modelos produzidos. Entramos em mais detalhes sobre a prepara\u00e7\u00e3o de dados na se\u00e7\u00e3o Prepara\u00e7\u00e3o de Dados .","title":"Prepara\u00e7\u00e3o dos Dados"},{"location":"concepts/machine_learning_engineering/#modelagem","text":"Esta \u00e9 a etapa onde os modelos cogitados para atacar o problema definido no escopo s\u00e3o treinados, testados, selecionados e reavaliados. As subetapas principais da etapa de modelagem s\u00e3o: Treinamento & Sele\u00e7\u00e3o de Modelos. Processo onde modelos s\u00e3o treinados e o melhor \\(-\\) com base em m\u00e9tricas de desempenho para a tarefa em quest\u00e3o (e.g. acur\u00e1cia, erro quadr\u00e1tico m\u00e9dio, etc) \\(-\\) \u00e9 selecionado como candidato \u00e0 produ\u00e7\u00e3o. Avalia\u00e7\u00e3o. Processo onde s\u00e3o executadas an\u00e1lises de erro a fim de verificar se o modelo \\(-\\) al\u00e9m de possuir boas m\u00e9tricas de desempenho (do ponto de vista de treinamento) \\(-\\) resolve o problema definido. Nesta etapa tamb\u00e9m \u00e9 comum avaliar um poss\u00edvel enviesamento do modelo, assim como requisitos n\u00e3o funcionais (e.g. tempo de infer\u00eancia, custo computacional, etc.) Al\u00e9m disso, \u00e9 neste momento que comparamos o modelo constru\u00eddo com poss\u00edveis baselines e analisamos quais pontos podem ser melhorados. Entramos em mais detalhes sobre o treinamento e avalia\u00e7\u00e3o de modelos nas se\u00e7\u00f5es Constru\u00e7\u00e3o de Modelos e Avalia\u00e7\u00e3o , respectivamente.","title":"Modelagem"},{"location":"concepts/machine_learning_engineering/#implantacao","text":"Etapa onde o modelo constru\u00eddo \u00e9 colocado em produ\u00e7\u00e3o. Logo, al\u00e9m das pr\u00e1ticas convencionais aplicadas no desenvolvimento de modelos de ML, durante o deployment (implanta\u00e7\u00e3o) pr\u00e1ticas de engenharia de software s\u00e3o aplicadas com mais intensidade, incluindo testes unit\u00e1rios e de integra\u00e7\u00e3o, integra\u00e7\u00e3o do modelo com o restante do sistema, defini\u00e7\u00e3o de pol\u00edticas de monitoramento, etc. A etapa de implanta\u00e7\u00e3o \u00e9 geralmente composta pelos seguintes processos: Model Serving. Processo de disponibiliza\u00e7\u00e3o do modelo em um ambiente de produ\u00e7\u00e3o para acesso pelos usu\u00e1rios. Monitoramento de Performance. Processo de monitoramento da performance do modelo em dados n\u00e3o vistos anteriormente a fim de identificar poss\u00edveis falhas no seu desenvolvimento e queda de desempenho ao longo do tempo. Nota Mesmo ap\u00f3s o deployment inicial, a manuten\u00e7\u00e3o de tanto o sistema quanto o modelo \u00e9 necess\u00e1ria. Portanto, \u00e9 comum reexecutarmos etapas anteriores frequentemente. Entramos em mais detalhes sobre implanta\u00e7\u00e3o, serving e monitoramento nas se\u00e7\u00f5es Implanta\u00e7\u00e3o , Model Serving e Monitoramento , respectivamente.","title":"Implanta\u00e7\u00e3o"},{"location":"concepts/machine_learning_engineering/#referencias","text":"Designing Machine Learning Systems by Chip Huyen Machine Learning Engineering by Andriy Burkov Introduction to Machine Learning in Production by Coursera An Overview of the End-to-End Machine Learning Workflow by MLOps ML Life Cycle by ProductizeML","title":"Refer\u00eancias"},{"location":"concepts/template/","text":"Work in progress","title":"Template"},{"location":"concepts/best_practices/good_practices/","text":"Work in progress","title":"Boas Pr\u00e1ticas em ML"},{"location":"concepts/data_preparation/","text":"Prepara\u00e7\u00e3o de Dados \u00b6 Work in progress","title":"Prepara\u00e7\u00e3o de Dados"},{"location":"concepts/data_preparation/#preparacao-de-dados","text":"Work in progress","title":"Prepara\u00e7\u00e3o de Dados"},{"location":"concepts/data_preparation/data_collection/","text":"Work in progress","title":"Coleta de Dados"},{"location":"concepts/data_preparation/data_processing/","text":"Work in progress","title":"Processamento de Dados"},{"location":"concepts/deployment/","text":"Implanta\u00e7\u00e3o \u00b6 Work in progress","title":"Implanta\u00e7\u00e3o"},{"location":"concepts/deployment/#implantacao","text":"Work in progress","title":"Implanta\u00e7\u00e3o"},{"location":"concepts/evaluation/","text":"Avalia\u00e7\u00e3o \u00b6 Work in progress","title":"Avalia\u00e7\u00e3o"},{"location":"concepts/evaluation/#avaliacao","text":"Work in progress","title":"Avalia\u00e7\u00e3o"},{"location":"concepts/mlops/","text":"MLOps \u00b6 Attention! Aten\u00e7\u00e3o! (en_US) This post is a translation (into pt_BR) of my post Introducing MLOps originally published on Daitan's blog. (pt_BR) Esta publica\u00e7\u00e3o \u00e9 uma tradu\u00e7\u00e3o (para pt_BR) do meu artigo Introducing MLOps publicado originalmente no blog da Daitan . Ci\u00eancia de dados e aprendizado de m\u00e1quina (ML, do ingl\u00eas machine learning) t\u00eam se tornado estrat\u00e9gias priorit\u00e1rias na resolu\u00e7\u00e3o de diversos problemas complexos do mundo real. Por\u00e9m, embora implementar e treinar modelos de ML n\u00e3o sejam tarefas triviais, ainda assim O verdadeiro desafio n\u00e3o \u00e9 construir modelos de ML O verdadeiro desafio \u00e9 construir sistemas de ML integrados e que podem ser atulizados e operados continuamente em produ\u00e7\u00e3o. Afinal, para tirarmos m\u00e1ximo proveito de um modelo ML, precisamos coloc\u00e1-lo em produ\u00e7\u00e3o. Contudo, de acordo com o relat\u00f3rio \"2020 State of Enterprise Machine Learning\" da Algorithmia. A maior parte das empresas ainda n\u00e3o descobriram como atingir seus objetivos de ML/IA pois a lacuna entre a constru\u00e7\u00e3o do modelo de ML e o deploy \u00e9 desafiadora. Apenas 22% das companhias que usam aprendizado de m\u00e1quina implantaram com sucesso um modelo de ML em produ\u00e7\u00e3o. Ao mesmo tempo, a pr\u00f3pria constru\u00e7\u00e3o do modelo e avalia\u00e7\u00e3o deste em escala \u00e9 uma tarefa complicada. Em aplica\u00e7\u00f5es do \"mundo real\", avaliar o desempenho e impacto do modelo no problema que se busca resolver vai muito al\u00e9m de uma simples experimenta\u00e7\u00e3o de \"treino e teste\" . Tamb\u00e9m \u00e9 necess\u00e1rio levar em conta quest\u00f5es como complexidade do algoritmo, velocidade de infer\u00eancia e enviesamento. Al\u00e9m disso, de acordo com o artigo \"Hidden Technical Debt in Machine Learning Systems\" Apenas uma pequena fra\u00e7\u00e3o dos sistemas de ML do mundo real \u00e9 composta por c\u00f3digo de ML, enquanto que a infraestrutura envolvente necess\u00e1ria \u00e9 vasta e complexa. Fonte: Sculley, David, et al. \"Hidden technical debt in machine learning systems.\" Advances in neural information processing systems 28 (2015): 2503-2511. Portanto, \u00e9 necess\u00e1rio estabelecer um conjunto de pr\u00e1ticas e processos eficazes para projetar, construir e implantar modelos de ML em produ\u00e7\u00e3o. Defini\u00e7\u00f5es \u00b6 De acordo com a MLOps SIG , MLOps \u00e9: Cita\u00e7\u00e3o \"A extens\u00e3o da metodologia DevOps para incluir ativos de aprendizado de m\u00e1quina e ci\u00eancia de dados como cidad\u00e3os de primeira classe dentro da ecologia DevOps.\" Por\u00e9m, como uma \u00e1rea em ascens\u00e3o, o termo MLOps n\u00e3o \u00e9 estritamente definido, especialmente quando comparado com machine learning engineering (MLE). Portanto, a defini\u00e7\u00e3o de Andriy Burkov sobre MLE tamb\u00e9m \u00e9 aplic\u00e1vel \u00e0 MLOps, onde Cita\u00e7\u00e3o \"Machine learning engineering \u00e9 o uso de princ\u00edpios cient\u00edficos, ferramentas e t\u00e9cnicas de aprendizado de m\u00e1quina e engenharia de software tradicional para projetar e construir sistemas de computa\u00e7\u00e3o complexos. O MLE abrange todas as etapas, desde a coleta de dados, at\u00e9 a constru\u00e7\u00e3o do modelo, a fim de disponibilizar o modelo para uso pelo produto ou consumidores.\" \\(\u2014\\) Andriy Burkov Assim, independente do termo utilizado (MLOps e MLE), o que importa \u00e9 o objetivo da \u00e1rea de fornecer um processo de projeto e desenvolvimento de sistemas baseados em machine learning que sejam reprodut\u00edveis, escal\u00e1veis e robustos. Benef\u00edcios do MLOps \u00b6 Como dito, MLOps tem como objetivo fornecer um conjunto de pr\u00e1ticas e processos eficazes para projetar, construir e implantar modelos escal\u00e1veis de ML em produ\u00e7\u00e3o. Isso pode ser alcan\u00e7ado ao garantir capacidades e qualidades fundamentais, tanto para a aplica\u00e7\u00e3o quanto para o projeto em si. Alguns exemplos s\u00e3o: Redu\u00e7\u00e3o do d\u00e9bito t\u00e9cnico ao longo do projeto de ML. Aplica\u00e7\u00e3o de Princ\u00edpios \u00c1geis ao projeto de ML. Garantia de reprodutibilidade. Versionamento de dados, pipelines e modelos. Teste automatizando de artefatos de ML. 1 Monitoramento de performance dos modelos em produ\u00e7\u00e3o. Suporte a CI/CD para artefatos de ML, incluindo dados. Suporte a CT (Continuous training) para modelos e pipelines. Unifica\u00e7\u00e3o do ciclo de entrega tanto para os modelos quanto para toda a aplica\u00e7\u00e3o. Escalabilidade, alta disponibilidade, toler\u00e2ncia \u00e0 falhas, equidade e seguran\u00e7a no contexto de ML. Note que a partir dessas capacidades, mais benef\u00edcios surgem, como velocidade no processo de introdu\u00e7\u00e3o dos modelos \u00e0 produ\u00e7\u00e3o, custo reduzido de desenvolvimento e opera\u00e7\u00f5es (em n\u00edvel empresariaral), mitiga\u00e7\u00e3o de riscos associados ao projeto, etc. Pr\u00e1ticas Fundamentais \u00b6 No mundo de MLOps, novas tend\u00eancias e pr\u00e1ticas surgem o tempo todo. Por\u00e9m, h\u00e1 algumas pr\u00e1ticas essenciais que fazem parte do cora\u00e7\u00e3o do MLOps. Tais pr\u00e1ticas s\u00e3o obrigat\u00f3rias para se alcan\u00e7ar um processo de desenvolvimento de sistemas baseados em ML poderoso. Al\u00e9m disso, cada uma dessas pr\u00e1ticas podem ser estendidas e melhoradas. Controle de Vers\u00e3o \u00b6 Diferente do desenvolvimento convencional de software, aplica\u00e7\u00f5es baseadas em ML possuem tr\u00eas artefatos que devem ser trabalhados: dado, modelo e c\u00f3digo 2 . A pr\u00e1tica de versionar dado, modelo e c\u00f3digo \u00e9 uma extremamente importante no \u00e2mbito de MLOps, visto que a partir do versionamento \u00e9 poss\u00edvel melhorar a reprodutibilidade e garantir manutenibilidade, preven\u00e7\u00e3o de erros e recupera\u00e7\u00e3o de desastres para todo o projeto. Por exemplo, pode haver situa\u00e7\u00f5es onde a atualiza\u00e7\u00e3o de um modelo em produ\u00e7\u00e3o prejudica a performance da aplica\u00e7\u00e3o como um todo. Assim, \u00e9 necess\u00e1rio reverter o modelo (i.e. rollback) para uma vers\u00e3o anterior de modo autom\u00e1tico. Outro caso \u00e9 a necessidade de um tracking pesado de altera\u00e7\u00f5es, uma vez que tanto o dado quanto o modelo s\u00e3o atualizados frequentemente de forma autom\u00e1tica. Assim, o versionamento de artefatos em projetos de ML permite: Manter tanto altera\u00e7\u00f5es no modelo quanto no dado rastreadas, possibilitando identificar inser\u00e7\u00e3o de bugs ou mudan\u00e7as que ferem a performance da aplica\u00e7\u00e3o. Reverter a vers\u00e3o do modelo para uma vers\u00e3o anterior no caso de releases quebradas (ou que podem vir a quebrar em produ\u00e7\u00e3o). Automatizar todo o pipeline de ML atrav\u00e9s de CI/CD e CT. Rastreamento de Experimentos \u00b6 Devido a natureza experimental e iterativa de modelos de ML, manter um rastreamento sistem\u00e1\u00feico de todas as informa\u00e7\u00f5es relacionadas aos experimentos \u00e9 essencial. Basicamente, o rastreio de experimentos \u00e9 a pr\u00e1tica de salvar (i.e. \"loggar\") todas as informa\u00e7\u00f5es importantes relacionadas aos dados, modelo e c\u00f3digo de cada itera\u00e7\u00e3o do experimento executado, de forma que seja poss\u00edvel se ter um conhecimento completo de cada informa\u00e7\u00e3o gerada e o controle total sobre todas as modifica\u00e7\u00f5es realizadas. Por exemplo, ao desenvolvermos um modelo, podemos querer rastrear (e versionar) em cada itera\u00e7\u00e3o de um experimento: Scripts (c\u00f3digo-fonte) usado. Arquivos de configura\u00e7\u00e3o. Dados e metadados utilizados para o treinamento, valida\u00e7\u00e3o e teste. Par\u00e2metros e hiperpar\u00e2metros do modelo. Resultados das m\u00e9tricas de avalia\u00e7\u00e3o do modelo. Resultados das m\u00e9tricas de performance da aplica\u00e7\u00e3o. Uma vez tendo essas informa\u00e7\u00f5es, podemos comparar os diferentes resultados alcan\u00e7ados, identificar o impacto de cada altera\u00e7\u00e3o no resultado final, identificar problemas de performance do sistema, etc. Portanto, a pr\u00e1tica de rastrear os experimentos \u00e9 fundamental tanto para a reprodutiblidade (de fato, \u00e9 a principal forma de alcan\u00e7\u00e1-la) quanto para o desenvolvimento da aplica\u00e7\u00e3o em si. Pipelines de ML Automatizados \u00b6 A automa\u00e7\u00e3o \u00e9 outra pr\u00e1tica fundamental em MLOps. No contexto de ML, a automa\u00e7\u00e3o consiste em automatizar todos os pipelines do workflow de ML, incluindo pipelines de dados, constru\u00e7\u00e3o de modelos e integra\u00e7\u00e3o de c\u00f3digo a fim de que todo o processo seja executado sem qualquer interven\u00e7\u00e3o humana. Com isso: Os experimentos acontecem de forma mais r\u00e1pida e com uma maior prontid\u00e3o para mover todo o pipeline do desenvolvimento \u00e0 produ\u00e7\u00e3o. Os modelos em produ\u00e7\u00e3o s\u00e3o automaticamente retreinados por meio dos dados atualizados (onde, o retreinamento \u00e9 automaticamente ativado atrav\u00e9s de triggers ). O pipeline implementado no ambiente de desenvolvimento \u00e9 correspondente ao utilizado nos ambientes de (pr\u00e9-)produ\u00e7\u00e3o. O pipeline em produ\u00e7\u00e3o est\u00e1 sempre atualizado, uma vez que a etapa de deployment do modelo tamb\u00e9m \u00e9 automatizado. Logo, considerando um pipeline t\u00edpico de ML, que parte da coleta de dados at\u00e9 a disponibiliza\u00e7\u00e3o do modelo, podemos considerar (no geral) 3 n\u00edveis de automa\u00e7\u00e3o. N\u00edvel 1 - Processo Manual \u00b6 O N\u00edvel 1 (Processo Manual) \u00e9 o processo tradicional de ci\u00eancia de dados, onde cada etapa do pipeline \u00e9 executado usando ferramentas RAD (do ingl\u00eas, Rapid Application Development), como Jupyter Notebooks. Este n\u00edvel de automa\u00e7\u00e3o \u00e9 caracterizado principalmente pela natureza experimental e iterativa. Fonte: Example of a manual process. Adapted from: Google Cloud [4] N\u00edvel 2 - Pipeline de ML Automatizado \u00b6 O N\u00edvel 2 de automa\u00e7\u00e3o \u00e9 um n\u00edvel onde todo o processo de constru\u00e7\u00e3o \u00e0 valida\u00e7\u00e3o do modelo \u00e9 executado automaticamente conforme novos dados s\u00e3o disponibilizados ou o procedimento de retreino \u00e9 disparado (baseado em uma pol\u00edtica de agendamento ou threshold de performance). Assim, o objetivo e prover um processo treinamento cont\u00ednuo (CT, do ingl\u00eas continuous training) atrav\u00e9s da automatiza\u00e7\u00e3o de todo o pipeline de ML. Este n\u00edvel de automata\u00e7\u00e3o \u00e9 caracterizado por: Experimentos orquestrados 3 Modelos em produ\u00e7\u00e3o que s\u00e3o continuamente atualizados automaticamente. Etapas de teste e deployment ocorrem manualmente. Fonte: Example of an automated ML pipeline. Adapted from: Google Cloud [4] N\u00edvel 3 - Pipeline CI/CD \u00b6 No N\u00edvel 3 de automa\u00e7\u00e3o, todo o workflow ocorre automaticamente atrav\u00e9s de estrat\u00e9gias de CI/CD. Logo, diferente do anterior, as etapas de build, teste e deployment de cada um dos artefatos (dado, modelo e c\u00f3digo) tamb\u00e9m ocorrem automaticamente. Este n\u00edvel de automa\u00e7\u00e3o \u00e9 caracterizado por: Experimentos orquestrados Automa\u00e7\u00e3o completa de todo o pipeline de ML, incluindo build, teste e deployment de cada um dos artefatos relacionados ao pipeline. Fonte: Example of a CI/CD pipeline. Adapted from: Google Cloud [4] Pr\u00e1ticas Adicionais \u00b6 Teste Automatizados \u00b6 Conforme a automa\u00e7\u00e3o do sistema de ML se torna mais sofisticada, as rotinas de teste devem acompanhar a evolu\u00e7\u00e3o do sistema e passarem a ser executadas automaticamente. Portanto, al\u00e9m dos testes unit\u00e1rios e de integra\u00e7\u00e3o, devemos incluir testes espec\u00edficos tanto para os modelos quanto dados. Por exemplo, checar se: O modelo (em desenvolvimento e produ\u00e7\u00e3o) n\u00e3o est\u00e1 enviesado. O modelo (em produ\u00e7\u00e3o) n\u00e3o est\u00e1 obsoleto. O dado segue os esquemas definidos. Monitoramento \u00b6 Ap\u00f3s um modelo ir para produ\u00e7\u00e3o, ele precisa ser monitoramento a fim de garantir que funcione como o esperado. No contexto de pipelines de ML, o monitoramento \u00e9 um pr\u00e9-requisito para uma automa\u00e7\u00e3o apropriada. Em outras palavras, apenas atrav\u00e9s do monitoramento \u00e9 poss\u00edvel acompanhar a performance do modelo em produ\u00e7\u00e3o e automaticamente retrein\u00e1-lo quando ele se tornar obsoleto. Fonte: ML Model Decay Monitoring and Retraining. Source: https://ml-ops.org/ Feature Stores \u00b6 Uma Feature Store \u00e9 um servi\u00e7o centralizado de armazenamento e processamento de features atrav\u00e9s do qual as features s\u00e3o definidas, armazenadas e usadas tanto para o treinamento de modelos quanto para modelos em produ\u00e7\u00e3o. Desse modo, feature stores devem ser capazes de armazenar um grande volume de dados e fornecer acesso com baixa lat\u00eancia para as aplica\u00e7\u00f5es. Alguns benef\u00edcios de feature stores s\u00e3o: Reuso das features dispon\u00edveis atrav\u00e9s do compartilhamento do dado entre times e projetos (ao inv\u00e9s de recri\u00e1-las). Preven\u00e7\u00e3o de features semelhantes mas com defini\u00e7\u00f5es diferentes atrav\u00e9s da manuten\u00e7\u00e3o do pipeline de extra\u00e7\u00e3o de features e dos metadados relacionados. Disponibiliza\u00e7\u00e3o em escala e com baixa lat\u00eancia das feaures, principalmente para rotinas de retreinamento. Garantira de consist\u00eancia das features entre o processo de treinamento e deployment. Conclus\u00e3o \u00b6 Dado o crescente uso de ML em v\u00e1rios setores da ind\u00fastria e a necessidade por aplica\u00e7\u00f5es baseadas em ML manuten\u00edveis e escal\u00e1veis, a ado\u00e7\u00e3o da cultura de MLOps deve ser tornar um padr\u00e3o para todos aqueles que trabalham com IA ao longo dos pr\u00f3ximos anos. Afinal, MLOps tem se mostrado essencial em projetos de larga escala gra\u00e7as aos diversos benef\u00edcios indispens\u00e1veis que s\u00e3o gerados. Notas e Coment\u00e1rios \u00b6 Refer\u00eancias \u00b6 Sculley, David, et al. \u201cHidden technical debt in machine learning systems.\u201d Advances in neural information processing systems 28 (2015): 2503\u20132511. \"ML-Ops.org.\" MLOps, ml-ops.org/. Burkov, Andriy. Machine learning engineering. True Positive Incorporated, 2020. \"MLOps: Continuous Delivery and Automation Pipelines in Machine Learning.\" Google Cloud, cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning Breck, Eric, et al. \"The ml test score: A rubric for ml production readiness and technical debt reduction.\" 2017 IEEE International Conference on Big Data (Big Data). IEEE, 2017. Artefatos de ML s\u00e3o todos os (hiper)par\u00e2metros, scripts e dados de treinamento e teste utilizados para a constru\u00e7\u00e3o de um modelo. \u21a9 Dado compreende tanto o pipeline de dados quanto os dados utilizados para treinamento, valida\u00e7\u00e3o e teste. Modelo compreende todos os artefatos associados \u00e0 constru\u00e7\u00e3o do modelo. C\u00f3digo compreende tanto aos c\u00f3digos relacionados aos dados e modelo, quanto o c\u00f3digo-fonte da aplica\u00e7\u00e3o ao qual o modelo deve ser integrado. \u21a9 Experimentos orquestrados s\u00e3o aqueles cujas transi\u00e7\u00f5es entre cada etapa do experimento ocorre de maneira autom\u00e1tica e com um rastramento rigoroso. \u21a9","title":"MLOps"},{"location":"concepts/mlops/#mlops","text":"Attention! Aten\u00e7\u00e3o! (en_US) This post is a translation (into pt_BR) of my post Introducing MLOps originally published on Daitan's blog. (pt_BR) Esta publica\u00e7\u00e3o \u00e9 uma tradu\u00e7\u00e3o (para pt_BR) do meu artigo Introducing MLOps publicado originalmente no blog da Daitan . Ci\u00eancia de dados e aprendizado de m\u00e1quina (ML, do ingl\u00eas machine learning) t\u00eam se tornado estrat\u00e9gias priorit\u00e1rias na resolu\u00e7\u00e3o de diversos problemas complexos do mundo real. Por\u00e9m, embora implementar e treinar modelos de ML n\u00e3o sejam tarefas triviais, ainda assim O verdadeiro desafio n\u00e3o \u00e9 construir modelos de ML O verdadeiro desafio \u00e9 construir sistemas de ML integrados e que podem ser atulizados e operados continuamente em produ\u00e7\u00e3o. Afinal, para tirarmos m\u00e1ximo proveito de um modelo ML, precisamos coloc\u00e1-lo em produ\u00e7\u00e3o. Contudo, de acordo com o relat\u00f3rio \"2020 State of Enterprise Machine Learning\" da Algorithmia. A maior parte das empresas ainda n\u00e3o descobriram como atingir seus objetivos de ML/IA pois a lacuna entre a constru\u00e7\u00e3o do modelo de ML e o deploy \u00e9 desafiadora. Apenas 22% das companhias que usam aprendizado de m\u00e1quina implantaram com sucesso um modelo de ML em produ\u00e7\u00e3o. Ao mesmo tempo, a pr\u00f3pria constru\u00e7\u00e3o do modelo e avalia\u00e7\u00e3o deste em escala \u00e9 uma tarefa complicada. Em aplica\u00e7\u00f5es do \"mundo real\", avaliar o desempenho e impacto do modelo no problema que se busca resolver vai muito al\u00e9m de uma simples experimenta\u00e7\u00e3o de \"treino e teste\" . Tamb\u00e9m \u00e9 necess\u00e1rio levar em conta quest\u00f5es como complexidade do algoritmo, velocidade de infer\u00eancia e enviesamento. Al\u00e9m disso, de acordo com o artigo \"Hidden Technical Debt in Machine Learning Systems\" Apenas uma pequena fra\u00e7\u00e3o dos sistemas de ML do mundo real \u00e9 composta por c\u00f3digo de ML, enquanto que a infraestrutura envolvente necess\u00e1ria \u00e9 vasta e complexa. Fonte: Sculley, David, et al. \"Hidden technical debt in machine learning systems.\" Advances in neural information processing systems 28 (2015): 2503-2511. Portanto, \u00e9 necess\u00e1rio estabelecer um conjunto de pr\u00e1ticas e processos eficazes para projetar, construir e implantar modelos de ML em produ\u00e7\u00e3o.","title":"MLOps"},{"location":"concepts/mlops/#definicoes","text":"De acordo com a MLOps SIG , MLOps \u00e9: Cita\u00e7\u00e3o \"A extens\u00e3o da metodologia DevOps para incluir ativos de aprendizado de m\u00e1quina e ci\u00eancia de dados como cidad\u00e3os de primeira classe dentro da ecologia DevOps.\" Por\u00e9m, como uma \u00e1rea em ascens\u00e3o, o termo MLOps n\u00e3o \u00e9 estritamente definido, especialmente quando comparado com machine learning engineering (MLE). Portanto, a defini\u00e7\u00e3o de Andriy Burkov sobre MLE tamb\u00e9m \u00e9 aplic\u00e1vel \u00e0 MLOps, onde Cita\u00e7\u00e3o \"Machine learning engineering \u00e9 o uso de princ\u00edpios cient\u00edficos, ferramentas e t\u00e9cnicas de aprendizado de m\u00e1quina e engenharia de software tradicional para projetar e construir sistemas de computa\u00e7\u00e3o complexos. O MLE abrange todas as etapas, desde a coleta de dados, at\u00e9 a constru\u00e7\u00e3o do modelo, a fim de disponibilizar o modelo para uso pelo produto ou consumidores.\" \\(\u2014\\) Andriy Burkov Assim, independente do termo utilizado (MLOps e MLE), o que importa \u00e9 o objetivo da \u00e1rea de fornecer um processo de projeto e desenvolvimento de sistemas baseados em machine learning que sejam reprodut\u00edveis, escal\u00e1veis e robustos.","title":"Defini\u00e7\u00f5es"},{"location":"concepts/mlops/#beneficios-do-mlops","text":"Como dito, MLOps tem como objetivo fornecer um conjunto de pr\u00e1ticas e processos eficazes para projetar, construir e implantar modelos escal\u00e1veis de ML em produ\u00e7\u00e3o. Isso pode ser alcan\u00e7ado ao garantir capacidades e qualidades fundamentais, tanto para a aplica\u00e7\u00e3o quanto para o projeto em si. Alguns exemplos s\u00e3o: Redu\u00e7\u00e3o do d\u00e9bito t\u00e9cnico ao longo do projeto de ML. Aplica\u00e7\u00e3o de Princ\u00edpios \u00c1geis ao projeto de ML. Garantia de reprodutibilidade. Versionamento de dados, pipelines e modelos. Teste automatizando de artefatos de ML. 1 Monitoramento de performance dos modelos em produ\u00e7\u00e3o. Suporte a CI/CD para artefatos de ML, incluindo dados. Suporte a CT (Continuous training) para modelos e pipelines. Unifica\u00e7\u00e3o do ciclo de entrega tanto para os modelos quanto para toda a aplica\u00e7\u00e3o. Escalabilidade, alta disponibilidade, toler\u00e2ncia \u00e0 falhas, equidade e seguran\u00e7a no contexto de ML. Note que a partir dessas capacidades, mais benef\u00edcios surgem, como velocidade no processo de introdu\u00e7\u00e3o dos modelos \u00e0 produ\u00e7\u00e3o, custo reduzido de desenvolvimento e opera\u00e7\u00f5es (em n\u00edvel empresariaral), mitiga\u00e7\u00e3o de riscos associados ao projeto, etc.","title":"Benef\u00edcios do MLOps"},{"location":"concepts/mlops/#praticas-fundamentais","text":"No mundo de MLOps, novas tend\u00eancias e pr\u00e1ticas surgem o tempo todo. Por\u00e9m, h\u00e1 algumas pr\u00e1ticas essenciais que fazem parte do cora\u00e7\u00e3o do MLOps. Tais pr\u00e1ticas s\u00e3o obrigat\u00f3rias para se alcan\u00e7ar um processo de desenvolvimento de sistemas baseados em ML poderoso. Al\u00e9m disso, cada uma dessas pr\u00e1ticas podem ser estendidas e melhoradas.","title":"Pr\u00e1ticas Fundamentais"},{"location":"concepts/mlops/#controle-de-versao","text":"Diferente do desenvolvimento convencional de software, aplica\u00e7\u00f5es baseadas em ML possuem tr\u00eas artefatos que devem ser trabalhados: dado, modelo e c\u00f3digo 2 . A pr\u00e1tica de versionar dado, modelo e c\u00f3digo \u00e9 uma extremamente importante no \u00e2mbito de MLOps, visto que a partir do versionamento \u00e9 poss\u00edvel melhorar a reprodutibilidade e garantir manutenibilidade, preven\u00e7\u00e3o de erros e recupera\u00e7\u00e3o de desastres para todo o projeto. Por exemplo, pode haver situa\u00e7\u00f5es onde a atualiza\u00e7\u00e3o de um modelo em produ\u00e7\u00e3o prejudica a performance da aplica\u00e7\u00e3o como um todo. Assim, \u00e9 necess\u00e1rio reverter o modelo (i.e. rollback) para uma vers\u00e3o anterior de modo autom\u00e1tico. Outro caso \u00e9 a necessidade de um tracking pesado de altera\u00e7\u00f5es, uma vez que tanto o dado quanto o modelo s\u00e3o atualizados frequentemente de forma autom\u00e1tica. Assim, o versionamento de artefatos em projetos de ML permite: Manter tanto altera\u00e7\u00f5es no modelo quanto no dado rastreadas, possibilitando identificar inser\u00e7\u00e3o de bugs ou mudan\u00e7as que ferem a performance da aplica\u00e7\u00e3o. Reverter a vers\u00e3o do modelo para uma vers\u00e3o anterior no caso de releases quebradas (ou que podem vir a quebrar em produ\u00e7\u00e3o). Automatizar todo o pipeline de ML atrav\u00e9s de CI/CD e CT.","title":"Controle de Vers\u00e3o"},{"location":"concepts/mlops/#rastreamento-de-experimentos","text":"Devido a natureza experimental e iterativa de modelos de ML, manter um rastreamento sistem\u00e1\u00feico de todas as informa\u00e7\u00f5es relacionadas aos experimentos \u00e9 essencial. Basicamente, o rastreio de experimentos \u00e9 a pr\u00e1tica de salvar (i.e. \"loggar\") todas as informa\u00e7\u00f5es importantes relacionadas aos dados, modelo e c\u00f3digo de cada itera\u00e7\u00e3o do experimento executado, de forma que seja poss\u00edvel se ter um conhecimento completo de cada informa\u00e7\u00e3o gerada e o controle total sobre todas as modifica\u00e7\u00f5es realizadas. Por exemplo, ao desenvolvermos um modelo, podemos querer rastrear (e versionar) em cada itera\u00e7\u00e3o de um experimento: Scripts (c\u00f3digo-fonte) usado. Arquivos de configura\u00e7\u00e3o. Dados e metadados utilizados para o treinamento, valida\u00e7\u00e3o e teste. Par\u00e2metros e hiperpar\u00e2metros do modelo. Resultados das m\u00e9tricas de avalia\u00e7\u00e3o do modelo. Resultados das m\u00e9tricas de performance da aplica\u00e7\u00e3o. Uma vez tendo essas informa\u00e7\u00f5es, podemos comparar os diferentes resultados alcan\u00e7ados, identificar o impacto de cada altera\u00e7\u00e3o no resultado final, identificar problemas de performance do sistema, etc. Portanto, a pr\u00e1tica de rastrear os experimentos \u00e9 fundamental tanto para a reprodutiblidade (de fato, \u00e9 a principal forma de alcan\u00e7\u00e1-la) quanto para o desenvolvimento da aplica\u00e7\u00e3o em si.","title":"Rastreamento de Experimentos"},{"location":"concepts/mlops/#pipelines-de-ml-automatizados","text":"A automa\u00e7\u00e3o \u00e9 outra pr\u00e1tica fundamental em MLOps. No contexto de ML, a automa\u00e7\u00e3o consiste em automatizar todos os pipelines do workflow de ML, incluindo pipelines de dados, constru\u00e7\u00e3o de modelos e integra\u00e7\u00e3o de c\u00f3digo a fim de que todo o processo seja executado sem qualquer interven\u00e7\u00e3o humana. Com isso: Os experimentos acontecem de forma mais r\u00e1pida e com uma maior prontid\u00e3o para mover todo o pipeline do desenvolvimento \u00e0 produ\u00e7\u00e3o. Os modelos em produ\u00e7\u00e3o s\u00e3o automaticamente retreinados por meio dos dados atualizados (onde, o retreinamento \u00e9 automaticamente ativado atrav\u00e9s de triggers ). O pipeline implementado no ambiente de desenvolvimento \u00e9 correspondente ao utilizado nos ambientes de (pr\u00e9-)produ\u00e7\u00e3o. O pipeline em produ\u00e7\u00e3o est\u00e1 sempre atualizado, uma vez que a etapa de deployment do modelo tamb\u00e9m \u00e9 automatizado. Logo, considerando um pipeline t\u00edpico de ML, que parte da coleta de dados at\u00e9 a disponibiliza\u00e7\u00e3o do modelo, podemos considerar (no geral) 3 n\u00edveis de automa\u00e7\u00e3o.","title":"Pipelines de ML Automatizados"},{"location":"concepts/mlops/#nivel-1-processo-manual","text":"O N\u00edvel 1 (Processo Manual) \u00e9 o processo tradicional de ci\u00eancia de dados, onde cada etapa do pipeline \u00e9 executado usando ferramentas RAD (do ingl\u00eas, Rapid Application Development), como Jupyter Notebooks. Este n\u00edvel de automa\u00e7\u00e3o \u00e9 caracterizado principalmente pela natureza experimental e iterativa. Fonte: Example of a manual process. Adapted from: Google Cloud [4]","title":"N\u00edvel 1 - Processo Manual"},{"location":"concepts/mlops/#nivel-2-pipeline-de-ml-automatizado","text":"O N\u00edvel 2 de automa\u00e7\u00e3o \u00e9 um n\u00edvel onde todo o processo de constru\u00e7\u00e3o \u00e0 valida\u00e7\u00e3o do modelo \u00e9 executado automaticamente conforme novos dados s\u00e3o disponibilizados ou o procedimento de retreino \u00e9 disparado (baseado em uma pol\u00edtica de agendamento ou threshold de performance). Assim, o objetivo e prover um processo treinamento cont\u00ednuo (CT, do ingl\u00eas continuous training) atrav\u00e9s da automatiza\u00e7\u00e3o de todo o pipeline de ML. Este n\u00edvel de automata\u00e7\u00e3o \u00e9 caracterizado por: Experimentos orquestrados 3 Modelos em produ\u00e7\u00e3o que s\u00e3o continuamente atualizados automaticamente. Etapas de teste e deployment ocorrem manualmente. Fonte: Example of an automated ML pipeline. Adapted from: Google Cloud [4]","title":"N\u00edvel 2 - Pipeline de ML Automatizado"},{"location":"concepts/mlops/#nivel-3-pipeline-cicd","text":"No N\u00edvel 3 de automa\u00e7\u00e3o, todo o workflow ocorre automaticamente atrav\u00e9s de estrat\u00e9gias de CI/CD. Logo, diferente do anterior, as etapas de build, teste e deployment de cada um dos artefatos (dado, modelo e c\u00f3digo) tamb\u00e9m ocorrem automaticamente. Este n\u00edvel de automa\u00e7\u00e3o \u00e9 caracterizado por: Experimentos orquestrados Automa\u00e7\u00e3o completa de todo o pipeline de ML, incluindo build, teste e deployment de cada um dos artefatos relacionados ao pipeline. Fonte: Example of a CI/CD pipeline. Adapted from: Google Cloud [4]","title":"N\u00edvel 3 - Pipeline CI/CD"},{"location":"concepts/mlops/#praticas-adicionais","text":"","title":"Pr\u00e1ticas Adicionais"},{"location":"concepts/mlops/#teste-automatizados","text":"Conforme a automa\u00e7\u00e3o do sistema de ML se torna mais sofisticada, as rotinas de teste devem acompanhar a evolu\u00e7\u00e3o do sistema e passarem a ser executadas automaticamente. Portanto, al\u00e9m dos testes unit\u00e1rios e de integra\u00e7\u00e3o, devemos incluir testes espec\u00edficos tanto para os modelos quanto dados. Por exemplo, checar se: O modelo (em desenvolvimento e produ\u00e7\u00e3o) n\u00e3o est\u00e1 enviesado. O modelo (em produ\u00e7\u00e3o) n\u00e3o est\u00e1 obsoleto. O dado segue os esquemas definidos.","title":"Teste Automatizados"},{"location":"concepts/mlops/#monitoramento","text":"Ap\u00f3s um modelo ir para produ\u00e7\u00e3o, ele precisa ser monitoramento a fim de garantir que funcione como o esperado. No contexto de pipelines de ML, o monitoramento \u00e9 um pr\u00e9-requisito para uma automa\u00e7\u00e3o apropriada. Em outras palavras, apenas atrav\u00e9s do monitoramento \u00e9 poss\u00edvel acompanhar a performance do modelo em produ\u00e7\u00e3o e automaticamente retrein\u00e1-lo quando ele se tornar obsoleto. Fonte: ML Model Decay Monitoring and Retraining. Source: https://ml-ops.org/","title":"Monitoramento"},{"location":"concepts/mlops/#feature-stores","text":"Uma Feature Store \u00e9 um servi\u00e7o centralizado de armazenamento e processamento de features atrav\u00e9s do qual as features s\u00e3o definidas, armazenadas e usadas tanto para o treinamento de modelos quanto para modelos em produ\u00e7\u00e3o. Desse modo, feature stores devem ser capazes de armazenar um grande volume de dados e fornecer acesso com baixa lat\u00eancia para as aplica\u00e7\u00f5es. Alguns benef\u00edcios de feature stores s\u00e3o: Reuso das features dispon\u00edveis atrav\u00e9s do compartilhamento do dado entre times e projetos (ao inv\u00e9s de recri\u00e1-las). Preven\u00e7\u00e3o de features semelhantes mas com defini\u00e7\u00f5es diferentes atrav\u00e9s da manuten\u00e7\u00e3o do pipeline de extra\u00e7\u00e3o de features e dos metadados relacionados. Disponibiliza\u00e7\u00e3o em escala e com baixa lat\u00eancia das feaures, principalmente para rotinas de retreinamento. Garantira de consist\u00eancia das features entre o processo de treinamento e deployment.","title":"Feature Stores"},{"location":"concepts/mlops/#conclusao","text":"Dado o crescente uso de ML em v\u00e1rios setores da ind\u00fastria e a necessidade por aplica\u00e7\u00f5es baseadas em ML manuten\u00edveis e escal\u00e1veis, a ado\u00e7\u00e3o da cultura de MLOps deve ser tornar um padr\u00e3o para todos aqueles que trabalham com IA ao longo dos pr\u00f3ximos anos. Afinal, MLOps tem se mostrado essencial em projetos de larga escala gra\u00e7as aos diversos benef\u00edcios indispens\u00e1veis que s\u00e3o gerados.","title":"Conclus\u00e3o"},{"location":"concepts/mlops/#notas-e-comentarios","text":"","title":"Notas e Coment\u00e1rios"},{"location":"concepts/mlops/#referencias","text":"Sculley, David, et al. \u201cHidden technical debt in machine learning systems.\u201d Advances in neural information processing systems 28 (2015): 2503\u20132511. \"ML-Ops.org.\" MLOps, ml-ops.org/. Burkov, Andriy. Machine learning engineering. True Positive Incorporated, 2020. \"MLOps: Continuous Delivery and Automation Pipelines in Machine Learning.\" Google Cloud, cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning Breck, Eric, et al. \"The ml test score: A rubric for ml production readiness and technical debt reduction.\" 2017 IEEE International Conference on Big Data (Big Data). IEEE, 2017. Artefatos de ML s\u00e3o todos os (hiper)par\u00e2metros, scripts e dados de treinamento e teste utilizados para a constru\u00e7\u00e3o de um modelo. \u21a9 Dado compreende tanto o pipeline de dados quanto os dados utilizados para treinamento, valida\u00e7\u00e3o e teste. Modelo compreende todos os artefatos associados \u00e0 constru\u00e7\u00e3o do modelo. C\u00f3digo compreende tanto aos c\u00f3digos relacionados aos dados e modelo, quanto o c\u00f3digo-fonte da aplica\u00e7\u00e3o ao qual o modelo deve ser integrado. \u21a9 Experimentos orquestrados s\u00e3o aqueles cujas transi\u00e7\u00f5es entre cada etapa do experimento ocorre de maneira autom\u00e1tica e com um rastramento rigoroso. \u21a9","title":"Refer\u00eancias"},{"location":"concepts/mlops/experiment_tracking/","text":"Rastreamento e Versionamento de Experimentos \u00b6 Introdu\u00e7\u00e3o \u00b6 Uma pr\u00e1tica extremamente importante nos projetos de ML \u00e9 o rastreamento dos experimentos, tal como o versionamento do c\u00f3digo e artefatos produzidos pelo experimento. Ao rastrear e versionar os experimentos, conseguimos: Acompanhar os resultados de diferentes itera\u00e7\u00f5es de um experimento, visto que cada itera\u00e7\u00e3o retornar\u00e1 valores de m\u00e9tricas diferentes. Acompanhar os resultados alcan\u00e7ados por cada (hiper)par\u00e2metro. Registrar, para cada itera\u00e7\u00e3o, o c\u00f3digo do experimento, assim como os artefatos (i.e. modelo e dados utilizados para construir o modelo). Manter rastreada a exata vers\u00e3o do c\u00f3digo de uma itera\u00e7\u00e3o, tal como o dado e modelo resultante desta vers\u00e3o. Basicamente, o rastreio de experimentos \u00e9 a pr\u00e1tica de salvar (i.e. \"loggar\") todas as informa\u00e7\u00f5es importantes relacionadas aos dados, modelo e c\u00f3digo de cada itera\u00e7\u00e3o do experimento executado, de forma que seja poss\u00edvel se ter um conhecimento completo de cada informa\u00e7\u00e3o gerada e o controle total sobre todas as modifica\u00e7\u00f5es realizadas. Por exemplo, ao desenvolvermos um modelo, podemos querer rastrear (e versionar) em cada itera\u00e7\u00e3o de um experimento: Scripts (c\u00f3digo-fonte) usado. Arquivos de configura\u00e7\u00e3o. Dados e metadados utilizados para o treinamento, valida\u00e7\u00e3o e teste. Par\u00e2metros e hiperpar\u00e2metros do modelo. Resultados das m\u00e9tricas de avalia\u00e7\u00e3o do modelo. Resultados das m\u00e9tricas de performance da aplica\u00e7\u00e3o. Uma vez tendo essas informa\u00e7\u00f5es, podemos: Comparar os diferentes resultados alcan\u00e7ados Identificar o impacto de cada altera\u00e7\u00e3o no resultado final Identificar problemas de performance do sistema, etc. Portanto, a pr\u00e1tica de rastrear os experimentos \u00e9 fundamental tanto para a reprodutiblidade (de fato, \u00e9 a principal forma de alcan\u00e7\u00e1-la) quanto para o desenvolvimento da aplica\u00e7\u00e3o em si. Rastrear manualmente experimentos pode ser extremamente complexo. Por isso usamos ferramentas free e open-source dispon\u00edveis, como \u00e9 o caso do MLflow Tracking. MLflow Tracking \u00b6 O MLflow Tracking \u00e9 uma ferramenta para loggar par\u00e2metros, m\u00e9tricas, vers\u00f5es de c\u00f3digo e artefatos, arquivos de dados, etc. Podemos loggar os experimentos atrav\u00e9s da API Python, REST API e CLI. Ainda, a ferramenta tamb\u00e9m fornece uma UI que nos permite visualizar e comparar os resultados. O MLflow Tracking gira em torno do conceito de runs . Uma run nada mais \u00e9 que a execu\u00e7\u00e3o de um peda\u00e7o de c\u00f3digo (por isso, usaremos \"run\" e execu\u00e7\u00e3o de forma intercambi\u00e1vel). No caso, usamos tal comportamento para definirmos itera\u00e7\u00f5es de um experimento. Assim, cada run \u00e9 uma execu\u00e7\u00e3o de um experimento com um certo conjunto de par\u00e2metros. Para cada run s\u00e3o salvos: Code version . Hash do commit (Git) usado na execu\u00e7\u00e3o (se o experimento estiver em um reposit\u00f3rio). Start & End time . Hora de in\u00edcio e t\u00e9rmino da run. Source . Nome do arquivo (source code) de registro do experimento. Ainda, s\u00e3o salvos outros metadados \u00fateis para a ferramenta. Dica Se as execu\u00e7\u00f5es estiverem organizadas em um MLflow Project , tamb\u00e9m s\u00e3o registrados o URI do projeto e a vers\u00e3o do c\u00f3digo-fonte. Para acompanhar os experimento rastreados, utilize a UI invocando o web server: $ mlflow ui Aten\u00e7\u00e3o A UI deve ser invocada no mesmo diret\u00f3rio onde os dados dos experimentos s\u00e3o logados. Veja a se\u00e7\u00e3o Como Execu\u00e7\u00f5es s\u00e3o Armazenadas Criando Experimentos \u00b6 Uma vez que execu\u00e7\u00f5es s\u00e3o agrupadas em experimentos, para cri\u00e1-los utilizamos o m\u00e9todo set_experiment() . set_experiment(experiment_name) . Atribui o experimento passado por par\u00e2metro como o experimento ativo. Caso o experimento n\u00e3o exista, ent\u00e3o ele \u00e9 criado. import mlflow mlflow . set_experiment ( \"Experiment #1\" ) Criando Execu\u00e7\u00f5es \u00b6 Uma vez definido o experimento, precisamos definir a itera\u00e7\u00e3o de execu\u00e7\u00e3o do experimento a partir do qual as entidades (i.e. par\u00e2metros, m\u00e9tricas, etc.) e artefatos (i.e. modelo e dados) ser\u00e3o logados. Podemos definir itera\u00e7\u00f5es atrav\u00e9s da chamada simples dos m\u00e9todos mlflow.start_run() e mlflow.end_run() ou usando mlflow.start_run() como um gerenciador de contexto. mlflow.start_run(run_id, experiment_id, run_name, nested, tags) . Caso exista uma execu\u00e7\u00e3o ativa, ent\u00e3o a retorna. Caso contr\u00e1rio, cria uma nova itera\u00e7\u00e3o. mlflow.end_run() . Encerra uma execu\u00e7\u00e3o ativa, caso exista. mlflow . start_run () mlflow . log_param ( \"param\" , 1.0 ) mlflow . end_run () Contudo, o uso mais recomendado dos m\u00e9todos \u00e9 usando gerenciadores de contexto. with mlflow . start_run () as run : mlflow . log_param ( \"param\" , 1.0 ) Par\u00e2metros \u00b6 run_id . Executa a itera\u00e7\u00e3o sobre uma execu\u00e7\u00e3o passada cujo identificador \u00e9 run_id (UUID) experiment_id. Executa a itera\u00e7\u00e3o sob um experimento cujo identificador \u00e9 experiment_id . run_name . Nome da execu\u00e7\u00e3o (salvo na tag/arquivo mlflow.runName ). Boas Pr\u00e1ticas \u00b6 Sempre que o c\u00f3digo referente a itera\u00e7\u00e3o de um experimento \u00e9 executado, \u00e9 criado um novo diret\u00f3rio (cujo nome \u00e9 o run_id , na forma de UUID) onde as entidades e artefatos s\u00e3o armazenados. Logo, \u00e9 importante manter o run_name consistente, pois ao acessarmos a UI poder\u00e1 haver v\u00e1rias execu\u00e7\u00f5es com o mesmo run_name . Loggando Entidades e Artefatos \u00b6 Cada execu\u00e7\u00e3o (i.e. run) \u00e9 registrada na forma de um diret\u00f3rio. Dentro do diret\u00f3rio h\u00e1 um arquivo de metadados denominado meta.yml e quatro diret\u00f3rios: params/ . Diret\u00f3rio onde s\u00e3o armazenados os par\u00e2metros logados. metrics/ . Diret\u00f3rio onde s\u00e3o armazenadas as m\u00e9tricas logadas. artifacts/ . Diret\u00f3rio onde s\u00e3o armazenados os artefatos. tags/ . Diret\u00f3rio onde s\u00e3o armazenadas as tags. No caso dos par\u00e2metros e m\u00e9tricas, cada par\u00e2metro indicado pelo argumento key \u00e9 um arquivo de texto cujo conte\u00fado \u00e9 a key e o respectivo valor definido. Os m\u00e9todos de logging mais importantes s\u00e3o: log_param(key, value) . Loga um parametro de nome key e valor value log_params(dict) . Semelhante a log_param , mas loga um conjunto de par\u00e2metros organizados em um dicion\u00e1rio. Aten\u00e7\u00e3o! N\u00e3o \u00e9 poss\u00edvel logar o mesmo par\u00e2metro mais de uma vez usando o m\u00e9todo log_param . Caso isso seja necess\u00e1rio, use log_params . Ainda, \u00e9 recomendado o uso consistente dos m\u00e9todos. Logo, opte por sempre usar um ou outro. log_metric(key, value, step) . An\u00e1logo ao log_param com a diferen\u00e7a do argumento step , que nos permite logar v\u00e1rios resultados para uma mesma m\u00e9trica (assim, podemos registrar experimentos executados com Valida\u00e7\u00e3o Cruzada, por exemplo). log_metrics(dict, step) . An\u00e1logo ao log_metric mas para conjuntos de m\u00e9tricas. log_artifact(local_path, artifact_path) . log_artifacts(local_dir, artifact_path) . Loggando Modelos \u00b6 TODO Boas Pr\u00e1ticas \u00b6 Por padr\u00e3o, ao loggar modelos, apenas o bin\u00e1rio do modelo e as depend\u00eancias para sua execu\u00e7\u00e3o s\u00e3o armazenadas. Por\u00e9m, \u00e9 interessante manter junto ao modelo os dados utilizados para sua constru\u00e7\u00e3o. Afinal, c\u00f3digo, dado e modelo precisam estar sempre sincronizados. Dessa forma, pr\u00e1ticas que podemos adotar s\u00e3o: (Recomendada) Loggar os dados como artefatos. A primeira e mais simples alternativa \u00e9 salvar os dados como artefatos junto do modelo. # [...] # df = pd.read_csv(\"path/to/dataset.csv\") mlflow . log_artifact ( local_path = \"path/to/dataset.csv\" ) O problema dessa abordagem \u00e9 que tanto as itera\u00e7\u00f5es quanto o armazenamento em si pode ficar custoso. Podemos amenizar o custo de armazenamento, ao loggarmos tanto dado quanto modelo em objects storage (e.g. Hadoop ou AWS S3). Contudo, o custo de upload do dado ainda tende a ser custoso. (N\u00e3o recomendada) Usar uma ferramenta de versionamento de dado, tal como DVC. Embora interessante a princ\u00edpio, essa estrat\u00e9gia possui v\u00e1rias complica\u00e7\u00f5es*. Como Execu\u00e7\u00f5es (Entidades e Artefatos) s\u00e3o Armazenados \u00b6 As execu\u00e7\u00f5es (runs) do MLflow Tracking podem ser armazenadas no sistema local de arquivos (como arquivos locais), bancos de dados compat\u00edveis com SQLAlchemy ou remotamente para um servi\u00e7o de tracking. J\u00e1 os artefatos podem ser armazenados tanto localmente quanto em diversos servi\u00e7os de armazenamento de arquivos. O MLflow utiliza dois componentes para o armazenamento dos dados: Backend Store. Armazena as entidades MLflow (metadados de execu\u00e7\u00e3o, par\u00e2metros, m\u00e9tricas, tags, notas, etc.) Artifact Store. Armazena os artefatos (arquivos, modelos, dados, imagens, objetos, etc.) Para definirmos como e onde as execu\u00e7\u00f5es ser\u00e3o registradas, usamos o m\u00e9todo set_tracking_uri . Armazenando no Sistema de Arquivos Local \u00b6 Ao utilizar o sistema de arquivos local, ambos os componentes backend store e artifact store armazenam os dados no diret\u00f3rio ./mlruns . As interfaces para tal s\u00e3o: LocalArtifactRepository para armazenar os artefatos. FileStore para armazenar as entidades. Assim, para cada experimento: MLflow cria um diret\u00f3rio (cujo nome s\u00e3o n\u00fameros inteiros) dentro de ./mlruns para armazenar as execu\u00e7\u00f5es. Por padr\u00e3o, o MLflow sempre criar\u00e1 o diret\u00f3rio 0 . Este diret\u00f3rio \u00e9 de prop\u00f3sito geral e utilizado para armazenar as execu\u00e7\u00f5es que n\u00e3o organizadas em experimentos. Cada execu\u00e7\u00e3o possui um diret\u00f3rio dentro da pasta do respectivo experimento onde s\u00e3o armazenados os artefatos e entidades. O nome do diret\u00f3rio de cada execu\u00e7\u00e3o \u00e9 o UUID da respectiva execu\u00e7\u00e3o. Nota Ao especificarmos um caminho para o sistema de arquivos local, devemos sempreutilizar a sintaxe: file:///path/to/dir/mlflow/ . Isso porque caso a gente n\u00e3o adicione o diret\u00f3rio mlflow no final dasintaxe, n\u00e3o ser\u00e3o criados os diret\u00f3rios mlruns/ e nem mlruns/0/ .Consequentemente: - A UI do MLflow n\u00e3o ir\u00e1 conseguir rastrear as execu\u00e7\u00f5es. - N\u00e3o haver\u00e1 onde adicionar execu\u00e7\u00f5es que n\u00e3o estiverem organizadas emexperimentos. Aten\u00e7\u00e3o Se a URI de rastreamento n\u00e3o for definida \\(-\\) seja atrav\u00e9s da vari\u00e1vel de ambiente MLFLOW_TRACKING_URI ou set_tracking_uri \\(-\\) o MLflow automaticamente ir\u00e1 criar o diret\u00f3rio mlruns/ na mesma pasta onde o script Python for chamado. Versionamento com Git e MLflow Tracking \u00b6 Al\u00e9m do MLflow Tracking, tamb\u00e9m podemos utilizar o MLflow Project. O MLflow Project \u00e9 um formato de empacotamento de projetos orientados a dados de forma que sejam reutiliz\u00e1veis e reprodut\u00edveis. Essencialmente, um projeto no formato MLflow Project \u00e9 apenas um diret\u00f3rio ou reposit\u00f3rio Git com os arquivos relacionados ao projeto e um arquivo adicionado denominado MLproject onde s\u00e3o definidas as configura\u00e7\u00f5es do projeto permitindo-o que seja execut\u00e1vel. Ainda, no caso de um projeto a partir de um reposit\u00f3rio Git o MLflow associa a vers\u00e3o de cada c\u00f3digo fonte a hash do \u00faltimo commit em que o c\u00f3digo foi adicionado ou modificado. Portanto, ao usar o Git com o MLflow Tracking podemos (sem necessariamente adicionar o arquivo MLproject, cerne do MLflow Project) logar as entidades e artefatos de cada execu\u00e7\u00e3o de um experimento de forma que o c\u00f3digo, dado e modelos estejam sincronizados. Boas Pr\u00e1ticas \u00b6 Dado que a vers\u00e3o de cada c\u00f3digo fonte (e consequentemente, dos artefatos relacionados) \u00e9 definida com base na hash de um commit, o versionamento correto \u00e9 responsabilidade total do usu\u00e1rio, o que pode ser sujeito a erros. Por exemplo, podemos modificar o c\u00f3digo de um experimento e execut\u00e1-lo diversas vezes sem \"commit\u00e1-lo\". Com isso, v\u00e1rias itera\u00e7\u00f5es ser\u00e3o registradas para um mesmo arquivo de c\u00f3digo fonte (assim como modelo e dado). Por\u00e9m, embora todos tenham a mesma vers\u00e3o, o conte\u00fado de cada execu\u00e7\u00e3o \u00e9 diferente. Dessa forma, fica imposs\u00edvel identificar o c\u00f3digo que gerou os artefatos da respectiva execu\u00e7\u00e3o. Portanto, as pr\u00e1ticas que podemos adotar s\u00e3o: Sempre que o c\u00f3digo do experimento for alterado, ele deve ser commitado antes de ser executado novamente. Utilizar uma ferramenta para auto-commit (abordagem recomendada). Com isso, toda altera\u00e7\u00e3o permanecer\u00e1 rastreada. Ao mesmo tempo, h\u00e1 um potencial de polui\u00e7\u00e3o do hist\u00f3rico de commits, visto que altera\u00e7\u00f5es pequenas ou pouco significantes tamb\u00e9m ser\u00e3o inclu\u00eddas como commits individuais. Considerar apenas a \u00faltima execu\u00e7\u00e3o. Ao optar por essa abordagem, caso a nova execu\u00e7\u00e3o tenha resultados inferiores, n\u00e3o ser\u00e1 poss\u00edvel reverter o c\u00f3digo para a \u00faltima vers\u00e3o (uma vez que ele n\u00e3o foi versionado)","title":"Rastreamento de Experimentos"},{"location":"concepts/mlops/experiment_tracking/#rastreamento-e-versionamento-de-experimentos","text":"","title":"Rastreamento e Versionamento de Experimentos"},{"location":"concepts/mlops/experiment_tracking/#introducao","text":"Uma pr\u00e1tica extremamente importante nos projetos de ML \u00e9 o rastreamento dos experimentos, tal como o versionamento do c\u00f3digo e artefatos produzidos pelo experimento. Ao rastrear e versionar os experimentos, conseguimos: Acompanhar os resultados de diferentes itera\u00e7\u00f5es de um experimento, visto que cada itera\u00e7\u00e3o retornar\u00e1 valores de m\u00e9tricas diferentes. Acompanhar os resultados alcan\u00e7ados por cada (hiper)par\u00e2metro. Registrar, para cada itera\u00e7\u00e3o, o c\u00f3digo do experimento, assim como os artefatos (i.e. modelo e dados utilizados para construir o modelo). Manter rastreada a exata vers\u00e3o do c\u00f3digo de uma itera\u00e7\u00e3o, tal como o dado e modelo resultante desta vers\u00e3o. Basicamente, o rastreio de experimentos \u00e9 a pr\u00e1tica de salvar (i.e. \"loggar\") todas as informa\u00e7\u00f5es importantes relacionadas aos dados, modelo e c\u00f3digo de cada itera\u00e7\u00e3o do experimento executado, de forma que seja poss\u00edvel se ter um conhecimento completo de cada informa\u00e7\u00e3o gerada e o controle total sobre todas as modifica\u00e7\u00f5es realizadas. Por exemplo, ao desenvolvermos um modelo, podemos querer rastrear (e versionar) em cada itera\u00e7\u00e3o de um experimento: Scripts (c\u00f3digo-fonte) usado. Arquivos de configura\u00e7\u00e3o. Dados e metadados utilizados para o treinamento, valida\u00e7\u00e3o e teste. Par\u00e2metros e hiperpar\u00e2metros do modelo. Resultados das m\u00e9tricas de avalia\u00e7\u00e3o do modelo. Resultados das m\u00e9tricas de performance da aplica\u00e7\u00e3o. Uma vez tendo essas informa\u00e7\u00f5es, podemos: Comparar os diferentes resultados alcan\u00e7ados Identificar o impacto de cada altera\u00e7\u00e3o no resultado final Identificar problemas de performance do sistema, etc. Portanto, a pr\u00e1tica de rastrear os experimentos \u00e9 fundamental tanto para a reprodutiblidade (de fato, \u00e9 a principal forma de alcan\u00e7\u00e1-la) quanto para o desenvolvimento da aplica\u00e7\u00e3o em si. Rastrear manualmente experimentos pode ser extremamente complexo. Por isso usamos ferramentas free e open-source dispon\u00edveis, como \u00e9 o caso do MLflow Tracking.","title":"Introdu\u00e7\u00e3o"},{"location":"concepts/mlops/experiment_tracking/#mlflow-tracking","text":"O MLflow Tracking \u00e9 uma ferramenta para loggar par\u00e2metros, m\u00e9tricas, vers\u00f5es de c\u00f3digo e artefatos, arquivos de dados, etc. Podemos loggar os experimentos atrav\u00e9s da API Python, REST API e CLI. Ainda, a ferramenta tamb\u00e9m fornece uma UI que nos permite visualizar e comparar os resultados. O MLflow Tracking gira em torno do conceito de runs . Uma run nada mais \u00e9 que a execu\u00e7\u00e3o de um peda\u00e7o de c\u00f3digo (por isso, usaremos \"run\" e execu\u00e7\u00e3o de forma intercambi\u00e1vel). No caso, usamos tal comportamento para definirmos itera\u00e7\u00f5es de um experimento. Assim, cada run \u00e9 uma execu\u00e7\u00e3o de um experimento com um certo conjunto de par\u00e2metros. Para cada run s\u00e3o salvos: Code version . Hash do commit (Git) usado na execu\u00e7\u00e3o (se o experimento estiver em um reposit\u00f3rio). Start & End time . Hora de in\u00edcio e t\u00e9rmino da run. Source . Nome do arquivo (source code) de registro do experimento. Ainda, s\u00e3o salvos outros metadados \u00fateis para a ferramenta. Dica Se as execu\u00e7\u00f5es estiverem organizadas em um MLflow Project , tamb\u00e9m s\u00e3o registrados o URI do projeto e a vers\u00e3o do c\u00f3digo-fonte. Para acompanhar os experimento rastreados, utilize a UI invocando o web server: $ mlflow ui Aten\u00e7\u00e3o A UI deve ser invocada no mesmo diret\u00f3rio onde os dados dos experimentos s\u00e3o logados. Veja a se\u00e7\u00e3o Como Execu\u00e7\u00f5es s\u00e3o Armazenadas","title":"MLflow Tracking"},{"location":"concepts/mlops/experiment_tracking/#criando-experimentos","text":"Uma vez que execu\u00e7\u00f5es s\u00e3o agrupadas em experimentos, para cri\u00e1-los utilizamos o m\u00e9todo set_experiment() . set_experiment(experiment_name) . Atribui o experimento passado por par\u00e2metro como o experimento ativo. Caso o experimento n\u00e3o exista, ent\u00e3o ele \u00e9 criado. import mlflow mlflow . set_experiment ( \"Experiment #1\" )","title":"Criando Experimentos"},{"location":"concepts/mlops/experiment_tracking/#criando-execucoes","text":"Uma vez definido o experimento, precisamos definir a itera\u00e7\u00e3o de execu\u00e7\u00e3o do experimento a partir do qual as entidades (i.e. par\u00e2metros, m\u00e9tricas, etc.) e artefatos (i.e. modelo e dados) ser\u00e3o logados. Podemos definir itera\u00e7\u00f5es atrav\u00e9s da chamada simples dos m\u00e9todos mlflow.start_run() e mlflow.end_run() ou usando mlflow.start_run() como um gerenciador de contexto. mlflow.start_run(run_id, experiment_id, run_name, nested, tags) . Caso exista uma execu\u00e7\u00e3o ativa, ent\u00e3o a retorna. Caso contr\u00e1rio, cria uma nova itera\u00e7\u00e3o. mlflow.end_run() . Encerra uma execu\u00e7\u00e3o ativa, caso exista. mlflow . start_run () mlflow . log_param ( \"param\" , 1.0 ) mlflow . end_run () Contudo, o uso mais recomendado dos m\u00e9todos \u00e9 usando gerenciadores de contexto. with mlflow . start_run () as run : mlflow . log_param ( \"param\" , 1.0 )","title":"Criando Execu\u00e7\u00f5es"},{"location":"concepts/mlops/experiment_tracking/#parametros","text":"run_id . Executa a itera\u00e7\u00e3o sobre uma execu\u00e7\u00e3o passada cujo identificador \u00e9 run_id (UUID) experiment_id. Executa a itera\u00e7\u00e3o sob um experimento cujo identificador \u00e9 experiment_id . run_name . Nome da execu\u00e7\u00e3o (salvo na tag/arquivo mlflow.runName ).","title":"Par\u00e2metros"},{"location":"concepts/mlops/experiment_tracking/#boas-praticas","text":"Sempre que o c\u00f3digo referente a itera\u00e7\u00e3o de um experimento \u00e9 executado, \u00e9 criado um novo diret\u00f3rio (cujo nome \u00e9 o run_id , na forma de UUID) onde as entidades e artefatos s\u00e3o armazenados. Logo, \u00e9 importante manter o run_name consistente, pois ao acessarmos a UI poder\u00e1 haver v\u00e1rias execu\u00e7\u00f5es com o mesmo run_name .","title":"Boas Pr\u00e1ticas"},{"location":"concepts/mlops/experiment_tracking/#loggando-entidades-e-artefatos","text":"Cada execu\u00e7\u00e3o (i.e. run) \u00e9 registrada na forma de um diret\u00f3rio. Dentro do diret\u00f3rio h\u00e1 um arquivo de metadados denominado meta.yml e quatro diret\u00f3rios: params/ . Diret\u00f3rio onde s\u00e3o armazenados os par\u00e2metros logados. metrics/ . Diret\u00f3rio onde s\u00e3o armazenadas as m\u00e9tricas logadas. artifacts/ . Diret\u00f3rio onde s\u00e3o armazenados os artefatos. tags/ . Diret\u00f3rio onde s\u00e3o armazenadas as tags. No caso dos par\u00e2metros e m\u00e9tricas, cada par\u00e2metro indicado pelo argumento key \u00e9 um arquivo de texto cujo conte\u00fado \u00e9 a key e o respectivo valor definido. Os m\u00e9todos de logging mais importantes s\u00e3o: log_param(key, value) . Loga um parametro de nome key e valor value log_params(dict) . Semelhante a log_param , mas loga um conjunto de par\u00e2metros organizados em um dicion\u00e1rio. Aten\u00e7\u00e3o! N\u00e3o \u00e9 poss\u00edvel logar o mesmo par\u00e2metro mais de uma vez usando o m\u00e9todo log_param . Caso isso seja necess\u00e1rio, use log_params . Ainda, \u00e9 recomendado o uso consistente dos m\u00e9todos. Logo, opte por sempre usar um ou outro. log_metric(key, value, step) . An\u00e1logo ao log_param com a diferen\u00e7a do argumento step , que nos permite logar v\u00e1rios resultados para uma mesma m\u00e9trica (assim, podemos registrar experimentos executados com Valida\u00e7\u00e3o Cruzada, por exemplo). log_metrics(dict, step) . An\u00e1logo ao log_metric mas para conjuntos de m\u00e9tricas. log_artifact(local_path, artifact_path) . log_artifacts(local_dir, artifact_path) .","title":"Loggando Entidades e Artefatos"},{"location":"concepts/mlops/experiment_tracking/#loggando-modelos","text":"TODO","title":"Loggando Modelos"},{"location":"concepts/mlops/experiment_tracking/#boas-praticas_1","text":"Por padr\u00e3o, ao loggar modelos, apenas o bin\u00e1rio do modelo e as depend\u00eancias para sua execu\u00e7\u00e3o s\u00e3o armazenadas. Por\u00e9m, \u00e9 interessante manter junto ao modelo os dados utilizados para sua constru\u00e7\u00e3o. Afinal, c\u00f3digo, dado e modelo precisam estar sempre sincronizados. Dessa forma, pr\u00e1ticas que podemos adotar s\u00e3o: (Recomendada) Loggar os dados como artefatos. A primeira e mais simples alternativa \u00e9 salvar os dados como artefatos junto do modelo. # [...] # df = pd.read_csv(\"path/to/dataset.csv\") mlflow . log_artifact ( local_path = \"path/to/dataset.csv\" ) O problema dessa abordagem \u00e9 que tanto as itera\u00e7\u00f5es quanto o armazenamento em si pode ficar custoso. Podemos amenizar o custo de armazenamento, ao loggarmos tanto dado quanto modelo em objects storage (e.g. Hadoop ou AWS S3). Contudo, o custo de upload do dado ainda tende a ser custoso. (N\u00e3o recomendada) Usar uma ferramenta de versionamento de dado, tal como DVC. Embora interessante a princ\u00edpio, essa estrat\u00e9gia possui v\u00e1rias complica\u00e7\u00f5es*.","title":"Boas Pr\u00e1ticas"},{"location":"concepts/mlops/experiment_tracking/#como-execucoes-entidades-e-artefatos-sao-armazenados","text":"As execu\u00e7\u00f5es (runs) do MLflow Tracking podem ser armazenadas no sistema local de arquivos (como arquivos locais), bancos de dados compat\u00edveis com SQLAlchemy ou remotamente para um servi\u00e7o de tracking. J\u00e1 os artefatos podem ser armazenados tanto localmente quanto em diversos servi\u00e7os de armazenamento de arquivos. O MLflow utiliza dois componentes para o armazenamento dos dados: Backend Store. Armazena as entidades MLflow (metadados de execu\u00e7\u00e3o, par\u00e2metros, m\u00e9tricas, tags, notas, etc.) Artifact Store. Armazena os artefatos (arquivos, modelos, dados, imagens, objetos, etc.) Para definirmos como e onde as execu\u00e7\u00f5es ser\u00e3o registradas, usamos o m\u00e9todo set_tracking_uri .","title":"Como Execu\u00e7\u00f5es (Entidades e Artefatos) s\u00e3o Armazenados"},{"location":"concepts/mlops/experiment_tracking/#armazenando-no-sistema-de-arquivos-local","text":"Ao utilizar o sistema de arquivos local, ambos os componentes backend store e artifact store armazenam os dados no diret\u00f3rio ./mlruns . As interfaces para tal s\u00e3o: LocalArtifactRepository para armazenar os artefatos. FileStore para armazenar as entidades. Assim, para cada experimento: MLflow cria um diret\u00f3rio (cujo nome s\u00e3o n\u00fameros inteiros) dentro de ./mlruns para armazenar as execu\u00e7\u00f5es. Por padr\u00e3o, o MLflow sempre criar\u00e1 o diret\u00f3rio 0 . Este diret\u00f3rio \u00e9 de prop\u00f3sito geral e utilizado para armazenar as execu\u00e7\u00f5es que n\u00e3o organizadas em experimentos. Cada execu\u00e7\u00e3o possui um diret\u00f3rio dentro da pasta do respectivo experimento onde s\u00e3o armazenados os artefatos e entidades. O nome do diret\u00f3rio de cada execu\u00e7\u00e3o \u00e9 o UUID da respectiva execu\u00e7\u00e3o. Nota Ao especificarmos um caminho para o sistema de arquivos local, devemos sempreutilizar a sintaxe: file:///path/to/dir/mlflow/ . Isso porque caso a gente n\u00e3o adicione o diret\u00f3rio mlflow no final dasintaxe, n\u00e3o ser\u00e3o criados os diret\u00f3rios mlruns/ e nem mlruns/0/ .Consequentemente: - A UI do MLflow n\u00e3o ir\u00e1 conseguir rastrear as execu\u00e7\u00f5es. - N\u00e3o haver\u00e1 onde adicionar execu\u00e7\u00f5es que n\u00e3o estiverem organizadas emexperimentos. Aten\u00e7\u00e3o Se a URI de rastreamento n\u00e3o for definida \\(-\\) seja atrav\u00e9s da vari\u00e1vel de ambiente MLFLOW_TRACKING_URI ou set_tracking_uri \\(-\\) o MLflow automaticamente ir\u00e1 criar o diret\u00f3rio mlruns/ na mesma pasta onde o script Python for chamado.","title":"Armazenando no Sistema de Arquivos Local"},{"location":"concepts/mlops/experiment_tracking/#versionamento-com-git-e-mlflow-tracking","text":"Al\u00e9m do MLflow Tracking, tamb\u00e9m podemos utilizar o MLflow Project. O MLflow Project \u00e9 um formato de empacotamento de projetos orientados a dados de forma que sejam reutiliz\u00e1veis e reprodut\u00edveis. Essencialmente, um projeto no formato MLflow Project \u00e9 apenas um diret\u00f3rio ou reposit\u00f3rio Git com os arquivos relacionados ao projeto e um arquivo adicionado denominado MLproject onde s\u00e3o definidas as configura\u00e7\u00f5es do projeto permitindo-o que seja execut\u00e1vel. Ainda, no caso de um projeto a partir de um reposit\u00f3rio Git o MLflow associa a vers\u00e3o de cada c\u00f3digo fonte a hash do \u00faltimo commit em que o c\u00f3digo foi adicionado ou modificado. Portanto, ao usar o Git com o MLflow Tracking podemos (sem necessariamente adicionar o arquivo MLproject, cerne do MLflow Project) logar as entidades e artefatos de cada execu\u00e7\u00e3o de um experimento de forma que o c\u00f3digo, dado e modelos estejam sincronizados.","title":"Versionamento com Git e MLflow Tracking"},{"location":"concepts/mlops/experiment_tracking/#boas-praticas_2","text":"Dado que a vers\u00e3o de cada c\u00f3digo fonte (e consequentemente, dos artefatos relacionados) \u00e9 definida com base na hash de um commit, o versionamento correto \u00e9 responsabilidade total do usu\u00e1rio, o que pode ser sujeito a erros. Por exemplo, podemos modificar o c\u00f3digo de um experimento e execut\u00e1-lo diversas vezes sem \"commit\u00e1-lo\". Com isso, v\u00e1rias itera\u00e7\u00f5es ser\u00e3o registradas para um mesmo arquivo de c\u00f3digo fonte (assim como modelo e dado). Por\u00e9m, embora todos tenham a mesma vers\u00e3o, o conte\u00fado de cada execu\u00e7\u00e3o \u00e9 diferente. Dessa forma, fica imposs\u00edvel identificar o c\u00f3digo que gerou os artefatos da respectiva execu\u00e7\u00e3o. Portanto, as pr\u00e1ticas que podemos adotar s\u00e3o: Sempre que o c\u00f3digo do experimento for alterado, ele deve ser commitado antes de ser executado novamente. Utilizar uma ferramenta para auto-commit (abordagem recomendada). Com isso, toda altera\u00e7\u00e3o permanecer\u00e1 rastreada. Ao mesmo tempo, h\u00e1 um potencial de polui\u00e7\u00e3o do hist\u00f3rico de commits, visto que altera\u00e7\u00f5es pequenas ou pouco significantes tamb\u00e9m ser\u00e3o inclu\u00eddas como commits individuais. Considerar apenas a \u00faltima execu\u00e7\u00e3o. Ao optar por essa abordagem, caso a nova execu\u00e7\u00e3o tenha resultados inferiores, n\u00e3o ser\u00e1 poss\u00edvel reverter o c\u00f3digo para a \u00faltima vers\u00e3o (uma vez que ele n\u00e3o foi versionado)","title":"Boas Pr\u00e1ticas"},{"location":"concepts/mlops/feature_stores/","text":"Work in progress","title":"Feature Stores"},{"location":"concepts/mlops/ml_pipelines_automation/","text":"Automa\u00e7\u00e3o de Pipelines de ML \u00b6 Attention! Aten\u00e7\u00e3o! (en_US) This post is a synthesis and translation (into pt_BR) of the post MLOps: Continuous delivery and automation pipelines in machine learning by Google Team. (pt_BR) Esta publica\u00e7\u00e3o \u00e9 uma s\u00edntese e tradu\u00e7\u00e3o (para pt_BR) do artigo MLOps: Continuous delivery and automation pipelines in machine learning do Google Team. Ci\u00eancia de Dados e Aprendizado de M\u00e1quina (ML, do ingl\u00eas Machine Learning) t\u00eam-se tornado estrat\u00e9gias priorit\u00e1rias na resolu\u00e7\u00e3o de diversos problemas complexos do mundo real. De fato, implementar e treinar modelos de ML n\u00e3o s\u00e3o tarefas triviais. Contudo, O verdadeiro desafio n\u00e3o \u00e9 construir modelos de ML O verdadeiro desafio \u00e9 construir sistemas de ML integrados e que podem ser atulizados e operados continuamente em produ\u00e7\u00e3o. De acordo com o Sculley et al , Apenas uma pequena fra\u00e7\u00e3o dos sistemas de ML em produ\u00e7\u00e3o s\u00e3o compostos por c\u00f3digos referente \u00e0 ML Por outro lado, a infraestrutura \u00e9 vasta e complexa. Portanto, para desenvolver e operar sistemas complexos como esses, voc\u00ea pode recorrer aos princ\u00edpios do DevOps aos sistemas de ML (MLOps). MLOps \u00e9 uma cultura e pr\u00e1tica de engenharia de ML que visa unificar o desenvolvimento do sistema de ML (Dev) e a opera\u00e7\u00e3o do sistema de ML (Ops). Praticar MLOps significa que voc\u00ea defende a automa\u00e7\u00e3o e o monitoramento em todas as etapas da constru\u00e7\u00e3o do sistema de ML, incluindo integra\u00e7\u00e3o, teste, releasing, deployment e gerenciamento de infraestrutura.* Ainda, al\u00e9m das pr\u00e1ticas aplicadas \u00e0 sistemas de software convencionais \u2014 uma vez que sistemas de ML tamb\u00e9m s\u00e3o sistemas de software \u2014 sistemas de ML possuem algumas caracter\u00edsticas espec\u00edficas que exigem novas pr\u00e1ticas, como, por exemplo. Desenvolvimento. ML \u00e9 experimental por natureza. Logo, \u00e9 estritamente necess\u00e1rio manter rastreado todos os experimentos feitos, a fim de permitir a identifica\u00e7\u00e3o do que funcionou, o que n\u00e3o funcionou e porqu\u00ea, ao mesmo tempo que reprodutibilidade e reutiliza\u00e7\u00e3o de c\u00f3digo devem estar presentes. Teste. Al\u00e9m dos testes executados em sistemas de softwares convencionais (e.g. testes unit\u00e1rios e de integra\u00e7\u00e3o), em sistemas de ML tamb\u00e9m s\u00e3o necess\u00e1rios teste e valida\u00e7\u00e3o tanto de dados quanto de modelos. Deployment. Em sistemas de ML, o deploy pode requer um alto n\u00edvel de complexidade que dificulta tanto o desenvolvimento quanto a opera\u00e7\u00e3o do modelo em produ\u00e7\u00e3o. Production. Em produ\u00e7\u00e3o, os modelos de ML podem alcan\u00e7ar desempenhos ruins n\u00e3o apenas devido a qualidade de c\u00f3digo, mas tamb\u00e9m a inconsist\u00eancia dos dados. Assim, o monitoramento do sistema precisa ser muito mais rigoroso e complexo. Etapas de Machine Learning \u00b6 Os n\u00edveis de automa\u00e7\u00e3o destas etapas definem a maturidade do pipeline do sistema de ML. Em geral, podemos dividir a maturidade de automa\u00e7\u00e3o em tr\u00eas n\u00edveis: N\u00edvel #0. N\u00e3o h\u00e1 automa\u00e7\u00e3o e todos os processos s\u00e3o executados manualmente N\u00edvel #1. Os pipelines de ML s\u00e3o automatizados. Logo, Os experimentos s\u00e3o orquestrados. Os modelos em produ\u00e7\u00e3o s\u00e3o continuamente atualizados atrav\u00e9s de um pipeline de ML automatizado acionado por triggers (que s\u00e3o disparados periodicamente ou com base em um certo conjunto de regras comumente relacionadas ao desempenho do modelo em produ\u00e7\u00e3o). Etapas de build , test e deployment s\u00e3o executadas manualmente. N\u00edvel #2. Todo o pipeline, incluindo as etapas de build , test e deployment s\u00e3o automatizadas. Logo, Os experimentos s\u00e3o orquestrados Os modelos em produ\u00e7\u00e3o s\u00e3o continuamente atualizados atrav\u00e9s de um pipeline de ML automatizado acionado por triggers (que s\u00e3o disparados periodicamente ou com base em um certo conjunto de regras comumente relacionadas ao desempenho do modelo em produ\u00e7\u00e3o). Etapas de build , test e deployment s\u00e3o executadas automaticamente atrav\u00e9s de mecanismos de CI/CD. Automa\u00e7\u00e3o N\u00edvel #0 \u2014 Processo Manual \u00b6 Work in progress Automa\u00e7\u00e3o N\u00edvel #1 \u2014 ML Pipeline Automatizado \u00b6 Um primeiro n\u00edvel (#1) de automa\u00e7\u00e3o consiste em: Experimenta\u00e7\u00e3o orquestrada. Executar (ou permitir) o treinamento cont\u00ednuo (CT, do ingl\u00eas Continuos Training) do modelo por meio da automa\u00e7\u00e3o do pipeline de ML em produ\u00e7\u00e3o. Para uma automa\u00e7\u00e3o confi\u00e1vel e de r\u00e1pida execu\u00e7\u00e3o \u00e9 necess\u00e1rio incluir: Source Control. Orquestrador de Experimentos. Valida\u00e7\u00e3o (autom\u00e1tica) de Dados e Modelos. ML Metadata Store. Feature Store. Model Registry. Triggers. Etapas \u00b6 Um primeiro n\u00edvel de automa\u00e7\u00e3o consiste (em suma) das seguintes etapas: Experimenta\u00e7\u00e3o Orquestrada. Atrav\u00e9s de um ambiente de experimenta\u00e7\u00f5es orquestradas, novos algoritmos de ML s\u00e3o experimentados iterativamente. A sa\u00edda desta etapa \u00e9 o c\u00f3digo-fonte do pipeline (ou o modelo de ML resultante do experimento) que \u00e9 armazenado em um reposit\u00f3rio de c\u00f3digos-fonte (source control) . Nota A experimenta\u00e7\u00e3o orquestrada pode resultar apenas em um novo modelo ou em um pipeline totalmente novo. Por\u00e9m, mesmo um novo modelo pode ser visto como uma nova vers\u00e3o de um pipeline antigo, assim como altera\u00e7\u00f5es em demais componentes (e.g., etapa de extra\u00e7\u00e3o de dados ou transforma\u00e7\u00f5es). Logo, o que ser\u00e1 atualizado em produ\u00e7\u00e3o pode desde componentes individuais, at\u00e9 pipelines inteiros. Treinamento Cont\u00ednuo. Ap\u00f3s a execu\u00e7\u00e3o manual das etapas de build , test e deployment , o pipeline (ou modelo) \u00e9 atualizado em produ\u00e7\u00e3o, onde \u00e9 executado automaticamente com base em uma periodicidade pr\u00e9-definida ou em resposta a um trigger. A sa\u00edda desta etapa \u00e9 um modelo treinado que \u00e9 armazenado no Model Registry. Alternativamente, a etapa de CT pode ser executada simplesmente para atualizar o conhecimento do modelo atual em produ\u00e7\u00e3o. Neste caso, O pipeline \u00e9 acionado por meio de triggers. Os triggers podem ser disparados atrav\u00e9s de regras como: desempenho m\u00ednimo alcan\u00e7ado. A sa\u00edda desta etapa \u00e9 um pipeline ou modelo que \u00e9 armazenado em um Model Registry. Caracter\u00edsticas \u00b6 Experimentos Orquestrados. Todo o experimento, etapas e transi\u00e7\u00f5es entre as etapas s\u00e3o automatizadas. Assim, cada itera\u00e7\u00e3o de experimenta\u00e7\u00e3o acontece de forma r\u00e1pida e h\u00e1 maior prontid\u00e3o para mover todo o pipeline do desenvolvimento para a produ\u00e7\u00e3o. Treinamento Cont\u00ednuo (CT) do Modelo em Produ\u00e7\u00e3o. O modelo em produ\u00e7\u00e3o \u00e9 automaticamente retreinado usando dados atualizados. O (re)treinamento \u00e9 acionado atrav\u00e9s triggers. Simetria Experimental-Operacional. A implementa\u00e7\u00e3o do pipeline usada no ambiente de desenvolvimento \u00e9 tamb\u00e9m usada no ambiente de pr\u00e9-produ\u00e7\u00e3o e produ\u00e7\u00e3o (o que \u00e9 um aspecto-chave da pr\u00e1tica de MLOps para unificar DevOps). Componentes \u00b6 Source Control \u00b6 Work in progress Orquestrador de Experimentos \u00b6 Work in progress Valida\u00e7\u00e3o de Dados e Modelos \u00b6 Os pipelines de ML em produ\u00e7\u00e3o s\u00e3o disparados por meio de triggers. Assim, para garantir o funcionamento correto tanto do modelo quanto de todo pipeline: \u00c9 necess\u00e1rio validar os dados que ser\u00e3o utilizados como sinais de entrada para o novo modelo, assim como validar o pr\u00f3prio modelo em si. Por ser um processo autom\u00e1tico, \u00e9 necess\u00e1rio que a valida\u00e7\u00e3o do dado e modelo tamb\u00e9m sejam autom\u00e1ticas. Valida\u00e7\u00e3o de Dados. Etapa executada antes do treinamento do modelo cujo objetivo \u00e9 decidir se os dados s\u00e3o aptos para o retreinamento do modelo ou n\u00e3o. Alguns exemplos de situa\u00e7\u00f5es em que os dados n\u00e3o s\u00e3o aptos: Data Schema Skews. Data Values Skews. Valida\u00e7\u00e3o de Modelo. Etapa executada ap\u00f3s o retreinamento do modelo com os novos dados. O modelo \u00e9 avaliado e validado da forma offline tradicional antes de, de fato, entrar em produ\u00e7\u00e3o, ou seja: ML Metadata Store \u00b6 Work in progress Feature Store \u00b6 Work in progress Model Registry \u00b6 Work in progress Triggers \u00b6 Work in progress Desafios \u00b6 Se um sistema \u00e9 composto por uma grande quantidade de pipelines em produ\u00e7\u00e3o e, alguns modelos precisam entrar rapidamente em produ\u00e7\u00e3o ou serem testados, o build, test e deployment pipeline manualmente acaba, se tornando invi\u00e1veis. Assim, \u00e9 necess\u00e1rio um ambiente de CI/CD. Ferramentas para Implementa\u00e7\u00e3o de Automa\u00e7\u00e3o N\u00edvel #1 \u00b6 TensorFlow Extended (TFX). Apache Airflow. MLFlow. Kedro. Automa\u00e7\u00e3o N\u00edvel #2 \u2014 CI/CD Pipeline \u00b6 Um segundo n\u00edvel (#2) de automa\u00e7\u00e3o consiste em: Experimenta\u00e7\u00e3o orquestrada. Executar (ou permitir) a atualiza\u00e7\u00e3o r\u00e1pida e confi\u00e1vel de pipelines em produ\u00e7\u00e3o atrav\u00e9s da automa\u00e7\u00e3o de todo o fluxo de desenvolvimento e opera\u00e7\u00e3o. Automatiza\u00e7\u00e3o do pipeline de ML (CT). Sistemas de CI/CD. Para uma automa\u00e7\u00e3o de n\u00edvel #2 \u00e9 necess\u00e1rio incluir componentes como: Source Control. Orquestrador de Experimentos. Valida\u00e7\u00e3o (autom\u00e1tica) de Dados e Modelos. Servi\u00e7os de Teste e Build. Servi\u00e7os de Deployment. ML Metadata Store. Feature Store. Model Registry. Triggers. Etapas \u00b6 Um segundo n\u00edvel de automa\u00e7\u00e3o consiste, em suma, das seguintes etapas: Experimenta\u00e7\u00e3o Orquestrada. Atrav\u00e9s de um ambiente de experimenta\u00e7\u00f5es orquestradas, novos algoritmos de ML s\u00e3o experimentados iterativamente. A sa\u00edda desta etapa \u00e9 o c\u00f3digo-fonte do pipeline (ou o modelo de ML resultante do experimento) que \u00e9 armazenado em um reposit\u00f3rio de c\u00f3digos-fonte (source control) . Integra\u00e7\u00e3o Cont\u00ednua do Pipeline. O c\u00f3digo-fonte \u00e9 \"buildado\" e passa por um grande quantidade de testes unit\u00e1rios e de integra\u00e7\u00e3o. A sa\u00edda desta etapa s\u00e3o todos os artefatos necess\u00e1rios para o deployment futuro do pipeline (e.g. pacotes e execut\u00e1veis). Entrega Cont\u00ednua do Pipeline. Os artefatos produzidos na etapa de integra\u00e7\u00e3o cont\u00ednua s\u00e3o disponibilizados (deploy) no ambiente de produ\u00e7\u00e3o (ou qualquer outro ambiente alvo). A sa\u00edda desta etapa \u00e9 um pipeline atualizado e disponibilizado (deployed) em produ\u00e7\u00e3o, com uma nova implementa\u00e7\u00e3o do modelo. Treinamento Cont\u00ednuo. Em produ\u00e7\u00e3o, o pipeline \u00e9 executado automaticamente com base em uma scheduling ou em resposta a um trigger. A sa\u00edda desta etapa \u00e9 um modelo treinado que \u00e9 armazenado no Model Registry. Entrega Cont\u00ednua do Modelo. O modelo mais recente (ou melhor ranqueado) do Model Registry \u00e9 servido como um servi\u00e7o (ou motor) de infer\u00eancias. A sa\u00edda deste est\u00e1gio \u00e9 um servi\u00e7o de infer\u00eancias. Monitoramento. Estat\u00edsticas sobre a performance do modelo em produ\u00e7\u00e3o s\u00e3o coletadas . A sa\u00edda deste est\u00e1gio \u00e9 o disparo de um trigger que deve provocar uma nova execu\u00e7\u00e3o do pipeline em produ\u00e7\u00e3o ou indicar a necessidade de um novo ciclo de experimenta\u00e7\u00e3o. As etapas de an\u00e1lise explotar\u00f3ria de dados e an\u00e1lise de modelo ainda s\u00e3o etapas manuais e que necessitam de um trabalho extensivo por parte do cientista de dados, por exemplo. Caracter\u00edsticas \u00b6 Experimentos Orquestrados. Todo o experimento, etapas e transi\u00e7\u00f5es entre as etapas s\u00e3o automatizadas. Assim, cada itera\u00e7\u00e3o de experimenta\u00e7\u00e3o acontece de forma r\u00e1pida e h\u00e1 maior prontid\u00e3o para mover todo o pipeline do desenvolvimento para a produ\u00e7\u00e3o. Integra\u00e7\u00e3o e Entrega Cont\u00ednua do Pipeline. Treinamento Cont\u00ednuo (CT) do Modelo em Produ\u00e7\u00e3o. O modelo em produ\u00e7\u00e3o \u00e9 automaticamente retreinado usando dados atualizados e acionado atrav\u00e9s triggers. Simetria Experimental-Operacional. A implementa\u00e7\u00e3o do pipeline usada no ambiente de desenvolvimento \u00e9 tamb\u00e9m usada no ambiente de pr\u00e9-produ\u00e7\u00e3o e produ\u00e7\u00e3o (o que \u00e9 um aspecto-chave da pr\u00e1tica de MLOps para unificar DevOps). Entrega Cont\u00ednua do Modelo. (work in progress) Componentes \u00b6 Servi\u00e7os de Teste e Build \u00b6 Work in progress Servi\u00e7os de Deployment \u00b6 Work in progress Desafios \u00b6 Em um segundo n\u00edvel de automa\u00e7\u00e3o, praticamente todos os processos s\u00e3o executados automaticamente. Por conta disso, h\u00e1 um grande complexidade envolvida na implementa\u00e7\u00e3o do sistema.","title":"Automa\u00e7\u00e3o de Pipelines de ML"},{"location":"concepts/mlops/ml_pipelines_automation/#automacao-de-pipelines-de-ml","text":"Attention! Aten\u00e7\u00e3o! (en_US) This post is a synthesis and translation (into pt_BR) of the post MLOps: Continuous delivery and automation pipelines in machine learning by Google Team. (pt_BR) Esta publica\u00e7\u00e3o \u00e9 uma s\u00edntese e tradu\u00e7\u00e3o (para pt_BR) do artigo MLOps: Continuous delivery and automation pipelines in machine learning do Google Team. Ci\u00eancia de Dados e Aprendizado de M\u00e1quina (ML, do ingl\u00eas Machine Learning) t\u00eam-se tornado estrat\u00e9gias priorit\u00e1rias na resolu\u00e7\u00e3o de diversos problemas complexos do mundo real. De fato, implementar e treinar modelos de ML n\u00e3o s\u00e3o tarefas triviais. Contudo, O verdadeiro desafio n\u00e3o \u00e9 construir modelos de ML O verdadeiro desafio \u00e9 construir sistemas de ML integrados e que podem ser atulizados e operados continuamente em produ\u00e7\u00e3o. De acordo com o Sculley et al , Apenas uma pequena fra\u00e7\u00e3o dos sistemas de ML em produ\u00e7\u00e3o s\u00e3o compostos por c\u00f3digos referente \u00e0 ML Por outro lado, a infraestrutura \u00e9 vasta e complexa. Portanto, para desenvolver e operar sistemas complexos como esses, voc\u00ea pode recorrer aos princ\u00edpios do DevOps aos sistemas de ML (MLOps). MLOps \u00e9 uma cultura e pr\u00e1tica de engenharia de ML que visa unificar o desenvolvimento do sistema de ML (Dev) e a opera\u00e7\u00e3o do sistema de ML (Ops). Praticar MLOps significa que voc\u00ea defende a automa\u00e7\u00e3o e o monitoramento em todas as etapas da constru\u00e7\u00e3o do sistema de ML, incluindo integra\u00e7\u00e3o, teste, releasing, deployment e gerenciamento de infraestrutura.* Ainda, al\u00e9m das pr\u00e1ticas aplicadas \u00e0 sistemas de software convencionais \u2014 uma vez que sistemas de ML tamb\u00e9m s\u00e3o sistemas de software \u2014 sistemas de ML possuem algumas caracter\u00edsticas espec\u00edficas que exigem novas pr\u00e1ticas, como, por exemplo. Desenvolvimento. ML \u00e9 experimental por natureza. Logo, \u00e9 estritamente necess\u00e1rio manter rastreado todos os experimentos feitos, a fim de permitir a identifica\u00e7\u00e3o do que funcionou, o que n\u00e3o funcionou e porqu\u00ea, ao mesmo tempo que reprodutibilidade e reutiliza\u00e7\u00e3o de c\u00f3digo devem estar presentes. Teste. Al\u00e9m dos testes executados em sistemas de softwares convencionais (e.g. testes unit\u00e1rios e de integra\u00e7\u00e3o), em sistemas de ML tamb\u00e9m s\u00e3o necess\u00e1rios teste e valida\u00e7\u00e3o tanto de dados quanto de modelos. Deployment. Em sistemas de ML, o deploy pode requer um alto n\u00edvel de complexidade que dificulta tanto o desenvolvimento quanto a opera\u00e7\u00e3o do modelo em produ\u00e7\u00e3o. Production. Em produ\u00e7\u00e3o, os modelos de ML podem alcan\u00e7ar desempenhos ruins n\u00e3o apenas devido a qualidade de c\u00f3digo, mas tamb\u00e9m a inconsist\u00eancia dos dados. Assim, o monitoramento do sistema precisa ser muito mais rigoroso e complexo.","title":"Automa\u00e7\u00e3o de Pipelines de ML"},{"location":"concepts/mlops/ml_pipelines_automation/#etapas-de-machine-learning","text":"Os n\u00edveis de automa\u00e7\u00e3o destas etapas definem a maturidade do pipeline do sistema de ML. Em geral, podemos dividir a maturidade de automa\u00e7\u00e3o em tr\u00eas n\u00edveis: N\u00edvel #0. N\u00e3o h\u00e1 automa\u00e7\u00e3o e todos os processos s\u00e3o executados manualmente N\u00edvel #1. Os pipelines de ML s\u00e3o automatizados. Logo, Os experimentos s\u00e3o orquestrados. Os modelos em produ\u00e7\u00e3o s\u00e3o continuamente atualizados atrav\u00e9s de um pipeline de ML automatizado acionado por triggers (que s\u00e3o disparados periodicamente ou com base em um certo conjunto de regras comumente relacionadas ao desempenho do modelo em produ\u00e7\u00e3o). Etapas de build , test e deployment s\u00e3o executadas manualmente. N\u00edvel #2. Todo o pipeline, incluindo as etapas de build , test e deployment s\u00e3o automatizadas. Logo, Os experimentos s\u00e3o orquestrados Os modelos em produ\u00e7\u00e3o s\u00e3o continuamente atualizados atrav\u00e9s de um pipeline de ML automatizado acionado por triggers (que s\u00e3o disparados periodicamente ou com base em um certo conjunto de regras comumente relacionadas ao desempenho do modelo em produ\u00e7\u00e3o). Etapas de build , test e deployment s\u00e3o executadas automaticamente atrav\u00e9s de mecanismos de CI/CD.","title":"Etapas de Machine Learning"},{"location":"concepts/mlops/ml_pipelines_automation/#automacao-nivel-0-processo-manual","text":"Work in progress","title":"Automa\u00e7\u00e3o N\u00edvel #0 \u2014 Processo Manual"},{"location":"concepts/mlops/ml_pipelines_automation/#automacao-nivel-1-ml-pipeline-automatizado","text":"Um primeiro n\u00edvel (#1) de automa\u00e7\u00e3o consiste em: Experimenta\u00e7\u00e3o orquestrada. Executar (ou permitir) o treinamento cont\u00ednuo (CT, do ingl\u00eas Continuos Training) do modelo por meio da automa\u00e7\u00e3o do pipeline de ML em produ\u00e7\u00e3o. Para uma automa\u00e7\u00e3o confi\u00e1vel e de r\u00e1pida execu\u00e7\u00e3o \u00e9 necess\u00e1rio incluir: Source Control. Orquestrador de Experimentos. Valida\u00e7\u00e3o (autom\u00e1tica) de Dados e Modelos. ML Metadata Store. Feature Store. Model Registry. Triggers.","title":"Automa\u00e7\u00e3o N\u00edvel #1 \u2014 ML Pipeline Automatizado"},{"location":"concepts/mlops/ml_pipelines_automation/#etapas","text":"Um primeiro n\u00edvel de automa\u00e7\u00e3o consiste (em suma) das seguintes etapas: Experimenta\u00e7\u00e3o Orquestrada. Atrav\u00e9s de um ambiente de experimenta\u00e7\u00f5es orquestradas, novos algoritmos de ML s\u00e3o experimentados iterativamente. A sa\u00edda desta etapa \u00e9 o c\u00f3digo-fonte do pipeline (ou o modelo de ML resultante do experimento) que \u00e9 armazenado em um reposit\u00f3rio de c\u00f3digos-fonte (source control) . Nota A experimenta\u00e7\u00e3o orquestrada pode resultar apenas em um novo modelo ou em um pipeline totalmente novo. Por\u00e9m, mesmo um novo modelo pode ser visto como uma nova vers\u00e3o de um pipeline antigo, assim como altera\u00e7\u00f5es em demais componentes (e.g., etapa de extra\u00e7\u00e3o de dados ou transforma\u00e7\u00f5es). Logo, o que ser\u00e1 atualizado em produ\u00e7\u00e3o pode desde componentes individuais, at\u00e9 pipelines inteiros. Treinamento Cont\u00ednuo. Ap\u00f3s a execu\u00e7\u00e3o manual das etapas de build , test e deployment , o pipeline (ou modelo) \u00e9 atualizado em produ\u00e7\u00e3o, onde \u00e9 executado automaticamente com base em uma periodicidade pr\u00e9-definida ou em resposta a um trigger. A sa\u00edda desta etapa \u00e9 um modelo treinado que \u00e9 armazenado no Model Registry. Alternativamente, a etapa de CT pode ser executada simplesmente para atualizar o conhecimento do modelo atual em produ\u00e7\u00e3o. Neste caso, O pipeline \u00e9 acionado por meio de triggers. Os triggers podem ser disparados atrav\u00e9s de regras como: desempenho m\u00ednimo alcan\u00e7ado. A sa\u00edda desta etapa \u00e9 um pipeline ou modelo que \u00e9 armazenado em um Model Registry.","title":"Etapas"},{"location":"concepts/mlops/ml_pipelines_automation/#caracteristicas","text":"Experimentos Orquestrados. Todo o experimento, etapas e transi\u00e7\u00f5es entre as etapas s\u00e3o automatizadas. Assim, cada itera\u00e7\u00e3o de experimenta\u00e7\u00e3o acontece de forma r\u00e1pida e h\u00e1 maior prontid\u00e3o para mover todo o pipeline do desenvolvimento para a produ\u00e7\u00e3o. Treinamento Cont\u00ednuo (CT) do Modelo em Produ\u00e7\u00e3o. O modelo em produ\u00e7\u00e3o \u00e9 automaticamente retreinado usando dados atualizados. O (re)treinamento \u00e9 acionado atrav\u00e9s triggers. Simetria Experimental-Operacional. A implementa\u00e7\u00e3o do pipeline usada no ambiente de desenvolvimento \u00e9 tamb\u00e9m usada no ambiente de pr\u00e9-produ\u00e7\u00e3o e produ\u00e7\u00e3o (o que \u00e9 um aspecto-chave da pr\u00e1tica de MLOps para unificar DevOps).","title":"Caracter\u00edsticas"},{"location":"concepts/mlops/ml_pipelines_automation/#componentes","text":"","title":"Componentes"},{"location":"concepts/mlops/ml_pipelines_automation/#source-control","text":"Work in progress","title":"Source Control"},{"location":"concepts/mlops/ml_pipelines_automation/#orquestrador-de-experimentos","text":"Work in progress","title":"Orquestrador de Experimentos"},{"location":"concepts/mlops/ml_pipelines_automation/#validacao-de-dados-e-modelos","text":"Os pipelines de ML em produ\u00e7\u00e3o s\u00e3o disparados por meio de triggers. Assim, para garantir o funcionamento correto tanto do modelo quanto de todo pipeline: \u00c9 necess\u00e1rio validar os dados que ser\u00e3o utilizados como sinais de entrada para o novo modelo, assim como validar o pr\u00f3prio modelo em si. Por ser um processo autom\u00e1tico, \u00e9 necess\u00e1rio que a valida\u00e7\u00e3o do dado e modelo tamb\u00e9m sejam autom\u00e1ticas. Valida\u00e7\u00e3o de Dados. Etapa executada antes do treinamento do modelo cujo objetivo \u00e9 decidir se os dados s\u00e3o aptos para o retreinamento do modelo ou n\u00e3o. Alguns exemplos de situa\u00e7\u00f5es em que os dados n\u00e3o s\u00e3o aptos: Data Schema Skews. Data Values Skews. Valida\u00e7\u00e3o de Modelo. Etapa executada ap\u00f3s o retreinamento do modelo com os novos dados. O modelo \u00e9 avaliado e validado da forma offline tradicional antes de, de fato, entrar em produ\u00e7\u00e3o, ou seja:","title":"Valida\u00e7\u00e3o de Dados e Modelos"},{"location":"concepts/mlops/ml_pipelines_automation/#ml-metadata-store","text":"Work in progress","title":"ML Metadata Store"},{"location":"concepts/mlops/ml_pipelines_automation/#feature-store","text":"Work in progress","title":"Feature Store"},{"location":"concepts/mlops/ml_pipelines_automation/#model-registry","text":"Work in progress","title":"Model Registry"},{"location":"concepts/mlops/ml_pipelines_automation/#triggers","text":"Work in progress","title":"Triggers"},{"location":"concepts/mlops/ml_pipelines_automation/#desafios","text":"Se um sistema \u00e9 composto por uma grande quantidade de pipelines em produ\u00e7\u00e3o e, alguns modelos precisam entrar rapidamente em produ\u00e7\u00e3o ou serem testados, o build, test e deployment pipeline manualmente acaba, se tornando invi\u00e1veis. Assim, \u00e9 necess\u00e1rio um ambiente de CI/CD.","title":"Desafios"},{"location":"concepts/mlops/ml_pipelines_automation/#ferramentas-para-implementacao-de-automacao-nivel-1","text":"TensorFlow Extended (TFX). Apache Airflow. MLFlow. Kedro.","title":"Ferramentas para Implementa\u00e7\u00e3o de Automa\u00e7\u00e3o N\u00edvel #1"},{"location":"concepts/mlops/ml_pipelines_automation/#automacao-nivel-2-cicd-pipeline","text":"Um segundo n\u00edvel (#2) de automa\u00e7\u00e3o consiste em: Experimenta\u00e7\u00e3o orquestrada. Executar (ou permitir) a atualiza\u00e7\u00e3o r\u00e1pida e confi\u00e1vel de pipelines em produ\u00e7\u00e3o atrav\u00e9s da automa\u00e7\u00e3o de todo o fluxo de desenvolvimento e opera\u00e7\u00e3o. Automatiza\u00e7\u00e3o do pipeline de ML (CT). Sistemas de CI/CD. Para uma automa\u00e7\u00e3o de n\u00edvel #2 \u00e9 necess\u00e1rio incluir componentes como: Source Control. Orquestrador de Experimentos. Valida\u00e7\u00e3o (autom\u00e1tica) de Dados e Modelos. Servi\u00e7os de Teste e Build. Servi\u00e7os de Deployment. ML Metadata Store. Feature Store. Model Registry. Triggers.","title":"Automa\u00e7\u00e3o N\u00edvel #2 \u2014 CI/CD Pipeline"},{"location":"concepts/mlops/ml_pipelines_automation/#etapas_1","text":"Um segundo n\u00edvel de automa\u00e7\u00e3o consiste, em suma, das seguintes etapas: Experimenta\u00e7\u00e3o Orquestrada. Atrav\u00e9s de um ambiente de experimenta\u00e7\u00f5es orquestradas, novos algoritmos de ML s\u00e3o experimentados iterativamente. A sa\u00edda desta etapa \u00e9 o c\u00f3digo-fonte do pipeline (ou o modelo de ML resultante do experimento) que \u00e9 armazenado em um reposit\u00f3rio de c\u00f3digos-fonte (source control) . Integra\u00e7\u00e3o Cont\u00ednua do Pipeline. O c\u00f3digo-fonte \u00e9 \"buildado\" e passa por um grande quantidade de testes unit\u00e1rios e de integra\u00e7\u00e3o. A sa\u00edda desta etapa s\u00e3o todos os artefatos necess\u00e1rios para o deployment futuro do pipeline (e.g. pacotes e execut\u00e1veis). Entrega Cont\u00ednua do Pipeline. Os artefatos produzidos na etapa de integra\u00e7\u00e3o cont\u00ednua s\u00e3o disponibilizados (deploy) no ambiente de produ\u00e7\u00e3o (ou qualquer outro ambiente alvo). A sa\u00edda desta etapa \u00e9 um pipeline atualizado e disponibilizado (deployed) em produ\u00e7\u00e3o, com uma nova implementa\u00e7\u00e3o do modelo. Treinamento Cont\u00ednuo. Em produ\u00e7\u00e3o, o pipeline \u00e9 executado automaticamente com base em uma scheduling ou em resposta a um trigger. A sa\u00edda desta etapa \u00e9 um modelo treinado que \u00e9 armazenado no Model Registry. Entrega Cont\u00ednua do Modelo. O modelo mais recente (ou melhor ranqueado) do Model Registry \u00e9 servido como um servi\u00e7o (ou motor) de infer\u00eancias. A sa\u00edda deste est\u00e1gio \u00e9 um servi\u00e7o de infer\u00eancias. Monitoramento. Estat\u00edsticas sobre a performance do modelo em produ\u00e7\u00e3o s\u00e3o coletadas . A sa\u00edda deste est\u00e1gio \u00e9 o disparo de um trigger que deve provocar uma nova execu\u00e7\u00e3o do pipeline em produ\u00e7\u00e3o ou indicar a necessidade de um novo ciclo de experimenta\u00e7\u00e3o. As etapas de an\u00e1lise explotar\u00f3ria de dados e an\u00e1lise de modelo ainda s\u00e3o etapas manuais e que necessitam de um trabalho extensivo por parte do cientista de dados, por exemplo.","title":"Etapas"},{"location":"concepts/mlops/ml_pipelines_automation/#caracteristicas_1","text":"Experimentos Orquestrados. Todo o experimento, etapas e transi\u00e7\u00f5es entre as etapas s\u00e3o automatizadas. Assim, cada itera\u00e7\u00e3o de experimenta\u00e7\u00e3o acontece de forma r\u00e1pida e h\u00e1 maior prontid\u00e3o para mover todo o pipeline do desenvolvimento para a produ\u00e7\u00e3o. Integra\u00e7\u00e3o e Entrega Cont\u00ednua do Pipeline. Treinamento Cont\u00ednuo (CT) do Modelo em Produ\u00e7\u00e3o. O modelo em produ\u00e7\u00e3o \u00e9 automaticamente retreinado usando dados atualizados e acionado atrav\u00e9s triggers. Simetria Experimental-Operacional. A implementa\u00e7\u00e3o do pipeline usada no ambiente de desenvolvimento \u00e9 tamb\u00e9m usada no ambiente de pr\u00e9-produ\u00e7\u00e3o e produ\u00e7\u00e3o (o que \u00e9 um aspecto-chave da pr\u00e1tica de MLOps para unificar DevOps). Entrega Cont\u00ednua do Modelo. (work in progress)","title":"Caracter\u00edsticas"},{"location":"concepts/mlops/ml_pipelines_automation/#componentes_1","text":"","title":"Componentes"},{"location":"concepts/mlops/ml_pipelines_automation/#servicos-de-teste-e-build","text":"Work in progress","title":"Servi\u00e7os de Teste e Build"},{"location":"concepts/mlops/ml_pipelines_automation/#servicos-de-deployment","text":"Work in progress","title":"Servi\u00e7os de Deployment"},{"location":"concepts/mlops/ml_pipelines_automation/#desafios_1","text":"Em um segundo n\u00edvel de automa\u00e7\u00e3o, praticamente todos os processos s\u00e3o executados automaticamente. Por conta disso, h\u00e1 um grande complexidade envolvida na implementa\u00e7\u00e3o do sistema.","title":"Desafios"},{"location":"concepts/mlops/model_registry/","text":"Work in progress","title":"Model Registry"},{"location":"concepts/mlops/testing_assets/","text":"Work in progress","title":"Testes Automatizados"},{"location":"concepts/mlops/versioning/","text":"Work in progress","title":"Versionamento"},{"location":"concepts/monitoring/","text":"Monitoramento \u00b6 Work in progress","title":"Monitoramento"},{"location":"concepts/monitoring/#monitoramento","text":"Work in progress","title":"Monitoramento"},{"location":"concepts/project_planning/challenges_in_model_development/","text":"Desafios no Desenvolvimento de Modelos \u00b6 Introdu\u00e7\u00e3o \u00b6 Desenvolver modelos tende a ser uma tarefa d\u00edficil. Contudo, n\u00e3o pelo treinamento ou escolha de (hiper)par\u00e2metros, mas sim por conta dos dados dispon\u00edveis e m\u00e9tricas de neg\u00f3cio que queremos atingir. Principais Problemas \u00b6 De acordo com Andrew Ng, os principais problemas enfretados no desenvolvimento (e manuten\u00e7\u00e3o) de modelos de ML s\u00e3o: Desempenho do modelo em desenvolvimento x em produ\u00e7\u00e3o M\u00e9tricas de desenvolvimento x de neg\u00f3cios Dados desbalanceados Desempenho no Desenvolvimento x Em Produ\u00e7\u00e3o \u00b6 O erro do modelo nas parti\u00e7\u00f5es de valida\u00e7\u00e3o e teste, geralmente, \u00e9 pouco informativo quanto \u00e0 performance do modelo. De fato, a performance real de um modelo aparece somente quando este vai para produ\u00e7\u00e3o, pois apenas a partir deste momento \u00e9 que o modelo est\u00e1 exposto a dados reais. Consequentemente, s\u00e3o necess\u00e1rias estrat\u00e9gias para atualizar rapidamente o modelo em produ\u00e7\u00e3o, tal como experiment\u00e1-lo em produ\u00e7\u00e3o antes de que seja disponibilizado totalmente para todos os usu\u00e1rios. M\u00e9trica de Desenvolvimento x M\u00e9trica de Neg\u00f3cios \u00b6 M\u00e9tricas de desenvolvimento s\u00e3o m\u00e9tricas comuns utilizadas para testar a performance de um modelo durante seu desenvolvimento, como: acur\u00e1cia, precis\u00e3o, revoca\u00e7\u00e3o, etc. J\u00e1 m\u00e9tricas de neg\u00f3cios s\u00e3o m\u00e9tricas que indicam precisamente o qu\u00e3o bem (ou eficiente) um problema em quest\u00e3o est\u00e1 sendo resolvido atrav\u00e9s de uma estrat\u00e9gia espec\u00edfica. No geral, tais m\u00e9tricas acabam sendo KPIs. Ou seja, indicadores-chaves de desempenho que medem quantitativamente o qu\u00e3o eficiente est\u00e1 sendo uma estrat\u00e9gia espec\u00edfica (no caso, modelos de IA) em agregar valor ao neg\u00f3cio. Por serem medirem aspectos totalmente diferentes, nem sempre o modelo com melhor acur\u00e1cia \u00e9 aquele que possui melhor KPI. Consequentemente, desenvolver um modelo que atenda com sucesso ambas m\u00e9tricas \u00e9 uma tarefa consideravelmente complexa. Dados Desbalanceados \u00b6 Dados desbalanceados \u00e9 um dos problemas mais comuns no desenvolvimento de modelos. Desde classes desbalanceadas at\u00e9 distribui\u00e7\u00f5es consideravelmente enviesadas, \u00e9 muito dif\u00edcil tratar conjuntos de dados desbalanceados, pois h\u00e1 muita informa\u00e7\u00e3o sobre certo \"peda\u00e7o\" do conjunto de dados, enquanto h\u00e1 pouca informa\u00e7\u00e3o sobre qualquer outro \"peda\u00e7o\". Embora existam t\u00e9cnicas reamostragem a fim de minimizar os impactos do desbalanceamento, no geral elas s\u00e3o incapazes de produzir modelos confi\u00e1veis. Afinal, como podemos garantir que: O modelo desfavore\u00e7a pessoas por conta de caracter\u00edstica \u00e9tnico-raciais? As classes minorit\u00e1rias representam corretamente o mundo real? Os dados n\u00e3o possuem tendenciosidades impl\u00edcitas? De fato, o principal problema da constru\u00e7\u00e3o de modelos de IA na ind\u00fastria s\u00e3o os dados. Concept Drift e Data Drift \u00b6 Work in progress Refer\u00eancias \u00b6 Introduction to Machine Learning in Production by Coursera","title":"Desafios no Desenvolvimento de Modelos"},{"location":"concepts/project_planning/challenges_in_model_development/#desafios-no-desenvolvimento-de-modelos","text":"","title":"Desafios no Desenvolvimento de Modelos"},{"location":"concepts/project_planning/challenges_in_model_development/#introducao","text":"Desenvolver modelos tende a ser uma tarefa d\u00edficil. Contudo, n\u00e3o pelo treinamento ou escolha de (hiper)par\u00e2metros, mas sim por conta dos dados dispon\u00edveis e m\u00e9tricas de neg\u00f3cio que queremos atingir.","title":"Introdu\u00e7\u00e3o"},{"location":"concepts/project_planning/challenges_in_model_development/#principais-problemas","text":"De acordo com Andrew Ng, os principais problemas enfretados no desenvolvimento (e manuten\u00e7\u00e3o) de modelos de ML s\u00e3o: Desempenho do modelo em desenvolvimento x em produ\u00e7\u00e3o M\u00e9tricas de desenvolvimento x de neg\u00f3cios Dados desbalanceados","title":"Principais Problemas"},{"location":"concepts/project_planning/challenges_in_model_development/#desempenho-no-desenvolvimento-x-em-producao","text":"O erro do modelo nas parti\u00e7\u00f5es de valida\u00e7\u00e3o e teste, geralmente, \u00e9 pouco informativo quanto \u00e0 performance do modelo. De fato, a performance real de um modelo aparece somente quando este vai para produ\u00e7\u00e3o, pois apenas a partir deste momento \u00e9 que o modelo est\u00e1 exposto a dados reais. Consequentemente, s\u00e3o necess\u00e1rias estrat\u00e9gias para atualizar rapidamente o modelo em produ\u00e7\u00e3o, tal como experiment\u00e1-lo em produ\u00e7\u00e3o antes de que seja disponibilizado totalmente para todos os usu\u00e1rios.","title":"Desempenho no Desenvolvimento x Em Produ\u00e7\u00e3o"},{"location":"concepts/project_planning/challenges_in_model_development/#metrica-de-desenvolvimento-x-metrica-de-negocios","text":"M\u00e9tricas de desenvolvimento s\u00e3o m\u00e9tricas comuns utilizadas para testar a performance de um modelo durante seu desenvolvimento, como: acur\u00e1cia, precis\u00e3o, revoca\u00e7\u00e3o, etc. J\u00e1 m\u00e9tricas de neg\u00f3cios s\u00e3o m\u00e9tricas que indicam precisamente o qu\u00e3o bem (ou eficiente) um problema em quest\u00e3o est\u00e1 sendo resolvido atrav\u00e9s de uma estrat\u00e9gia espec\u00edfica. No geral, tais m\u00e9tricas acabam sendo KPIs. Ou seja, indicadores-chaves de desempenho que medem quantitativamente o qu\u00e3o eficiente est\u00e1 sendo uma estrat\u00e9gia espec\u00edfica (no caso, modelos de IA) em agregar valor ao neg\u00f3cio. Por serem medirem aspectos totalmente diferentes, nem sempre o modelo com melhor acur\u00e1cia \u00e9 aquele que possui melhor KPI. Consequentemente, desenvolver um modelo que atenda com sucesso ambas m\u00e9tricas \u00e9 uma tarefa consideravelmente complexa.","title":"M\u00e9trica de Desenvolvimento x M\u00e9trica de Neg\u00f3cios"},{"location":"concepts/project_planning/challenges_in_model_development/#dados-desbalanceados","text":"Dados desbalanceados \u00e9 um dos problemas mais comuns no desenvolvimento de modelos. Desde classes desbalanceadas at\u00e9 distribui\u00e7\u00f5es consideravelmente enviesadas, \u00e9 muito dif\u00edcil tratar conjuntos de dados desbalanceados, pois h\u00e1 muita informa\u00e7\u00e3o sobre certo \"peda\u00e7o\" do conjunto de dados, enquanto h\u00e1 pouca informa\u00e7\u00e3o sobre qualquer outro \"peda\u00e7o\". Embora existam t\u00e9cnicas reamostragem a fim de minimizar os impactos do desbalanceamento, no geral elas s\u00e3o incapazes de produzir modelos confi\u00e1veis. Afinal, como podemos garantir que: O modelo desfavore\u00e7a pessoas por conta de caracter\u00edstica \u00e9tnico-raciais? As classes minorit\u00e1rias representam corretamente o mundo real? Os dados n\u00e3o possuem tendenciosidades impl\u00edcitas? De fato, o principal problema da constru\u00e7\u00e3o de modelos de IA na ind\u00fastria s\u00e3o os dados.","title":"Dados Desbalanceados"},{"location":"concepts/project_planning/challenges_in_model_development/#concept-drift-e-data-drift","text":"Work in progress","title":"Concept Drift e Data Drift"},{"location":"concepts/project_planning/challenges_in_model_development/#referencias","text":"Introduction to Machine Learning in Production by Coursera","title":"Refer\u00eancias"},{"location":"concepts/project_planning/crisp_ml/","text":"Work in progress","title":"CRISP-ML(Q)"},{"location":"concepts/project_planning/data_centric_ai/","text":"Data-Centric AI \u00b6 Introdu\u00e7\u00e3o \u00b6 De acordo com Andrew Ng, h\u00e1 duas maneiras que podemos adotar para desenvolver modelos de ML: Model-centric (centrado no modelo). Estrat\u00e9gia onde dado um conjunto de dados fixo, aplicamos diferentes algoritmos e estrat\u00e9gias para encontrar o melhor modelo para aqueles dados e, consequentemente, o melhor modelo para a tarefa em quest\u00e3o. Data-centric (centrado no dado). Estrat\u00e9gia onde dado um conjunto de dados fixo, aplicamos diferentes estrat\u00e9gias de processamento de dados a fim de torn\u00e1-los o mais representativos poss\u00edvel, de modo que qualquer algoritmo minimamente complexo seja capaz de aprend\u00ea-los e assim performar bem na tarefa em quest\u00e3o. Embora o uso do Model-centric seja muito comum na academia, na ind\u00fastria \u00e9 fortemente recomendado (principalmente por Andrew Ng) o uso da abordagem Data-centric. Mais precisamente, dado um problema resolv\u00edvel por meio de ML, devemos buscar aumentar ao m\u00e1ximo poss\u00edvel a qualidade dos dados, tornando-os \"bom dados\" (good data), sendo \"good data\": Definidos consistentemente (a defini\u00e7\u00e3o de cada categoria \u00e9 n\u00e3o-amb\u00edguia) Todos os casos importantes s\u00e3o cobertos (cobertura de todas as possibilidades de entrada) Feedback constante de altera\u00e7\u00f5es (concept drift e data drift s\u00e3o monitorados) Quantidade de dados apropriada. Refer\u00eancias \u00b6 A Chat with Andrew on MLOps: From Model-centric to Data-centric AI Data-centric AI Community","title":"IA Centrada em Dados"},{"location":"concepts/project_planning/data_centric_ai/#data-centric-ai","text":"","title":"Data-Centric AI"},{"location":"concepts/project_planning/data_centric_ai/#introducao","text":"De acordo com Andrew Ng, h\u00e1 duas maneiras que podemos adotar para desenvolver modelos de ML: Model-centric (centrado no modelo). Estrat\u00e9gia onde dado um conjunto de dados fixo, aplicamos diferentes algoritmos e estrat\u00e9gias para encontrar o melhor modelo para aqueles dados e, consequentemente, o melhor modelo para a tarefa em quest\u00e3o. Data-centric (centrado no dado). Estrat\u00e9gia onde dado um conjunto de dados fixo, aplicamos diferentes estrat\u00e9gias de processamento de dados a fim de torn\u00e1-los o mais representativos poss\u00edvel, de modo que qualquer algoritmo minimamente complexo seja capaz de aprend\u00ea-los e assim performar bem na tarefa em quest\u00e3o. Embora o uso do Model-centric seja muito comum na academia, na ind\u00fastria \u00e9 fortemente recomendado (principalmente por Andrew Ng) o uso da abordagem Data-centric. Mais precisamente, dado um problema resolv\u00edvel por meio de ML, devemos buscar aumentar ao m\u00e1ximo poss\u00edvel a qualidade dos dados, tornando-os \"bom dados\" (good data), sendo \"good data\": Definidos consistentemente (a defini\u00e7\u00e3o de cada categoria \u00e9 n\u00e3o-amb\u00edguia) Todos os casos importantes s\u00e3o cobertos (cobertura de todas as possibilidades de entrada) Feedback constante de altera\u00e7\u00f5es (concept drift e data drift s\u00e3o monitorados) Quantidade de dados apropriada.","title":"Introdu\u00e7\u00e3o"},{"location":"concepts/project_planning/data_centric_ai/#referencias","text":"A Chat with Andrew on MLOps: From Model-centric to Data-centric AI Data-centric AI Community","title":"Refer\u00eancias"},{"location":"concepts/serving/","text":"Model Serving \u00b6 Introdu\u00e7\u00e3o \u00b6 O model serving \u00e9 a etapa do fluxo de cria\u00e7\u00e3o de um modelo de machine learning (ML) que tem como objetivo disponibilizar o modelo para uso em conjunto de estrat\u00e9gias de implanta\u00e7\u00e3o (deployment). A forma como um modelo \u00e9 disponibilizado para a execu\u00e7\u00e3o de infer\u00eancias afeta diretamente, tanto intera\u00e7\u00e3o do usu\u00e1rio (ou aplica\u00e7\u00e3o) com ele, quanto seu desempenho e manutenibilidade. Por isso, ao dedicir qual estrat\u00e9gia utilizar, devemos levar em considera\u00e7\u00e3o fatores como: Padr\u00e3o de treinamento e infer\u00eancia (em lotes ou fluxo) Disponibilidade offline (poss\u00edvel fazer infer\u00eancias offline ou apenas online) Lat\u00eancia de rede (caso necess\u00e1rio envio de dados) Seguran\u00e7a de dados sens\u00edveis Padr\u00e3o de atualiza\u00e7\u00e3o do modelo Recursos de computa\u00e7\u00e3o dispon\u00edvel De fato, esses s\u00e3o os principais aspectos que nos levam a escolher uma estrat\u00e9gia de serving . Serving x Deployment Termos como model serving e model deployment s\u00e3o utilizados de forma intercambi\u00e1vel na interwebsv Para tornar as explica\u00e7\u00f5es mais claras e consistentes, vamos definir: Model serving . Forma que um modelo \u00e9 disponiblizado para infer\u00eancias Model deployment . Como a forma que o modelo \u00e9 disponiblizado \u00e9 realizada Por exemplo, podemos servir um modelo como um servi\u00e7o encapsulado em um container e cuja implanta\u00e7\u00e3o (ou deployment ) se d\u00e1 atrav\u00e9s de um processo de CI/CD em Modo Can\u00e1rio . Padr\u00f5es de Treinamento e Infer\u00eancia \u00b6 Os padr\u00f5es de treinamento e infer\u00eancia s\u00e3o fatores fundamentais na decis\u00e3o de como um modelo deve ser disponibilizado, uma vez que h\u00e1 estrat\u00e9gias de serving que n\u00e3o suportam um determinado padr\u00e3o (ou combina\u00e7\u00e3o de padr\u00f5es) de treinamento e infer\u00eancia. Padr\u00f5es de (re)Treinamento de Modelos \u00b6 Considerando um cen\u00e1rio onde um modelo j\u00e1 est\u00e1 treinado e pronto para produ\u00e7\u00e3o, a preocupa\u00e7\u00e3o com seu padr\u00e3o de treinamento se d\u00e1 pela necessidade do seu retreinamento . Afinal, uma vez que o modelo est\u00e1 em produ\u00e7\u00e3o, ele \u00e9 exposto continuamente a dados novos do mundo real (e n\u00e3o apenas a uma amostra est\u00e1tica) e, consequentemente, torna-se obsoleto (fen\u00f4meno conhecido como model decay ). Para que o modelo em produ\u00e7\u00e3o mantenha um bom desempenho na maior parte do tempo, ele deve ser retreinado com uma certa frequ\u00eancia. Modelos de ML s\u00e3o treinados de duas formas: Em Lotes (batches), conhecido como Aprendizado em Lotes ou Offline/Batch Learning. Incremental, conhecido como Aprendizado Incremental Online Learning. Logo, o retreinamento tamb\u00e9m pode acontecer em lotes ou de forma incremental. Em Lotes \u00b6 No retreinamento em lotes, um modelo \u00e9 retreinado ap\u00f3s um tempo consider\u00e1vel em produ\u00e7\u00e3o. Esse retreinamento pode acontecer em intervalos fixos (por exemplo, a cada 30 dias) ou quando um limite inferior de desempenho \u00e9 atingindo. O principal problema do retreinamento em lotes \u00e9 que, no caso de um intervalos fixo, a degrada\u00e7\u00e3o do modelo pode acontecer em diferentes velocidades, o que torna dif\u00edcil encontrar uma frequ\u00eancia de retreinamento ideal. Por outro lado, monitorar um modelo em produ\u00e7\u00e3o e retrein\u00e1-lo com base em alguma m\u00e9trica de desempenho, \u00e9 um processo consideravelmente complexo tanto pela defini\u00e7\u00e3o e c\u00e1lculo da m\u00e9trica em si, quanto pela necessidade de toda uma solu\u00e7\u00e3o de monitoramento. Aprendizado Incremental \u00b6 No \"aprendizado incremental\", o modelo \u00e9 treinado regularmente conforme novos dados s\u00e3o disponibilizados \u00e0 aplica\u00e7\u00e3o (e.g. real-time data streams). O retreinamento pode ocorrer em um \u00fanico dado novo ou pequenos grupos de dados, denominados mini-batches . O principal problema do Aprendizado Incremental \u00e9 que, quando em produ\u00e7\u00e3o, a entrada de dados ruins (e.g, ru\u00eddos) tende a prejudicar consideravalmente o desempenho do modelo. Padr\u00f5es de Infer\u00eancia do Modelo \u00b6 Da mesma forma que treinados, modelos de ML podem ser dispostos para inferir dados de duas formas: Em Batches ou Sob-demanda. Na infer\u00eancia em batches, o modelo executa predi\u00e7\u00f5es sobre um \"grande\" volume de dados de uma vez e s\u00f3 ent\u00e3o retorna os resultados. Na infer\u00eancia em tempo real, as predi\u00e7\u00f5es s\u00e3o executadas sob-demanda para cada dado (ou pequenos conjuntos) de entrada e, em seguida, o resultado j\u00e1 \u00e9 retornado. O que \u00e9 grande? Grande \u00e9 relativo, n\u00e3o \u00e9 mesmo? De qualquer forma, no contexto de infer\u00eancia em batches significa que ao inv\u00e9s de executar infer\u00eancias sob-demanda em pequenos conjuntos de dados (e.g. 1 a ~300 inst\u00e2ncias), executa-se para v\u00e1rias entradas em conjunto (e.g., mais do que 500 ou 10 mil inst\u00e2ncias) Padr\u00f5es de Model Serving \u00b6 Existem diversas abordagens para servir um modelo, cada um com suas vantagens e desvantagens. Alguns exemplos s\u00e3o: Modelo como Parte da Aplica\u00e7\u00e3o (Static Deployment) Model-as-a-Dependency (MaaD) Model-as-a-Service (MaaS) Serverless Servig/Deployment Hybrid-Serving (Federated Learning) Refer\u00eancias \u00b6 Three Levels of ML Software Machine Learning Engineering by Andriy Burkov","title":"Model Serving"},{"location":"concepts/serving/#model-serving","text":"","title":"Model Serving"},{"location":"concepts/serving/#introducao","text":"O model serving \u00e9 a etapa do fluxo de cria\u00e7\u00e3o de um modelo de machine learning (ML) que tem como objetivo disponibilizar o modelo para uso em conjunto de estrat\u00e9gias de implanta\u00e7\u00e3o (deployment). A forma como um modelo \u00e9 disponibilizado para a execu\u00e7\u00e3o de infer\u00eancias afeta diretamente, tanto intera\u00e7\u00e3o do usu\u00e1rio (ou aplica\u00e7\u00e3o) com ele, quanto seu desempenho e manutenibilidade. Por isso, ao dedicir qual estrat\u00e9gia utilizar, devemos levar em considera\u00e7\u00e3o fatores como: Padr\u00e3o de treinamento e infer\u00eancia (em lotes ou fluxo) Disponibilidade offline (poss\u00edvel fazer infer\u00eancias offline ou apenas online) Lat\u00eancia de rede (caso necess\u00e1rio envio de dados) Seguran\u00e7a de dados sens\u00edveis Padr\u00e3o de atualiza\u00e7\u00e3o do modelo Recursos de computa\u00e7\u00e3o dispon\u00edvel De fato, esses s\u00e3o os principais aspectos que nos levam a escolher uma estrat\u00e9gia de serving . Serving x Deployment Termos como model serving e model deployment s\u00e3o utilizados de forma intercambi\u00e1vel na interwebsv Para tornar as explica\u00e7\u00f5es mais claras e consistentes, vamos definir: Model serving . Forma que um modelo \u00e9 disponiblizado para infer\u00eancias Model deployment . Como a forma que o modelo \u00e9 disponiblizado \u00e9 realizada Por exemplo, podemos servir um modelo como um servi\u00e7o encapsulado em um container e cuja implanta\u00e7\u00e3o (ou deployment ) se d\u00e1 atrav\u00e9s de um processo de CI/CD em Modo Can\u00e1rio .","title":"Introdu\u00e7\u00e3o"},{"location":"concepts/serving/#padroes-de-treinamento-e-inferencia","text":"Os padr\u00f5es de treinamento e infer\u00eancia s\u00e3o fatores fundamentais na decis\u00e3o de como um modelo deve ser disponibilizado, uma vez que h\u00e1 estrat\u00e9gias de serving que n\u00e3o suportam um determinado padr\u00e3o (ou combina\u00e7\u00e3o de padr\u00f5es) de treinamento e infer\u00eancia.","title":"Padr\u00f5es de Treinamento e Infer\u00eancia"},{"location":"concepts/serving/#padroes-de-retreinamento-de-modelos","text":"Considerando um cen\u00e1rio onde um modelo j\u00e1 est\u00e1 treinado e pronto para produ\u00e7\u00e3o, a preocupa\u00e7\u00e3o com seu padr\u00e3o de treinamento se d\u00e1 pela necessidade do seu retreinamento . Afinal, uma vez que o modelo est\u00e1 em produ\u00e7\u00e3o, ele \u00e9 exposto continuamente a dados novos do mundo real (e n\u00e3o apenas a uma amostra est\u00e1tica) e, consequentemente, torna-se obsoleto (fen\u00f4meno conhecido como model decay ). Para que o modelo em produ\u00e7\u00e3o mantenha um bom desempenho na maior parte do tempo, ele deve ser retreinado com uma certa frequ\u00eancia. Modelos de ML s\u00e3o treinados de duas formas: Em Lotes (batches), conhecido como Aprendizado em Lotes ou Offline/Batch Learning. Incremental, conhecido como Aprendizado Incremental Online Learning. Logo, o retreinamento tamb\u00e9m pode acontecer em lotes ou de forma incremental.","title":"Padr\u00f5es de (re)Treinamento de Modelos"},{"location":"concepts/serving/#em-lotes","text":"No retreinamento em lotes, um modelo \u00e9 retreinado ap\u00f3s um tempo consider\u00e1vel em produ\u00e7\u00e3o. Esse retreinamento pode acontecer em intervalos fixos (por exemplo, a cada 30 dias) ou quando um limite inferior de desempenho \u00e9 atingindo. O principal problema do retreinamento em lotes \u00e9 que, no caso de um intervalos fixo, a degrada\u00e7\u00e3o do modelo pode acontecer em diferentes velocidades, o que torna dif\u00edcil encontrar uma frequ\u00eancia de retreinamento ideal. Por outro lado, monitorar um modelo em produ\u00e7\u00e3o e retrein\u00e1-lo com base em alguma m\u00e9trica de desempenho, \u00e9 um processo consideravelmente complexo tanto pela defini\u00e7\u00e3o e c\u00e1lculo da m\u00e9trica em si, quanto pela necessidade de toda uma solu\u00e7\u00e3o de monitoramento.","title":"Em Lotes"},{"location":"concepts/serving/#aprendizado-incremental","text":"No \"aprendizado incremental\", o modelo \u00e9 treinado regularmente conforme novos dados s\u00e3o disponibilizados \u00e0 aplica\u00e7\u00e3o (e.g. real-time data streams). O retreinamento pode ocorrer em um \u00fanico dado novo ou pequenos grupos de dados, denominados mini-batches . O principal problema do Aprendizado Incremental \u00e9 que, quando em produ\u00e7\u00e3o, a entrada de dados ruins (e.g, ru\u00eddos) tende a prejudicar consideravalmente o desempenho do modelo.","title":"Aprendizado Incremental"},{"location":"concepts/serving/#padroes-de-inferencia-do-modelo","text":"Da mesma forma que treinados, modelos de ML podem ser dispostos para inferir dados de duas formas: Em Batches ou Sob-demanda. Na infer\u00eancia em batches, o modelo executa predi\u00e7\u00f5es sobre um \"grande\" volume de dados de uma vez e s\u00f3 ent\u00e3o retorna os resultados. Na infer\u00eancia em tempo real, as predi\u00e7\u00f5es s\u00e3o executadas sob-demanda para cada dado (ou pequenos conjuntos) de entrada e, em seguida, o resultado j\u00e1 \u00e9 retornado. O que \u00e9 grande? Grande \u00e9 relativo, n\u00e3o \u00e9 mesmo? De qualquer forma, no contexto de infer\u00eancia em batches significa que ao inv\u00e9s de executar infer\u00eancias sob-demanda em pequenos conjuntos de dados (e.g. 1 a ~300 inst\u00e2ncias), executa-se para v\u00e1rias entradas em conjunto (e.g., mais do que 500 ou 10 mil inst\u00e2ncias)","title":"Padr\u00f5es de Infer\u00eancia do Modelo"},{"location":"concepts/serving/#padroes-de-model-serving","text":"Existem diversas abordagens para servir um modelo, cada um com suas vantagens e desvantagens. Alguns exemplos s\u00e3o: Modelo como Parte da Aplica\u00e7\u00e3o (Static Deployment) Model-as-a-Dependency (MaaD) Model-as-a-Service (MaaS) Serverless Servig/Deployment Hybrid-Serving (Federated Learning)","title":"Padr\u00f5es de Model Serving"},{"location":"concepts/serving/#referencias","text":"Three Levels of ML Software Machine Learning Engineering by Andriy Burkov","title":"Refer\u00eancias"},{"location":"concepts/serving/federated_learning/","text":"Federated Learning \u00b6 Introdu\u00e7\u00e3o \u00b6 Hybrid-Serving, mais conhecido como Federated Learning \u00e9 uma forma relativamente nova, por\u00e9m, em alta, de servir modelos aos usu\u00e1rios, principalmente de dispositivos m\u00f3veis. Basicamente, trata-se de estrat\u00e9gia onde um modelo gen\u00e9rico \u00e9 disponibilizado para uma grande quantidade de usu\u00e1rios e, ent\u00e3o, cada usu\u00e1rio passa a ter um modelo espec\u00edfico para si que \u00e9 retreinado (ou especializado) em seus dados. Mais precisamente: H\u00e1 um modelo gen\u00e9rico no lado do servidor (ou server-side) pr\u00e9-treinado em dados do mundo real. Tal modelo \u00e9 usado como ponto de partida para novos usu\u00e1rios da aplica\u00e7\u00e3o. Do lado dos usu\u00e1rios (ou user-side), h\u00e1 modelos especializados e \u00fanicos para cada usu\u00e1rio (que partem do modelo gen\u00e9rico no server-side), de forma que o retreinamento (i.e. especializa\u00e7\u00e3o) destes modelos para este usu\u00e1rio ocorre no dispositivo do usu\u00e1rio. Uma vez especializados, os (hiper)par\u00e2metros de cada modelo s\u00e3o enviados para o servidor. Assim, o modelo do servidor \u00e9 ajustado a fim de que as tend\u00eancias reais de toda a comunidade de usu\u00e1rios sejam cobertas pelo modelo e, ent\u00e3o, este novo modelo passa a ser o novo modelo inicial para todos os usu\u00e1rios. Para que n\u00e3o haja desvantagens aos usu\u00e1rios, o processo de atualiza\u00e7\u00e3o dos modelos ocorre somente quando o aparelho est\u00e1 ocioso, conectado \u00e0 uma rede WiFi e carregando. Ainda, os testes s\u00e3o feitos nos dispositivos. Portanto, o modelo rec\u00e9m-adotado do servidor \u00e9 enviado aos dispositivos e testado quanto \u00e0 funcionalidade. A principal vantagem dessa abordagem \u00e9 que: Os dados pessoais necess\u00e1rios para o treinamento (e teste) nunca saem do dom\u00ednio do usuario. Enquanto que ainda assim \u00e9 poss\u00edvel atualizar os modelos com base nas tend\u00eancias da comunidade. Em outras palavras, \u00e9 poss\u00edvel treinar modelos de alta precis\u00e3o sem ter que armazenar toneladas de dados (provavelmente pessoais) na nuvem. Por\u00e9m, a grande desvantagem \u00e9 que a especializa\u00e7\u00e3o do modelo \u00e9 custosa para usu\u00e1rios. Afinal, os modelos de ML s\u00e3o desenvolvidos com conjuntos de dados grandes e homog\u00eaneos em um hardware poderoso. Refer\u00eancias \u00b6 Three Levels of ML Software","title":"Federated Learning"},{"location":"concepts/serving/federated_learning/#federated-learning","text":"","title":"Federated Learning"},{"location":"concepts/serving/federated_learning/#introducao","text":"Hybrid-Serving, mais conhecido como Federated Learning \u00e9 uma forma relativamente nova, por\u00e9m, em alta, de servir modelos aos usu\u00e1rios, principalmente de dispositivos m\u00f3veis. Basicamente, trata-se de estrat\u00e9gia onde um modelo gen\u00e9rico \u00e9 disponibilizado para uma grande quantidade de usu\u00e1rios e, ent\u00e3o, cada usu\u00e1rio passa a ter um modelo espec\u00edfico para si que \u00e9 retreinado (ou especializado) em seus dados. Mais precisamente: H\u00e1 um modelo gen\u00e9rico no lado do servidor (ou server-side) pr\u00e9-treinado em dados do mundo real. Tal modelo \u00e9 usado como ponto de partida para novos usu\u00e1rios da aplica\u00e7\u00e3o. Do lado dos usu\u00e1rios (ou user-side), h\u00e1 modelos especializados e \u00fanicos para cada usu\u00e1rio (que partem do modelo gen\u00e9rico no server-side), de forma que o retreinamento (i.e. especializa\u00e7\u00e3o) destes modelos para este usu\u00e1rio ocorre no dispositivo do usu\u00e1rio. Uma vez especializados, os (hiper)par\u00e2metros de cada modelo s\u00e3o enviados para o servidor. Assim, o modelo do servidor \u00e9 ajustado a fim de que as tend\u00eancias reais de toda a comunidade de usu\u00e1rios sejam cobertas pelo modelo e, ent\u00e3o, este novo modelo passa a ser o novo modelo inicial para todos os usu\u00e1rios. Para que n\u00e3o haja desvantagens aos usu\u00e1rios, o processo de atualiza\u00e7\u00e3o dos modelos ocorre somente quando o aparelho est\u00e1 ocioso, conectado \u00e0 uma rede WiFi e carregando. Ainda, os testes s\u00e3o feitos nos dispositivos. Portanto, o modelo rec\u00e9m-adotado do servidor \u00e9 enviado aos dispositivos e testado quanto \u00e0 funcionalidade. A principal vantagem dessa abordagem \u00e9 que: Os dados pessoais necess\u00e1rios para o treinamento (e teste) nunca saem do dom\u00ednio do usuario. Enquanto que ainda assim \u00e9 poss\u00edvel atualizar os modelos com base nas tend\u00eancias da comunidade. Em outras palavras, \u00e9 poss\u00edvel treinar modelos de alta precis\u00e3o sem ter que armazenar toneladas de dados (provavelmente pessoais) na nuvem. Por\u00e9m, a grande desvantagem \u00e9 que a especializa\u00e7\u00e3o do modelo \u00e9 custosa para usu\u00e1rios. Afinal, os modelos de ML s\u00e3o desenvolvidos com conjuntos de dados grandes e homog\u00eaneos em um hardware poderoso.","title":"Introdu\u00e7\u00e3o"},{"location":"concepts/serving/federated_learning/#referencias","text":"Three Levels of ML Software","title":"Refer\u00eancias"},{"location":"concepts/serving/model_as_a_dependency/","text":"Model as a Dependency (MaaD) \u00b6 Introdu\u00e7\u00e3o \u00b6 A estrat\u00e9gia MaaD \u00e9 bem parecida com static deployment . Contudo, ao inv\u00e9s de empacotarmos o modelo como parte da aplica\u00e7\u00e3o, ele \u00e9 definido como uma depend\u00eancia e empacotado de forma que seja poss\u00edvel atualiz\u00e1-lo individualmente. Por exemplo, podemos empacotar um modelo como: Um pacote instal\u00e1vel (e.g. um pacote Python) definido como uma depend\u00eancia da aplica\u00e7\u00e3o. Arquivo serializado que \u00e9 importado (e deserializado) pela aplica\u00e7\u00e3o durante sua inicializa\u00e7\u00e3o ou em tempo de execu\u00e7\u00e3o Arquivo com os par\u00e2metros do modelo que pode ser utilizado para atualiz\u00e1-lo. Neste cen\u00e1rio, para utilizar o modelo, a aplica\u00e7\u00e3o s\u00f3 precisa invocar um m\u00e9todo de infer\u00eancia deste. Vantagens x Desvantagens \u00b6 Model as as Dependency \u00e9 uma estrat\u00e9gia adequada para modelos simples que precisam estar dispon\u00edveis o tempo todo (mesmo se o usu\u00e1rio estiver offline). Tamb\u00e9m \u00e9 adequado tanto para infer\u00eancias quanto retreinamento em batches ou fluxo. Por outro lado, modelos \"pesados\" devem ser evitados pelo alto custo de computa\u00e7\u00e3o no dispositivo do usu\u00e1rio. Vantagens \u00b6 N\u00e3o \u00e9 preciso enviar dados do usu\u00e1rio para um servidor (ou qualquer recurso) externo ao dispositivo do usu\u00e1rio O modelo estar\u00e1 sempre dispon\u00edvel, mesmo se o usu\u00e1rio estiver offline. Caso seja um modelo simples, sem necessidade de computa\u00e7\u00f5es r\u00e1pidas ou pesadas, o tempo de infer\u00eancia \u00e9 muito mais r\u00e1pido quando comparado com qualquer outra estrat\u00e9gia O modelo pode ser atualizado sem a necessidade de atualizar toda a aplica\u00e7\u00e3o Desvantagens \u00b6 Executar o monitoramento de performance do modelo \u00e9 extremamente dif\u00edcil Se a computa\u00e7\u00e3o do modelo for cara, execut\u00e1-la no dispositivo do usu\u00e1rio pode ser ineficiente ou prejudicar a experi\u00eancia do usu\u00e1rio Dependendo da estrat\u00e9gia de empacotamento do modelo, t\u00e9cnicas de engenharia reversa podem ser aplicadas para manipular o resultado das infer\u00eancias Exemplos \u00b6","title":"Model as a Dependency"},{"location":"concepts/serving/model_as_a_dependency/#model-as-a-dependency-maad","text":"","title":"Model as a Dependency (MaaD)"},{"location":"concepts/serving/model_as_a_dependency/#introducao","text":"A estrat\u00e9gia MaaD \u00e9 bem parecida com static deployment . Contudo, ao inv\u00e9s de empacotarmos o modelo como parte da aplica\u00e7\u00e3o, ele \u00e9 definido como uma depend\u00eancia e empacotado de forma que seja poss\u00edvel atualiz\u00e1-lo individualmente. Por exemplo, podemos empacotar um modelo como: Um pacote instal\u00e1vel (e.g. um pacote Python) definido como uma depend\u00eancia da aplica\u00e7\u00e3o. Arquivo serializado que \u00e9 importado (e deserializado) pela aplica\u00e7\u00e3o durante sua inicializa\u00e7\u00e3o ou em tempo de execu\u00e7\u00e3o Arquivo com os par\u00e2metros do modelo que pode ser utilizado para atualiz\u00e1-lo. Neste cen\u00e1rio, para utilizar o modelo, a aplica\u00e7\u00e3o s\u00f3 precisa invocar um m\u00e9todo de infer\u00eancia deste.","title":"Introdu\u00e7\u00e3o"},{"location":"concepts/serving/model_as_a_dependency/#vantagens-x-desvantagens","text":"Model as as Dependency \u00e9 uma estrat\u00e9gia adequada para modelos simples que precisam estar dispon\u00edveis o tempo todo (mesmo se o usu\u00e1rio estiver offline). Tamb\u00e9m \u00e9 adequado tanto para infer\u00eancias quanto retreinamento em batches ou fluxo. Por outro lado, modelos \"pesados\" devem ser evitados pelo alto custo de computa\u00e7\u00e3o no dispositivo do usu\u00e1rio.","title":"Vantagens x Desvantagens"},{"location":"concepts/serving/model_as_a_dependency/#vantagens","text":"N\u00e3o \u00e9 preciso enviar dados do usu\u00e1rio para um servidor (ou qualquer recurso) externo ao dispositivo do usu\u00e1rio O modelo estar\u00e1 sempre dispon\u00edvel, mesmo se o usu\u00e1rio estiver offline. Caso seja um modelo simples, sem necessidade de computa\u00e7\u00f5es r\u00e1pidas ou pesadas, o tempo de infer\u00eancia \u00e9 muito mais r\u00e1pido quando comparado com qualquer outra estrat\u00e9gia O modelo pode ser atualizado sem a necessidade de atualizar toda a aplica\u00e7\u00e3o","title":"Vantagens"},{"location":"concepts/serving/model_as_a_dependency/#desvantagens","text":"Executar o monitoramento de performance do modelo \u00e9 extremamente dif\u00edcil Se a computa\u00e7\u00e3o do modelo for cara, execut\u00e1-la no dispositivo do usu\u00e1rio pode ser ineficiente ou prejudicar a experi\u00eancia do usu\u00e1rio Dependendo da estrat\u00e9gia de empacotamento do modelo, t\u00e9cnicas de engenharia reversa podem ser aplicadas para manipular o resultado das infer\u00eancias","title":"Desvantagens"},{"location":"concepts/serving/model_as_a_dependency/#exemplos","text":"","title":"Exemplos"},{"location":"concepts/serving/model_as_a_service/","text":"Model as a Service (MaaS) \u00b6 Introdu\u00e7\u00e3o \u00b6 A estrat\u00e9gia Model-as-a-Service \u00e9 a mais adotada para servir modelos de ML. Nela, o modelo \u00e9 abstra\u00eddo em um servi\u00e7o (tipicamente web) que recebe requisi\u00e7\u00f5es de infer\u00eancia. Ap\u00f3s executada as infer\u00eancias, o servi\u00e7o retorna os resultados ao requerente. Dependendo da implementa\u00e7\u00e3o, o servi\u00e7o pode receber tanto batches de dados para infer\u00eancia, quanto entradas individuais. Imagem: Exemplo gen\u00e9rico da arquitetura Model-as-a-Service, onde um dispositivo faz requisi\u00e7\u00f5es de infer\u00eancia atrav\u00e9s de uma interface e ent\u00e3o recebe como resposta o resultado da predi\u00e7\u00e3o. Sobre Servi\u00e7os No contexto de arquitetura de software, um servi\u00e7o \u00e9 uma unidade de software auto-contida respons\u00e1vel por executar uma tarefa espec\u00edfica. Um servi\u00e7o deve conter todo o c\u00f3digo e dados necess\u00e1rios para executar sua tarefa, sendo implantando (geralmente) em um ambiente totalmente dedicado para si. Demais componentes do software (ou arquitetura) interagem com o servi\u00e7o atrav\u00e9s de uma API definida sobre protocolos de comunica\u00e7\u00e3o de rede, tais como REST APIs e HTTP/HTTPS. O prop\u00f3sito principal de um servi\u00e7o \u00e9 fornecer, ao sistema, acesso a um conjunto de funcionalidades, de modo que o servi\u00e7o provedor seja totalmente reutiliz\u00e1vel e independente do resto do sistema. Com isso, podemos desenvolver, construir e implantar o servi\u00e7o de forma totalmente desacoplada dos demais componentes. Vantagens x Desvantagens \u00b6 Model as as Service \u00e9 uma estrat\u00e9gia adequada para a maioria das situa\u00e7\u00f5es. A principal ressalva \u00e9 que infer\u00eancias s\u00f3 estar\u00e3o dispon\u00edveis caso o usu\u00e1rio esteja online. Vantagens \u00b6 As principais vantagens de se implantar modelos de ML como servi\u00e7os s\u00e3o: Integra\u00e7\u00e3o com o restante do sistema, tecnologias e processos extremamente simplificada. Gerenciamento do modelo simplificado. Desvantagens \u00b6 J\u00e1 os contras s\u00e3o: Necess\u00e1rio mais aplica\u00e7\u00f5es para gerenciar. N\u00e3o \u00e9 poss\u00edvel realizar infer\u00eancias offline. Lat\u00eancia de infer\u00eancia consideravelmente maior quanto comparado com infer\u00eancias offline, uma vez que os dados precisam ser enviados pela rede. Dados sens\u00edveis do usu\u00e1rio s\u00e3o enviados pela rede e executados em um dom\u00ednio externo ao dele. Arquiteturas baseadas em M\u00e1quinas Virtuais e Containers \u00b6 Partindo de uma perspectiva de escalabilidade, podemos implantar os servi\u00e7os de predi\u00e7\u00e3o de duas formas principais: m\u00e1quinas virtuais ou containers. M\u00e1quinas Virtuais \u00b6 Com m\u00e1quinas virtuais (e.g. inst\u00e2ncias AWS EC2), usamos uma ou mais inst\u00e2ncias onde o servi\u00e7o web roda em paralelo (no caso de mais de uma inst\u00e2ncia). A necessidade de diversas inst\u00e2ncias se d\u00e1 quando h\u00e1 um grande volume de requisi\u00e7\u00f5es a ser atendido. Neste caso, tamb\u00e9m inclu\u00edmos um load balancer que ir\u00e1 receber as requisi\u00e7\u00f5es e redirecion\u00e1-las para a inst\u00e2ncia com maior disponibilidade. Note, entretanto, que a necessidade de virtualiza\u00e7\u00e3o prejudica consideravelmente a efici\u00eancia de uso dos recursos de cada inst\u00e2ncia. Fonte: Machine Learning Engineering by Andriy Burkov (2020) Containers \u00b6 Diferente de m\u00e1quinas virtuais, containers s\u00e3o consideravelmente mais eficientes no uso de recursos, tornando os gastos menores sem perda de desempenho (onde desempenho significa atender uma alta demanda de requisi\u00e7\u00f5es). Dessa forma, podemos usar um orquestrador de containers como o Kubernetes para gerenciar um conjunto de containers executando em uma ou mais m\u00e1quinas dentro de um cluster auto-escal\u00e1vel. Com essa estrat\u00e9gia, podemos reduzir o n\u00famero de r\u00e9plicas (ou seja, containers ativos em paralelo) para zero, quando n\u00e3o houver qualquer requisi\u00e7\u00e3o e aumentar para um n\u00famero suficientemente grande quando houver um grande volume de requisi\u00e7\u00f5es. No geral, a implanta\u00e7\u00e3o de servi\u00e7os de predi\u00e7\u00e3o em containers \u00e9 a mais indicada. Fonte: Machine Learning Engineering by Andriy Burkov (2020) Protocolos de Comunica\u00e7\u00e3o \u00b6 Assim como em qualquer servi\u00e7o convencional (aplica\u00e7\u00f5es web, banco de dados, etc), no Model as a Service (MaaS) a intera\u00e7\u00e3o com o modelo acontece atrav\u00e9s de APIs definidas sobre protocolos de comunica\u00e7\u00e3o em rede. As arquiteturas de API mais comuns s\u00e3o: REST (Representational State Transfer) com protocolo HTTP gRPC (Google Remote Procedure Call) com HTTP 2.0. Exemplo \u00b6 A fim de solidificar o conhecimento, segue um exemplo pr\u00e1tico de serving (ou seria implanta\u00e7\u00e3o? ) de um modelo como um servi\u00e7o. Model as a Service com FastAPI e Docker \u00b6 O Python cont\u00e9m diversos pacotes como Flask, FastAPI e Uvicorn que nos permite definir facilmente uma API REST, tal como servidores altamente eficientes. Para detalhes sobre a implementa\u00e7\u00e3o de APIs em Python acesse a p\u00e1gina de cria\u00e7\u00e3o de APIs em Python : Supondo que j\u00e1 temos um modelo treinado (no caso, para a an\u00e1lise de sentimentos), a primeira etapa \u00e9 definir o endpoint de requisi\u00e7\u00e3o para infer\u00eancias e qual m\u00e9todo REST ser\u00e1 utilizado. Geralmente, nomeamos o endpoint como predict ou inference e usamos o m\u00e9todo POST (uma vez que com POST podemos definir o corpo da requisi\u00e7\u00e3o). Para definir o corpo da requisi\u00e7\u00e3o no FastAPI, utilizamos a estrat\u00e9gia de definir uma classe UserRequest derivada da classe BaseModel de pydantic . Em seguida, basta chamar o preditor para executar a infer\u00eancia e ent\u00e3o retornamos os resultados. # my_predictor.py from fastapi import FastAPI from textblob import TextBlob app = FastAPI ( title = \"ML Model as a Service\" ) class UserRequest ( BaseModel ): sentence : str @app . post ( \"/predict/\" ) async def predict ( user_request : UserRequest ): testimonial = TextBlob ( user_request . sentence ) return { \"result\" : f \"Polarity is { testimonial . sentiment . polarity } and subjectivity is { testimonial . sentiment . subjectivity } \" # type: ignore } Para executar as requisi\u00e7\u00f5es, iniciamos um servidor (com o uvicorn), fazendo a chamada no mesmo n\u00edvel do arquivo Python onde est\u00e1 definda a API: $ uvicorn my_predictor:app --port <port_number> Ent\u00e3o acessamos o endere\u00e7o http://127.0.0.1:<port_number>/docs e usamos a documenta\u00e7\u00e3o de API fornecida pela Swagger UI para enviar requisi\u00e7\u00f5es. Ainda, dado que o endpoint defindo \u00e9 da forma http://<ip_address>:<port_number>/predict/?data=<data> , podemos enviar requisi\u00e7\u00f5es de qualquer forma, incluindo via curl curl -X 'POST' \\ 'http://localhost:8000/predict/' \\ -H 'accept: application/json' \\ -H 'Content-Type: application/json' \\ -d '{ \"sentence\": \"Life is beautiful, enjoy it!\" }' Podemos tamb\u00e9m definir o endpoint para receber requisi\u00e7\u00f5es GET , eliminando a passagem de dados via corpo de requisi\u00e7\u00e3o (embora isso seja mais uma vantagem do que desvantagem). # my_predictor.py from fastapi import FastAPI from textblob import TextBlob app = FastAPI ( title = \"ML Model as a Service\" ) @app . get ( \"/predict/\" ) async def predict ( sentence ): testimonial = TextBlob ( sentence ) return { \"result\" : f \"Polarity is { testimonial . sentiment . polarity } and subjectivity is { testimonial . sentiment . subjectivity } \" # type: ignore } Ent\u00e3o, executamos as chamadas via web browser, por exemplo: http://localhost:8000/predict/?sentence = %22Life%20is%20beautiful,%20enjoy%20it%22 Conclus\u00e3o \u00b6 Este foi um exemplo pr\u00e1tico extremamente simples. No mundo real, h\u00e1 diversas outras considera\u00e7\u00f5es que devemos levar em conta durante o serving de um modelo como um servi\u00e7o, por exemplo: Quando um modelo \u00e9 atualizado, precisamos que isso se reflita no servi\u00e7o. Contudo, n\u00e3o podemos simplesmente desligar e religar um servi\u00e7o. Portanto, como atualizar os modelos para servi\u00e7os em produ\u00e7\u00e3o? \u00c9 muito poss\u00edvel que existam per\u00edodos em que a quantidade de requisi\u00e7\u00e3o \u00e9 grande o suficiente para derrubar o servi\u00e7o, tornando necess\u00e1rio o uso de um load balancer. Quando isso deve acontecer? Como deve ser o load balancer? Coment\u00e1rios sobre estes problemas ser\u00e3o inclu\u00eddos futuramente! Interessado em mais exemplos? Caso queira ver mais exemplos de MaaS acesse o reposit\u00f3rio ahayasic/model-as-a-service-examples . Mas j\u00e1 adianto que n\u00e3o h\u00e1 uma explica\u00e7\u00e3o aprofundada para nenhum dos exemplos. Apenas c\u00f3digo \u00af\\_(\u30c4)_/\u00af","title":"Model as a Service"},{"location":"concepts/serving/model_as_a_service/#model-as-a-service-maas","text":"","title":"Model as a Service (MaaS)"},{"location":"concepts/serving/model_as_a_service/#introducao","text":"A estrat\u00e9gia Model-as-a-Service \u00e9 a mais adotada para servir modelos de ML. Nela, o modelo \u00e9 abstra\u00eddo em um servi\u00e7o (tipicamente web) que recebe requisi\u00e7\u00f5es de infer\u00eancia. Ap\u00f3s executada as infer\u00eancias, o servi\u00e7o retorna os resultados ao requerente. Dependendo da implementa\u00e7\u00e3o, o servi\u00e7o pode receber tanto batches de dados para infer\u00eancia, quanto entradas individuais. Imagem: Exemplo gen\u00e9rico da arquitetura Model-as-a-Service, onde um dispositivo faz requisi\u00e7\u00f5es de infer\u00eancia atrav\u00e9s de uma interface e ent\u00e3o recebe como resposta o resultado da predi\u00e7\u00e3o. Sobre Servi\u00e7os No contexto de arquitetura de software, um servi\u00e7o \u00e9 uma unidade de software auto-contida respons\u00e1vel por executar uma tarefa espec\u00edfica. Um servi\u00e7o deve conter todo o c\u00f3digo e dados necess\u00e1rios para executar sua tarefa, sendo implantando (geralmente) em um ambiente totalmente dedicado para si. Demais componentes do software (ou arquitetura) interagem com o servi\u00e7o atrav\u00e9s de uma API definida sobre protocolos de comunica\u00e7\u00e3o de rede, tais como REST APIs e HTTP/HTTPS. O prop\u00f3sito principal de um servi\u00e7o \u00e9 fornecer, ao sistema, acesso a um conjunto de funcionalidades, de modo que o servi\u00e7o provedor seja totalmente reutiliz\u00e1vel e independente do resto do sistema. Com isso, podemos desenvolver, construir e implantar o servi\u00e7o de forma totalmente desacoplada dos demais componentes.","title":"Introdu\u00e7\u00e3o"},{"location":"concepts/serving/model_as_a_service/#vantagens-x-desvantagens","text":"Model as as Service \u00e9 uma estrat\u00e9gia adequada para a maioria das situa\u00e7\u00f5es. A principal ressalva \u00e9 que infer\u00eancias s\u00f3 estar\u00e3o dispon\u00edveis caso o usu\u00e1rio esteja online.","title":"Vantagens x Desvantagens"},{"location":"concepts/serving/model_as_a_service/#vantagens","text":"As principais vantagens de se implantar modelos de ML como servi\u00e7os s\u00e3o: Integra\u00e7\u00e3o com o restante do sistema, tecnologias e processos extremamente simplificada. Gerenciamento do modelo simplificado.","title":"Vantagens"},{"location":"concepts/serving/model_as_a_service/#desvantagens","text":"J\u00e1 os contras s\u00e3o: Necess\u00e1rio mais aplica\u00e7\u00f5es para gerenciar. N\u00e3o \u00e9 poss\u00edvel realizar infer\u00eancias offline. Lat\u00eancia de infer\u00eancia consideravelmente maior quanto comparado com infer\u00eancias offline, uma vez que os dados precisam ser enviados pela rede. Dados sens\u00edveis do usu\u00e1rio s\u00e3o enviados pela rede e executados em um dom\u00ednio externo ao dele.","title":"Desvantagens"},{"location":"concepts/serving/model_as_a_service/#arquiteturas-baseadas-em-maquinas-virtuais-e-containers","text":"Partindo de uma perspectiva de escalabilidade, podemos implantar os servi\u00e7os de predi\u00e7\u00e3o de duas formas principais: m\u00e1quinas virtuais ou containers.","title":"Arquiteturas baseadas em M\u00e1quinas Virtuais e Containers"},{"location":"concepts/serving/model_as_a_service/#maquinas-virtuais","text":"Com m\u00e1quinas virtuais (e.g. inst\u00e2ncias AWS EC2), usamos uma ou mais inst\u00e2ncias onde o servi\u00e7o web roda em paralelo (no caso de mais de uma inst\u00e2ncia). A necessidade de diversas inst\u00e2ncias se d\u00e1 quando h\u00e1 um grande volume de requisi\u00e7\u00f5es a ser atendido. Neste caso, tamb\u00e9m inclu\u00edmos um load balancer que ir\u00e1 receber as requisi\u00e7\u00f5es e redirecion\u00e1-las para a inst\u00e2ncia com maior disponibilidade. Note, entretanto, que a necessidade de virtualiza\u00e7\u00e3o prejudica consideravelmente a efici\u00eancia de uso dos recursos de cada inst\u00e2ncia. Fonte: Machine Learning Engineering by Andriy Burkov (2020)","title":"M\u00e1quinas Virtuais"},{"location":"concepts/serving/model_as_a_service/#containers","text":"Diferente de m\u00e1quinas virtuais, containers s\u00e3o consideravelmente mais eficientes no uso de recursos, tornando os gastos menores sem perda de desempenho (onde desempenho significa atender uma alta demanda de requisi\u00e7\u00f5es). Dessa forma, podemos usar um orquestrador de containers como o Kubernetes para gerenciar um conjunto de containers executando em uma ou mais m\u00e1quinas dentro de um cluster auto-escal\u00e1vel. Com essa estrat\u00e9gia, podemos reduzir o n\u00famero de r\u00e9plicas (ou seja, containers ativos em paralelo) para zero, quando n\u00e3o houver qualquer requisi\u00e7\u00e3o e aumentar para um n\u00famero suficientemente grande quando houver um grande volume de requisi\u00e7\u00f5es. No geral, a implanta\u00e7\u00e3o de servi\u00e7os de predi\u00e7\u00e3o em containers \u00e9 a mais indicada. Fonte: Machine Learning Engineering by Andriy Burkov (2020)","title":"Containers"},{"location":"concepts/serving/model_as_a_service/#protocolos-de-comunicacao","text":"Assim como em qualquer servi\u00e7o convencional (aplica\u00e7\u00f5es web, banco de dados, etc), no Model as a Service (MaaS) a intera\u00e7\u00e3o com o modelo acontece atrav\u00e9s de APIs definidas sobre protocolos de comunica\u00e7\u00e3o em rede. As arquiteturas de API mais comuns s\u00e3o: REST (Representational State Transfer) com protocolo HTTP gRPC (Google Remote Procedure Call) com HTTP 2.0.","title":"Protocolos de Comunica\u00e7\u00e3o"},{"location":"concepts/serving/model_as_a_service/#exemplo","text":"A fim de solidificar o conhecimento, segue um exemplo pr\u00e1tico de serving (ou seria implanta\u00e7\u00e3o? ) de um modelo como um servi\u00e7o.","title":"Exemplo"},{"location":"concepts/serving/model_as_a_service/#model-as-a-service-com-fastapi-e-docker","text":"O Python cont\u00e9m diversos pacotes como Flask, FastAPI e Uvicorn que nos permite definir facilmente uma API REST, tal como servidores altamente eficientes. Para detalhes sobre a implementa\u00e7\u00e3o de APIs em Python acesse a p\u00e1gina de cria\u00e7\u00e3o de APIs em Python : Supondo que j\u00e1 temos um modelo treinado (no caso, para a an\u00e1lise de sentimentos), a primeira etapa \u00e9 definir o endpoint de requisi\u00e7\u00e3o para infer\u00eancias e qual m\u00e9todo REST ser\u00e1 utilizado. Geralmente, nomeamos o endpoint como predict ou inference e usamos o m\u00e9todo POST (uma vez que com POST podemos definir o corpo da requisi\u00e7\u00e3o). Para definir o corpo da requisi\u00e7\u00e3o no FastAPI, utilizamos a estrat\u00e9gia de definir uma classe UserRequest derivada da classe BaseModel de pydantic . Em seguida, basta chamar o preditor para executar a infer\u00eancia e ent\u00e3o retornamos os resultados. # my_predictor.py from fastapi import FastAPI from textblob import TextBlob app = FastAPI ( title = \"ML Model as a Service\" ) class UserRequest ( BaseModel ): sentence : str @app . post ( \"/predict/\" ) async def predict ( user_request : UserRequest ): testimonial = TextBlob ( user_request . sentence ) return { \"result\" : f \"Polarity is { testimonial . sentiment . polarity } and subjectivity is { testimonial . sentiment . subjectivity } \" # type: ignore } Para executar as requisi\u00e7\u00f5es, iniciamos um servidor (com o uvicorn), fazendo a chamada no mesmo n\u00edvel do arquivo Python onde est\u00e1 definda a API: $ uvicorn my_predictor:app --port <port_number> Ent\u00e3o acessamos o endere\u00e7o http://127.0.0.1:<port_number>/docs e usamos a documenta\u00e7\u00e3o de API fornecida pela Swagger UI para enviar requisi\u00e7\u00f5es. Ainda, dado que o endpoint defindo \u00e9 da forma http://<ip_address>:<port_number>/predict/?data=<data> , podemos enviar requisi\u00e7\u00f5es de qualquer forma, incluindo via curl curl -X 'POST' \\ 'http://localhost:8000/predict/' \\ -H 'accept: application/json' \\ -H 'Content-Type: application/json' \\ -d '{ \"sentence\": \"Life is beautiful, enjoy it!\" }' Podemos tamb\u00e9m definir o endpoint para receber requisi\u00e7\u00f5es GET , eliminando a passagem de dados via corpo de requisi\u00e7\u00e3o (embora isso seja mais uma vantagem do que desvantagem). # my_predictor.py from fastapi import FastAPI from textblob import TextBlob app = FastAPI ( title = \"ML Model as a Service\" ) @app . get ( \"/predict/\" ) async def predict ( sentence ): testimonial = TextBlob ( sentence ) return { \"result\" : f \"Polarity is { testimonial . sentiment . polarity } and subjectivity is { testimonial . sentiment . subjectivity } \" # type: ignore } Ent\u00e3o, executamos as chamadas via web browser, por exemplo: http://localhost:8000/predict/?sentence = %22Life%20is%20beautiful,%20enjoy%20it%22","title":"Model as a Service com FastAPI e Docker"},{"location":"concepts/serving/model_as_a_service/#conclusao","text":"Este foi um exemplo pr\u00e1tico extremamente simples. No mundo real, h\u00e1 diversas outras considera\u00e7\u00f5es que devemos levar em conta durante o serving de um modelo como um servi\u00e7o, por exemplo: Quando um modelo \u00e9 atualizado, precisamos que isso se reflita no servi\u00e7o. Contudo, n\u00e3o podemos simplesmente desligar e religar um servi\u00e7o. Portanto, como atualizar os modelos para servi\u00e7os em produ\u00e7\u00e3o? \u00c9 muito poss\u00edvel que existam per\u00edodos em que a quantidade de requisi\u00e7\u00e3o \u00e9 grande o suficiente para derrubar o servi\u00e7o, tornando necess\u00e1rio o uso de um load balancer. Quando isso deve acontecer? Como deve ser o load balancer? Coment\u00e1rios sobre estes problemas ser\u00e3o inclu\u00eddos futuramente! Interessado em mais exemplos? Caso queira ver mais exemplos de MaaS acesse o reposit\u00f3rio ahayasic/model-as-a-service-examples . Mas j\u00e1 adianto que n\u00e3o h\u00e1 uma explica\u00e7\u00e3o aprofundada para nenhum dos exemplos. Apenas c\u00f3digo \u00af\\_(\u30c4)_/\u00af","title":"Conclus\u00e3o"},{"location":"concepts/serving/serverless_serving/","text":"Serverless Serving \u00b6","title":"Serverless Serving"},{"location":"concepts/serving/serverless_serving/#serverless-serving","text":"","title":"Serverless Serving"},{"location":"concepts/serving/static_deployment/","text":"Modelo como Parte da Aplica\u00e7\u00e3o (Static Deployment) \u00b6 Introdu\u00e7\u00e3o \u00b6 Nesta abordagem \\(-\\) que Andriy Burkov chama de Static Deployment \\(-\\) o modelo \u00e9 empacotado como parte da aplica\u00e7\u00e3o que ent\u00e3o \u00e9 instalada atrav\u00e9s de um arquivo de distribui\u00e7\u00e3o de aplica\u00e7\u00f5es, como, por exemplo: arquivo bin\u00e1rio execut\u00e1vel, JAR, APK, DEB, etc. Vantagens x Desvantagens \u00b6 Static deployment \u00e9 uma estrat\u00e9gia adequada para modelos simples que precisam estar dispon\u00edveis o tempo todo (mesmo se o usu\u00e1rio estiver offline). Tamb\u00e9m \u00e9 adequado para infer\u00eancias em batches ou fluxo. Por\u00e9m, o retreinamento tende estar restrito a lotes, uma vez que \u00e9 necess\u00e1rio atualizar toda a aplica\u00e7\u00e3o para incluir uma nova vers\u00e3o do modelo. Vantagens \u00b6 N\u00e3o \u00e9 preciso enviar dados do usu\u00e1rio para um servidor (ou qualquer recurso) externo ao dispositivo do usu\u00e1rio O modelo estar\u00e1 sempre dispon\u00edvel, mesmo se o usu\u00e1rio estiver offline (sem conex\u00e3o com a Internet) Caso seja um modelo simples, sem necessidade de computa\u00e7\u00f5es r\u00e1pidas ou pesadas, o tempo de infer\u00eancia \u00e9 muito mais r\u00e1pido na abordagem \"est\u00e1tico\" quando comparado com qualquer outra estrat\u00e9gia Desvantagens \u00b6 Para atualizar o modelo \u00e9 necess\u00e1rio atualizar toda a aplica\u00e7\u00e3o (ou seja, reconstruir o arquivo de distribui\u00e7\u00e3o da aplica\u00e7\u00e3o mesmo que apenas o modelo tenha sofrido altera\u00e7\u00f5es) Executar o monitoramento de performance do modelo \u00e9 extremamente dif\u00edcil Se a computa\u00e7\u00e3o do modelo for cara, execut\u00e1-la no dispositivo do usu\u00e1rio pode ser ineficiente ou prejudicar a experi\u00eancia do usu\u00e1rio","title":"Static Deployment"},{"location":"concepts/serving/static_deployment/#modelo-como-parte-da-aplicacao-static-deployment","text":"","title":"Modelo como Parte da Aplica\u00e7\u00e3o (Static Deployment)"},{"location":"concepts/serving/static_deployment/#introducao","text":"Nesta abordagem \\(-\\) que Andriy Burkov chama de Static Deployment \\(-\\) o modelo \u00e9 empacotado como parte da aplica\u00e7\u00e3o que ent\u00e3o \u00e9 instalada atrav\u00e9s de um arquivo de distribui\u00e7\u00e3o de aplica\u00e7\u00f5es, como, por exemplo: arquivo bin\u00e1rio execut\u00e1vel, JAR, APK, DEB, etc.","title":"Introdu\u00e7\u00e3o"},{"location":"concepts/serving/static_deployment/#vantagens-x-desvantagens","text":"Static deployment \u00e9 uma estrat\u00e9gia adequada para modelos simples que precisam estar dispon\u00edveis o tempo todo (mesmo se o usu\u00e1rio estiver offline). Tamb\u00e9m \u00e9 adequado para infer\u00eancias em batches ou fluxo. Por\u00e9m, o retreinamento tende estar restrito a lotes, uma vez que \u00e9 necess\u00e1rio atualizar toda a aplica\u00e7\u00e3o para incluir uma nova vers\u00e3o do modelo.","title":"Vantagens x Desvantagens"},{"location":"concepts/serving/static_deployment/#vantagens","text":"N\u00e3o \u00e9 preciso enviar dados do usu\u00e1rio para um servidor (ou qualquer recurso) externo ao dispositivo do usu\u00e1rio O modelo estar\u00e1 sempre dispon\u00edvel, mesmo se o usu\u00e1rio estiver offline (sem conex\u00e3o com a Internet) Caso seja um modelo simples, sem necessidade de computa\u00e7\u00f5es r\u00e1pidas ou pesadas, o tempo de infer\u00eancia \u00e9 muito mais r\u00e1pido na abordagem \"est\u00e1tico\" quando comparado com qualquer outra estrat\u00e9gia","title":"Vantagens"},{"location":"concepts/serving/static_deployment/#desvantagens","text":"Para atualizar o modelo \u00e9 necess\u00e1rio atualizar toda a aplica\u00e7\u00e3o (ou seja, reconstruir o arquivo de distribui\u00e7\u00e3o da aplica\u00e7\u00e3o mesmo que apenas o modelo tenha sofrido altera\u00e7\u00f5es) Executar o monitoramento de performance do modelo \u00e9 extremamente dif\u00edcil Se a computa\u00e7\u00e3o do modelo for cara, execut\u00e1-la no dispositivo do usu\u00e1rio pode ser ineficiente ou prejudicar a experi\u00eancia do usu\u00e1rio","title":"Desvantagens"},{"location":"concepts/training/","text":"Constru\u00e7\u00e3o de Modelos \u00b6 Work in progress","title":"Constru\u00e7\u00e3o de Modelos"},{"location":"concepts/training/#construcao-de-modelos","text":"Work in progress","title":"Constru\u00e7\u00e3o de Modelos"},{"location":"concepts/training/error_analysis/","text":"Work in progress","title":"An\u00e1lise de Erros"},{"location":"concepts/training/establishing_baselines/","text":"Estabelecendo Baselines \u00b6 Introdu\u00e7\u00e3o \u00b6 No contexto de projetos de ML, um baseline \u00e9 um modelo simples mas que alcan\u00e7a resultados razo\u00e1veis no problema que desejamos resolver e cujos resultados s\u00e3o utilizados como ponto de partida (ou seja, define um desempenho m\u00ednimo) para o desempenho que queremos alcan\u00e7ar e, consequentemente, a constru\u00e7\u00e3o de modelos mais complexos. Nota Por simples, queremos dizer que \u00e9 um modelo f\u00e1cil de treinar, implantar e que n\u00e3o exige grande expertise. No geral, modelos assim tamb\u00e9m s\u00e3o f\u00e1ceis de explicar e analisar. De fato, definir um ponto de partida de performance (baseline level performance) \u00e9 uma pr\u00e1tica muito importante para a evolu\u00e7\u00e3o de desempenho de um modelo. Afinal, este ponto de partida nos ajuda a definir: Qual o desempenho m\u00ednimo aceit\u00e1vel para o modelo entrar em produ\u00e7\u00e3o e o qu\u00e3o fact\u00edvel esse desempenho \u00e9. Quais processamentos precisamos fazer nos dados a fim de melhorar sua qualidade. O quanto de recurso computacional (e humano) ser\u00e1 necess\u00e1rio para construir o modelo desejado. Por exemplo: Tarefas de Regress\u00e3o. Regress\u00e3o Linear. Tarefas de Classifica\u00e7\u00e3o em Dados Estruturados. K-Nearest Neighbors. Tarefas de Vis\u00e3o Computacional ou NLP. Modelos Pr\u00e9-treinados. Tipos de Baseline \u00b6 Emmanuel Ameisen define quatro tipos de baseline de performance: Performance Trivialmente Alcan\u00e7\u00e1vel. Desempenho obtido da maneira mais simples poss\u00edvel. \u00c9 esperado que qualquer modelo ultrapasse esse desempenho. Performance de N\u00edvel Humano (HLP, Human Level Performance). Desempenho obtido por humanos na tarefa em quest\u00e3o. Quando um modelo ultrapassa esse desempenho, ent\u00e3o \u00e9 um bom candidato a entrar em produ\u00e7\u00e3o. O uso de HLP \u00e9 recomend\u00e1vel principalmente em tarefas que envolvam a classifica\u00e7\u00e3o de dados n\u00e3o estruturados. Performance Automatizada Razo\u00e1vel. Desempenho obtido por um modelo consideravelmente simples. Esse desempenho nos ajuda a julgar se um modelo complexo est\u00e1 performando bem o suficiente em rela\u00e7\u00e3o a sua complexidade de implementa\u00e7\u00e3o. Performance M\u00ednima para Deployment. Desempenho m\u00ednimo necess\u00e1rio para que um modelo possa entrar em produ\u00e7\u00e3o. Qual tipo de baseline ser\u00e1 adotada depende do dom\u00ednio do problema e objetivos. Contudo, \u00e9 aconselh\u00e1vel sempre definir uma performance m\u00ednima para deployment, assim como o desempenho obtido por um modelo simples (performance automatizada razo\u00e1vel). Se estivermos trabalhando com dados n\u00e3o-estruturados, podemos incluir HLP. Refer\u00eancias \u00b6 Topic 3 - Baselines Always Start with a Stupid Model, No Exceptions by Emmanuel Ameisen Introduction to Machine Learning in Production by Coursera","title":"Defini\u00e7\u00e3o de Baselines"},{"location":"concepts/training/establishing_baselines/#estabelecendo-baselines","text":"","title":"Estabelecendo Baselines"},{"location":"concepts/training/establishing_baselines/#introducao","text":"No contexto de projetos de ML, um baseline \u00e9 um modelo simples mas que alcan\u00e7a resultados razo\u00e1veis no problema que desejamos resolver e cujos resultados s\u00e3o utilizados como ponto de partida (ou seja, define um desempenho m\u00ednimo) para o desempenho que queremos alcan\u00e7ar e, consequentemente, a constru\u00e7\u00e3o de modelos mais complexos. Nota Por simples, queremos dizer que \u00e9 um modelo f\u00e1cil de treinar, implantar e que n\u00e3o exige grande expertise. No geral, modelos assim tamb\u00e9m s\u00e3o f\u00e1ceis de explicar e analisar. De fato, definir um ponto de partida de performance (baseline level performance) \u00e9 uma pr\u00e1tica muito importante para a evolu\u00e7\u00e3o de desempenho de um modelo. Afinal, este ponto de partida nos ajuda a definir: Qual o desempenho m\u00ednimo aceit\u00e1vel para o modelo entrar em produ\u00e7\u00e3o e o qu\u00e3o fact\u00edvel esse desempenho \u00e9. Quais processamentos precisamos fazer nos dados a fim de melhorar sua qualidade. O quanto de recurso computacional (e humano) ser\u00e1 necess\u00e1rio para construir o modelo desejado. Por exemplo: Tarefas de Regress\u00e3o. Regress\u00e3o Linear. Tarefas de Classifica\u00e7\u00e3o em Dados Estruturados. K-Nearest Neighbors. Tarefas de Vis\u00e3o Computacional ou NLP. Modelos Pr\u00e9-treinados.","title":"Introdu\u00e7\u00e3o"},{"location":"concepts/training/establishing_baselines/#tipos-de-baseline","text":"Emmanuel Ameisen define quatro tipos de baseline de performance: Performance Trivialmente Alcan\u00e7\u00e1vel. Desempenho obtido da maneira mais simples poss\u00edvel. \u00c9 esperado que qualquer modelo ultrapasse esse desempenho. Performance de N\u00edvel Humano (HLP, Human Level Performance). Desempenho obtido por humanos na tarefa em quest\u00e3o. Quando um modelo ultrapassa esse desempenho, ent\u00e3o \u00e9 um bom candidato a entrar em produ\u00e7\u00e3o. O uso de HLP \u00e9 recomend\u00e1vel principalmente em tarefas que envolvam a classifica\u00e7\u00e3o de dados n\u00e3o estruturados. Performance Automatizada Razo\u00e1vel. Desempenho obtido por um modelo consideravelmente simples. Esse desempenho nos ajuda a julgar se um modelo complexo est\u00e1 performando bem o suficiente em rela\u00e7\u00e3o a sua complexidade de implementa\u00e7\u00e3o. Performance M\u00ednima para Deployment. Desempenho m\u00ednimo necess\u00e1rio para que um modelo possa entrar em produ\u00e7\u00e3o. Qual tipo de baseline ser\u00e1 adotada depende do dom\u00ednio do problema e objetivos. Contudo, \u00e9 aconselh\u00e1vel sempre definir uma performance m\u00ednima para deployment, assim como o desempenho obtido por um modelo simples (performance automatizada razo\u00e1vel). Se estivermos trabalhando com dados n\u00e3o-estruturados, podemos incluir HLP.","title":"Tipos de Baseline"},{"location":"concepts/training/establishing_baselines/#referencias","text":"Topic 3 - Baselines Always Start with a Stupid Model, No Exceptions by Emmanuel Ameisen Introduction to Machine Learning in Production by Coursera","title":"Refer\u00eancias"},{"location":"concepts/training/evaluation_metrics/","text":"Work in progress","title":"M\u00e9tricas de Avalia\u00e7\u00e3o"},{"location":"concepts/training/feature_engineering/","text":"Work in progress","title":"Feature Engineering"},{"location":"concepts/training/hyperparameters_tuning/","text":"Work in progress","title":"Otimiza\u00e7\u00e3o de Hiperpar\u00e2metros"},{"location":"concepts/training/model_selection/","text":"Work in progress","title":"Sele\u00e7\u00e3o de Modelos"}]}